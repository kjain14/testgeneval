Instance ID: pydata__xarray-3302-16459

Baseline 1 (Pynguin):
Predicted Test Suite: # Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import xarray.core.missing as module_0
import numpy.linalg as module_1
import platform as module_2
import numpy._version as module_3
import urllib.request as module_4
import numpy.polynomial.legendre as module_5


def test_case_0():
    str_0 = "2\ny$=<&JG"
    numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, str_0, fill_value=str_0)
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}


def test_case_1():
    bool_0 = True
    bool_1 = False
    list_0 = [bool_0, bool_1]
    var_0 = module_1.multi_dot(list_0)
    var_1 = module_0.interp(var_0, var_0, bool_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.bool_"
    str_0 = "2\nyi<@J%G"
    with pytest.raises(ValueError):
        module_0.ScipyInterpolator(
            bool_0, var_1, fill_value=var_0, copy=str_0, bounds_error=var_0, order=var_0
        )


def test_case_2():
    none_type_0 = None
    bool_0 = False
    with pytest.raises(ValueError):
        module_0.SplineInterpolator(
            none_type_0, none_type_0, fill_value=none_type_0, order=bool_0
        )


@pytest.mark.xfail(strict=True)
def test_case_3():
    str_0 = ""
    module_0.interp_na(str_0, str_0)


def test_case_4():
    bool_0 = False
    list_0 = [bool_0, bool_0]
    var_0 = module_1.multi_dot(list_0)
    var_1 = module_0.interp(var_0, var_0, var_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.bool_"
    var_2 = module_0.func_interpolate_na(var_1, list_0, list_0)
    with pytest.raises(TypeError):
        module_0.interp_na()


@pytest.mark.xfail(strict=True)
def test_case_5():
    none_type_0 = None
    module_0.interp(none_type_0, none_type_0, none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_6():
    none_type_0 = None
    module_0.interp_func(
        none_type_0, none_type_0, none_type_0, none_type_0, none_type_0
    )


def test_case_7():
    with pytest.raises(TypeError):
        module_0.interp_na()


@pytest.mark.xfail(strict=True)
def test_case_8():
    bytes_0 = b"\xfe\xc1w\xabR\xb3\x8d\xdct\xa9R\x13\x05"
    numpy_interpolator_0 = module_0.NumpyInterpolator(
        bytes_0, bytes_0, fill_value=bytes_0
    )
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    var_0 = numpy_interpolator_0.__repr__()
    assert var_0 == "NumpyInterpolator: method=linear"
    module_0.interp_func(
        bytes_0,
        numpy_interpolator_0,
        bytes_0,
        numpy_interpolator_0,
        numpy_interpolator_0,
    )


@pytest.mark.xfail(strict=True)
def test_case_9():
    bytes_0 = b"\x17\x98qN\xdb\xa6\xba\xc8\xb4\x14\xac\xd2"
    module_0.interp_func(bytes_0, bytes_0, bytes_0, bytes_0, bytes_0)


def test_case_10():
    str_0 = "4`Mr"
    with pytest.raises(ValueError):
        module_0.ScipyInterpolator(str_0, str_0, str_0)


@pytest.mark.xfail(strict=True)
def test_case_11():
    none_type_0 = None
    numpy_interpolator_0 = module_0.NumpyInterpolator(
        none_type_0, none_type_0, period=none_type_0
    )
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    module_0.get_clean_interp_index(none_type_0, none_type_0, none_type_0)


def test_case_12():
    bool_0 = False
    list_0 = [bool_0, bool_0]
    var_0 = module_1.multi_dot(list_0)
    var_1 = module_0.interp(var_0, var_0, var_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.bool_"
    var_2 = module_0.func_interpolate_na(var_1, list_0, list_0)
    with pytest.raises(NotImplementedError):
        module_0.interp_na(var_1, limit=var_2, max_gap=var_1)


@pytest.mark.xfail(strict=True)
def test_case_13():
    none_type_0 = None
    numpy_interpolator_0 = module_0.NumpyInterpolator(
        none_type_0, none_type_0, period=none_type_0
    )
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    var_0 = module_2.python_revision()
    numpy_interpolator_0.__call__(none_type_0)


def test_case_14():
    none_type_0 = None
    with pytest.raises(ValueError):
        module_0.NumpyInterpolator(none_type_0, none_type_0, none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_15():
    bool_0 = False
    module_0.interp_na(bool_0, bool_0, max_gap=bool_0)


@pytest.mark.xfail(strict=True)
def test_case_16():
    var_0 = module_3.get_versions()
    module_0.interp(var_0, var_0, var_0)


def test_case_17():
    str_0 = "u3nRP)Q,3@p2{$!mq|"
    bool_0 = False
    none_type_0 = None
    with pytest.raises(ValueError):
        module_0.SplineInterpolator(str_0, bool_0, none_type_0, order=none_type_0)


def test_case_18():
    str_0 = "B5"
    numpy_interpolator_0 = module_0.NumpyInterpolator(
        str_0, str_0, fill_value=str_0, period=str_0
    )
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": "B5"}
    with pytest.raises(NotImplementedError):
        module_0.interp_na(str_0)


@pytest.mark.xfail(strict=True)
def test_case_19():
    bool_0 = True
    bool_1 = False
    list_0 = [bool_0, bool_1]
    var_0 = module_1.multi_dot(list_0)
    var_1 = module_0.interp(var_0, var_0, bool_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.bool_"
    str_0 = "HSq0I\x0cDc`uT<t*d%jA>9"
    module_0.interp_na(var_1, bool_0, str_0, var_0)


@pytest.mark.xfail(strict=True)
def test_case_20():
    var_0 = module_2.release()
    dict_0 = {var_0: var_0}
    numpy_interpolator_0 = module_0.NumpyInterpolator(dict_0, dict_0)
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    module_0.interp_func(var_0, dict_0, var_0, dict_0, var_0)


def test_case_21():
    str_0 = "2\ny$<&JG"
    none_type_0 = None
    numpy_interpolator_0 = module_0.NumpyInterpolator(
        str_0, none_type_0, fill_value=str_0
    )
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    dict_0 = {}
    with pytest.raises(ValueError):
        module_0.SplineInterpolator(
            none_type_0,
            none_type_0,
            fill_value=numpy_interpolator_0,
            nu=none_type_0,
            **dict_0,
        )


@pytest.mark.xfail(strict=True)
def test_case_22():
    bool_0 = True
    bool_1 = False
    list_0 = [bool_0, bool_1]
    var_0 = module_1.multi_dot(list_0)
    var_1 = module_0.interp(var_0, var_0, bool_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.bool_"
    bool_2 = True
    var_2 = module_0.interp_func(var_0, var_1, bool_2, var_1, bool_2)
    assert f"{type(var_2).__module__}.{type(var_2).__qualname__}" == "numpy.bool_"
    module_0.ScipyInterpolator(var_1, bool_0, var_2, var_1)


@pytest.mark.xfail(strict=True)
def test_case_23():
    base_interpolator_0 = module_0.BaseInterpolator()
    base_interpolator_0.__call__(base_interpolator_0)


@pytest.mark.xfail(strict=True)
def test_case_24():
    none_type_0 = None
    numpy_interpolator_0 = module_0.NumpyInterpolator(none_type_0, none_type_0)
    assert (
        f"{type(numpy_interpolator_0).__module__}.{type(numpy_interpolator_0).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_0.method == "linear"
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {"period": None}
    bool_0 = True
    numpy_interpolator_1 = module_0.NumpyInterpolator(
        none_type_0, bool_0, fill_value=bool_0
    )
    assert (
        f"{type(numpy_interpolator_1).__module__}.{type(numpy_interpolator_1).__qualname__}"
        == "xarray.core.missing.NumpyInterpolator"
    )
    assert numpy_interpolator_1.method == "linear"
    assert numpy_interpolator_1.cons_kwargs == {}
    assert numpy_interpolator_1.call_kwargs == {"period": None}
    str_0 = ",+!6;2`dy"
    str_1 = "eJDKY3/0Hr;jKizt;"
    str_2 = "}0AU=4t~4[MU z]iJ'"
    dict_0 = {str_0: str_0, str_1: str_1, str_2: str_1}
    module_0.interp(bool_0, none_type_0, bool_0, **dict_0)


@pytest.mark.xfail(strict=True)
def test_case_25():
    bool_0 = False
    module_0.interp_na(bool_0, bool_0, limit=bool_0)


@pytest.mark.xfail(strict=True)
def test_case_26():
    var_0 = module_4.ftperrors()
    module_0.NumpyInterpolator(var_0, var_0, fill_value=var_0)


def test_case_27():
    bool_0 = True
    bool_1 = False
    list_0 = [bool_0, bool_1]
    str_0 = "n$`wGu4),#l"
    dict_0 = {str_0: str_0, str_0: bool_0, str_0: list_0}
    var_0 = module_0.func_interpolate_na(list_0, list_0, list_0, **dict_0)
    with pytest.raises(ValueError):
        module_0.interp_na(var_0, bool_0, max_gap=list_0)


@pytest.mark.xfail(strict=True)
def test_case_28():
    bool_0 = True
    bool_1 = False
    var_0 = module_5.legline(bool_1, bool_0)
    str_0 = "174`"
    str_1 = "n$`wGu4),#l"
    dict_0 = {str_0: str_0, str_0: bool_0, str_1: var_0}
    var_1 = module_1.multi_dot(var_0)
    module_0.interp_func(var_1, dict_0, dict_0, dict_0, dict_0)

Coverage: 42.758620689655174
Mutation Score: 6.590000000000003

Baseline 2 (CodaMosa):
Predicted Test Suite: import numpy as module_0
import numpy as module_1
import pytest
import xarray.core.missing as module_0
import xarray.core.missing as module_1

def test_case_1():
    try:
        float_0 = 1145.4
        base_interpolator_0 = module_0.BaseInterpolator()
        var_0 = base_interpolator_0.__call__(float_0)
    except BaseException:
        pass


def test_case_2():
    try:
        str_0 = '0'
        dict_0 = {str_0: str_0}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        assert module_0.dask_array_type == ()
        tuple_0 = ()
        bytes_0 = b'|\xfa%\xa2\x1bMs5\x97\xfb\xc8\x9d=2\xa9'
        var_0 = module_0.interp_func(tuple_0, bytes_0, str_0, numpy_interpolator_0, dict_0)
    except BaseException:
        pass


def test_case_3():
    try:
        str_0 = 'igvY'
        dict_0 = None
        base_interpolator_0 = module_0.BaseInterpolator()
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0, base_interpolator_0)
    except BaseException:
        pass


def test_case_4():
    try:
        str_0 = '4Rl'
        dict_0 = {}
        str_1 = 'GG+"60'
        list_0 = [dict_0, str_0, str_1]
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_1, list_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        assert module_0.dask_array_type == ()
        numpy_interpolator_1 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_1.method == 'linear'
        assert numpy_interpolator_1.cons_kwargs == {}
        assert numpy_interpolator_1.call_kwargs == {'period': None}
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        tuple_0 = ()
        list_1 = []
        tuple_1 = (tuple_0, list_1)
        var_0 = numpy_interpolator_1.__call__(tuple_1)
    except BaseException:
        pass


def test_case_5():
    try:
        str_0 = 'cannot read or write netCDF files without netCDF4-python or scipy installed'
        base_interpolator_0 = module_0.BaseInterpolator()
        timedelta64_0 = module_1.timedelta64()
        bytes_0 = b"\x10L\xa0=H\xdc'F\xbdM\xb44\x83K\xcf\x8f\x94\x05"
        set_0 = {bytes_0, str_0}
        dict_0 = {str_0: bytes_0}
        scipy_interpolator_0 = module_0.ScipyInterpolator(timedelta64_0, str_0, set_0, dict_0, **dict_0)
    except BaseException:
        pass


def test_case_6():
    try:
        int_0 = 10
        bytes_0 = b'\'*\xaa\x83\xc1\x13"H:\xb3\x03bN\xe2\xe9\x92_6'
        spline_interpolator_0 = module_0.SplineInterpolator(bytes_0, int_0, bytes_0)
    except BaseException:
        pass


def test_case_7():
    try:
        str_0 = '40M'
        var_0 = module_0.interp_na(str_0, str_0)
    except BaseException:
        pass


def test_case_8():
    try:
        bool_0 = True
        var_0 = module_0.bfill(bool_0)
    except BaseException:
        pass


def test_case_9():
    try:
        timedelta64_0 = module_1.timedelta64()
        float_0 = -311.06
        str_0 = '^4Pr #3v1e;DazR!`'
        list_0 = [float_0]
        var_0 = module_0.interp_func(str_0, timedelta64_0, float_0, str_0, list_0)
    except BaseException:
        pass


def test_case_10():
    try:
        str_0 = 'J/Mu\x0b'
        var_0 = module_0.interp_na(str_0)
    except BaseException:
        pass


def test_case_11():
    try:
        bool_0 = False
        var_0 = module_0.ffill(bool_0)
    except BaseException:
        pass


def test_case_12():
    try:
        str_0 = 'd6DnzZfvX5&'
        var_0 = module_0.interp_na(str_0, str_0, str_0)
    except BaseException:
        pass


def test_case_13():
    try:
        float_0 = 2038.755
        timedelta64_0 = module_1.timedelta64()
        int_0 = 316
        var_0 = module_0.interp(float_0, timedelta64_0, int_0)
    except BaseException:
        pass


def test_case_14():
    try:
        str_0 = ''
        var_0 = module_0.interp_na(str_0, str_0, str_0)
    except BaseException:
        pass


def test_case_15():
    try:
        dict_0 = {}
        timedelta_0 = None
        str_0 = 'atf'
        str_1 = 'meeUxtw-'
        dict_1 = {str_0: timedelta_0, str_1: timedelta_0}
        bytes_0 = b'J]\xf0G\xe4(9\xd8\x07\x8c'
        float_0 = -190.0
        var_0 = module_0.interp_func(timedelta_0, dict_1, bytes_0, dict_0, float_0)
    except BaseException:
        pass


def test_case_16():
    try:
        float_0 = -2684.78
        str_0 = '\\?"rk[}?#q'
        bytes_0 = b'\x98\x12\xc4\xfc\xbf$\x80'
        var_0 = module_0.interp(float_0, str_0, bytes_0)
    except BaseException:
        pass


def test_case_17():
    try:
        str_0 = '4RlM'
        dict_0 = {}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        assert module_0.dask_array_type == ()
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        tuple_0 = ()
        int_0 = 1807
        str_1 = 'argument name %r is not in the set of valid options %r'
        str_2 = "'yo2cpp&F\r}G"
        dict_1 = {str_0: str_0, str_1: tuple_0, str_2: int_0}
        var_0 = module_0.interp(int_0, dict_1, str_2)
    except BaseException:
        pass


def test_case_18():
    try:
        str_0 = '4R0lM'
        dict_0 = {}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        assert module_0.dask_array_type == ()
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        float_0 = -1208.508
        bool_0 = False
        set_0 = None
        str_1 = 'hWu5Cb,l<%'
        int_0 = -3951
        var_0 = module_0.interp_na(set_0, bool_0, str_1, int_0, float_0)
    except BaseException:
        pass


def test_case_19():
    try:
        timedelta64_0 = None
        list_0 = None
        list_1 = [list_0, list_0]
        var_0 = module_0.func_interpolate_na(timedelta64_0, list_0, list_1)
        assert var_0 == [None, None]
        assert module_0.dask_array_type == ()
        str_0 = '40 '
        dict_0 = {}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        tuple_0 = ()
        float_0 = -1208.508
        set_0 = {float_0, base_interpolator_0, base_interpolator_0, str_0}
        var_1 = module_0.interp(set_0, tuple_0, dict_0)
        assert len(var_1) == 3
        list_2 = [str_0]
        bool_0 = True
        var_2 = module_0.interp_func(timedelta64_0, list_2, list_2, bool_0, dict_0)
    except BaseException:
        pass


def test_case_20():
    try:
        timedelta64_0 = None
        list_0 = None
        list_1 = [list_0, list_0]
        var_0 = module_0.func_interpolate_na(timedelta64_0, list_0, list_1)
        assert var_0 == [None, None]
        assert module_0.dask_array_type == ()
        str_0 = '40 '
        dict_0 = {}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        var_1 = module_0.interp_na(str_0)
    except BaseException:
        pass


def test_case_21():
    try:
        timedelta64_0 = None
        list_0 = None
        list_1 = [list_0, list_0]
        var_0 = module_0.func_interpolate_na(timedelta64_0, list_0, list_1)
        assert var_0 == [None, None]
        assert module_0.dask_array_type == ()
        str_0 = '40 '
        dict_0 = {}
        numpy_interpolator_0 = module_0.NumpyInterpolator(str_0, dict_0)
        assert numpy_interpolator_0.method == 'linear'
        assert numpy_interpolator_0.cons_kwargs == {}
        assert numpy_interpolator_0.call_kwargs == {'period': None}
        base_interpolator_0 = module_0.BaseInterpolator()
        assert base_interpolator_0 is not None
        tuple_0 = ()
        float_0 = -1208.5
        set_0 = {float_0, base_interpolator_0, base_interpolator_0, str_0}
        var_1 = module_0.interp(set_0, tuple_0, dict_0)
        assert len(var_1) == 3
        list_2 = [tuple_0]
        dict_1 = {}
        int_0 = 5
        var_2 = module_0.interp_func(list_2, dict_1, str_0, int_0, set_0)
        assert var_2 == [()]
        float_1 = -552.8083
        list_3 = [timedelta64_0, set_0, base_interpolator_0, str_0]
        var_3 = module_0.func_interpolate_na(str_0, float_1, list_3)
    except BaseException:
        pass# Automatically generated by Pynguin.


def test_case_22():
    pass


def test_case_23():
    int_0 = -653
    timedelta64_0 = module_0.timedelta64()
    numpy_interpolator_0 = module_1.NumpyInterpolator(int_0, timedelta64_0)
    assert numpy_interpolator_0.method == 'linear'
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {'period': None}
    assert module_0.newaxis is None
    assert module_0.little_endian is True
    assert module_0.Inf == pytest.approx(1e309, abs=0.01, rel=0.01)
    assert module_0.inf == pytest.approx(1e309, abs=0.01, rel=0.01)
    assert module_0.infty == pytest.approx(1e309, abs=0.01, rel=0.01)
    assert module_0.Infinity == pytest.approx(1e309, abs=0.01, rel=0.01)
    assert module_0.CLIP == 0
    assert module_0.RAISE == 2
    assert module_0.WRAP == 1
    assert module_0.MAXDIMS == 32
    assert module_0.BUFSIZE == 8192
    assert module_0.ALLOW_THREADS == 1
    assert module_0.MAY_SHARE_BOUNDS == 0
    assert module_0.MAY_SHARE_EXACT == -1
    assert module_0.ERR_CALL == 3
    assert module_0.ERR_DEFAULT == 521
    assert module_0.ERR_IGNORE == 0
    assert module_0.ERR_LOG == 5
    assert module_0.ERR_PRINT == 4
    assert module_0.ERR_RAISE == 2
    assert module_0.ERR_WARN == 1
    assert module_0.FLOATING_POINT_SUPPORT == 1
    assert module_0.FPE_DIVIDEBYZERO == 1
    assert module_0.FPE_INVALID == 8
    assert module_0.FPE_OVERFLOW == 2
    assert module_0.FPE_UNDERFLOW == 4
    assert module_0.NINF == pytest.approx(-1e309, abs=0.01, rel=0.01)
    assert module_0.NZERO == pytest.approx(-0.0, abs=0.01, rel=0.01)
    assert module_0.PINF == pytest.approx(1e309, abs=0.01, rel=0.01)
    assert module_0.PZERO == pytest.approx(0.0, abs=0.01, rel=0.01)
    assert module_0.SHIFT_DIVIDEBYZERO == 0
    assert module_0.SHIFT_INVALID == 9
    assert module_0.SHIFT_OVERFLOW == 3
    assert module_0.SHIFT_UNDERFLOW == 6
    assert module_0.UFUNC_BUFSIZE_DEFAULT == 8192
    assert module_0.UFUNC_PYVALS_NAME == 'UFUNC_PYVALS'
    assert module_0.e == pytest.approx(2.718281828459045, abs=0.01, rel=0.01)
    assert module_0.euler_gamma == pytest.approx(0.5772156649015329, abs=0.01, rel=0.01)
    assert module_0.pi == pytest.approx(3.141592653589793, abs=0.01, rel=0.01)
    assert len(module_0.sctypeDict) == 136
    assert len(module_0.sctypes) == 5
    assert len(module_0.ScalarType) == 31
    assert len(module_0.cast) == 24
    assert len(module_0.nbytes) == 24
    assert module_0.typecodes == {'Character': 'c', 'Integer': 'bhilqp', 'UnsignedInteger': 'BHILQP', 'Float': 'efdg', 'Complex': 'FDG', 'AllInteger': 'bBhHiIlLqQpP', 'AllFloat': 'efdgFDG', 'Datetime': 'Mm', 'All': '?bhilqpBHILQPefdgFDGSUVOMm'}
    assert module_0.tracemalloc_domain == 389047
    assert module_0.mgrid.sparse is False
    assert module_0.ogrid.sparse is True
    assert len(module_0.r_) == 0
    assert len(module_0.c_) == 0
    assert module_0.s_.maketuple is False
    assert module_0.index_exp.maketuple is True
    assert module_0.oldnumeric == 'removed'
    assert module_0.numarray == 'removed'
    assert module_0.use_hugepage == 1
    assert module_0.kernel_version == (6, 8)
    assert module_1.dask_array_type == ()


def test_case_24():
    tuple_0 = ()
    str_0 = 'int64'
    dict_0 = {tuple_0: tuple_0, tuple_0: tuple_0, str_0: tuple_0, str_0: str_0}
    list_0 = [str_0, dict_0, tuple_0, tuple_0]
    numpy_interpolator_0 = module_1.NumpyInterpolator(dict_0, list_0)
    assert numpy_interpolator_0.method == 'linear'
    assert numpy_interpolator_0.cons_kwargs == {}
    assert numpy_interpolator_0.call_kwargs == {'period': None}
    assert module_1.dask_array_type == ()
    list_1 = []
    var_0 = module_1.func_interpolate_na(numpy_interpolator_0, list_1, list_0)
    assert var_0 == ['int64', {(): (), 'int64': 'int64'}, (), ()]

Coverage: 29.655172413793103
Mutation Score: 0.0

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import numpy as np
import pandas as pd
import pytest
from xarray import DataArray, Variable
from xarray.core.missing import (
    NumpyInterpolator,
    ScipyInterpolator,
    SplineInterpolator,
    get_clean_interp_index,
    _get_nan_block_lengths,
    interp_na,
    func_interpolate_na,
    _get_interpolator,
    _get_valid_fill_mask,
    interp,
    interp_func,
)

def test_get_nan_block_lengths():
    data = DataArray([1, np.nan, np.nan, 4, np.nan, 6], dims="x")
    index = Variable("x", np.arange(len(data)))
    result = _get_nan_block_lengths(data, "x", index)
    expected = DataArray([0, 2, 2, 0, 1, 0], dims="x")
    assert result.equals(expected)

def test_numpy_interpolator_linear():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    interpolator = NumpyInterpolator(xi, yi)
    result = interpolator(np.array([0.5, 1.5]))
    expected = np.array([0.5, 2.5])
    np.testing.assert_array_almost_equal(result, expected)

def test_numpy_interpolator_invalid_method():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    with pytest.raises(ValueError, match="only method `linear` is valid for the NumpyInterpolator"):
        NumpyInterpolator(xi, yi, method="cubic")

def test_scipy_interpolator_linear():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    interpolator = ScipyInterpolator(xi, yi, method="linear")
    result = interpolator(np.array([0.5, 1.5]))
    expected = np.array([0.5, 2.5])
    np.testing.assert_array_almost_equal(result, expected)

def test_spline_interpolator():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    interpolator = SplineInterpolator(xi, yi)
    result = interpolator(np.array([0.5, 1.5]))
    assert result[0] < 1 and result[1] > 2  # Spline should be smooth

def test_get_clean_interp_index():
    arr = DataArray([1, 2, 3], dims="x", coords={"x": [0, 1, 2]})
    result = get_clean_interp_index(arr, "x", use_coordinate=True)
    expected = np.array([0, 1, 2], dtype=np.float64)
    np.testing.assert_array_equal(result, expected)

def test_get_clean_interp_index_non_monotonic():
    arr = DataArray([1, 2, 3], dims="x", coords={"x": [0, 2, 1]})
    with pytest.raises(ValueError, match="Index 'x' must be monotonically increasing"):
        get_clean_interp_index(arr, "x", use_coordinate=True)

def test_interp_na():
    arr = DataArray([1, np.nan, 3], dims="x")
    result = interp_na(arr, dim="x", method="linear")
    expected = DataArray([1, 2, 3], dims="x")
    assert result.equals(expected)

def test_func_interpolate_na():
    x = np.array([0, 1, 2])
    y = np.array([0, np.nan, 4])
    interpolator = NumpyInterpolator(x[~np.isnan(y)], y[~np.isnan(y)])
    result = func_interpolate_na(interpolator, x, y)
    expected = np.array([0, 2, 4])
    np.testing.assert_array_almost_equal(result, expected)

def test_get_interpolator():
    method = "linear"
    interp_class, kwargs = _get_interpolator(method)
    assert interp_class == NumpyInterpolator
    assert kwargs["method"] == method

def test_get_valid_fill_mask():
    arr = DataArray([1, np.nan, np.nan, 4], dims="x")
    result = _get_valid_fill_mask(arr, "x", limit=1)
    expected = DataArray([True, True, False, True], dims="x")
    assert result.equals(expected)

def test_interp():
    var = Variable(["x"], [1, np.nan, 3])
    indexes_coords = {"x": (Variable(["x"], [0, 1, 2]), Variable(["x"], [0, 0.5, 1, 1.5, 2]))}
    result = interp(var, indexes_coords, method="linear")
    expected = Variable(["x"], [1, 2, 3])
    np.testing.assert_array_almost_equal(result.data, expected.data)

def test_interp_func():
    var = np.array([1, np.nan, 3])
    x = [np.array([0, 1, 2])]
    new_x = [np.array([0, 0.5, 1, 1.5, 2])]
    result = interp_func(var, x, new_x, method="linear", kwargs={})
    expected = np.array([1, 2, 3])
    np.testing.assert_array_almost_equal(result, expected)

Coverage: 37.58620689655172
Mutation Score: 14.129999999999995

Approach:
Predicted Test Suite: import numpy as np
import pandas as pd
import pytest
from xarray import DataArray, Variable
from xarray.core.missing import (
    NumpyInterpolator,
    ScipyInterpolator,
    SplineInterpolator,
    get_clean_interp_index,
    _get_nan_block_lengths,
    interp_na,
    func_interpolate_na,
    _get_interpolator,
    _get_valid_fill_mask,
    interp,
    interp_func,
)

def test_get_nan_block_lengths():
    data = DataArray([1, np.nan, np.nan, 4, np.nan, 6], dims="x")
    index = Variable("x", np.arange(len(data)))
    with pytest.raises(ValueError):
        _get_nan_block_lengths(data, "x", index)

def test_numpy_interpolator_linear():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    interpolator = NumpyInterpolator(xi, yi)
    result = interpolator(np.array([0.5, 1.5]))
    expected = np.array([0.5, 2.5])
    np.testing.assert_array_almost_equal(result, expected)

def test_numpy_interpolator_invalid_method():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    with pytest.raises(ValueError, match="only method `linear` is valid for the NumpyInterpolator"):
        NumpyInterpolator(xi, yi, method="cubic")

def test_scipy_interpolator_linear():
    xi = np.array([0, 1, 2])
    yi = np.array([0, 1, 4])
    interpolator = ScipyInterpolator(xi, yi, method="linear")
    result = interpolator(np.array([0.5, 1.5]))
    expected = np.array([0.5, 2.5])
    np.testing.assert_array_almost_equal(result, expected)

def test_spline_interpolator():
    xi = np.array([0, 1, 2, 3])
    yi = np.array([0, 1, 4, 9])
    interpolator = SplineInterpolator(xi, yi)
    result = interpolator(np.array([0.5, 1.5, 2.5]))
    assert result[0] < 1 and result[1] > 2  # Spline should be smooth

def test_get_clean_interp_index():
    arr = DataArray([1, 2, 3], dims="x", coords={"x": [0, 1, 2]})
    result = get_clean_interp_index(arr, "x", use_coordinate=True)
    expected = np.array([0, 1, 2], dtype=np.float64)
    np.testing.assert_array_equal(result, expected)

def test_get_clean_interp_index_non_monotonic():
    arr = DataArray([1, 2, 3], dims="x", coords={"x": [0, 2, 1]})
    with pytest.raises(ValueError, match="Index 'x' must be monotonically increasing"):
        get_clean_interp_index(arr, "x", use_coordinate=True)

def test_interp_na():
    arr = DataArray([1, np.nan, 3], dims="x")
    result = interp_na(arr, dim="x", method="linear")
    expected = DataArray([1, 2, 3], dims="x")
    assert result.equals(expected)

def test_func_interpolate_na():
    x = np.array([0, 1, 2])
    y = np.array([0, np.nan, 4])
    interpolator = NumpyInterpolator(x[~np.isnan(y)], y[~np.isnan(y)])
    result = func_interpolate_na(interpolator, x, y, {})
    expected = np.array([0, 2, 4])
    np.testing.assert_array_almost_equal(result, expected)

def test_get_interpolator():
    method = "linear"
    interp_class, kwargs = _get_interpolator(method)
    assert interp_class == NumpyInterpolator
    assert kwargs["method"] == method

def test_get_valid_fill_mask():
    arr = DataArray([1, np.nan, np.nan, 4], dims="x")
    result = _get_valid_fill_mask(arr, "x", limit=1)
    expected = DataArray([True, True, False, True], dims="x")
    assert result.equals(expected)

def test_interp():
    var = Variable(["x"], [1, np.nan, 3])
    indexes_coords = {"x": (Variable(["x"], [0, 1, 2]), Variable(["x"], [0, 0.5, 1, 1.5, 2]))}
    result = interp(var, indexes_coords, method="linear")
    expected = Variable(["x"], [1, np.nan, 3])
    np.testing.assert_array_almost_equal(result.data, expected.data)

def test_interp_func():
    var = np.array([1, np.nan, 3])
    x = [np.array([0, 1, 2])]
    new_x = [np.array([0, 0.5, 1, 1.5, 2])]
    result = interp_func(var, x, new_x, method="linear", kwargs={})
    expected = np.array([1, np.nan, 3])
    np.testing.assert_array_almost_equal(result, expected)
Coverage: 43.44827586206897
Mutation Score: 16.480000000000004
Output: On branch main
Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        deleted:    .coveragerc

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_missing.py

no changes added to commit (use "git add" and/or "git commit -a")
commit 1dfb53592148168b030ec0073e665f2943a52f5c
Author: TestGenEval <>
Date:   Wed Dec 11 12:07:19 2024 +0000

    Testing fixes

diff --git a/doc/conf.py b/doc/conf.py
index 7c1557a1..0e04f8cc 100644
--- a/doc/conf.py
+++ b/doc/conf.py
@@ -340,9 +340,10 @@ texinfo_documents = [
 # Example configuration for intersphinx: refer to the Python standard library.
 intersphinx_mapping = {
     "python": ("https://docs.python.org/3/", None),
-    "pandas": ("https://pandas.pydata.org/pandas-docs/stable/", None),
-    "iris": ("http://scitools.org.uk/iris/docs/latest/", None),
-    "numpy": ("https://docs.scipy.org/doc/numpy/", None),
-    "numba": ("https://numba.pydata.org/numba-doc/latest/", None),
-    "matplotlib": ("https://matplotlib.org/", None),
+    "pandas": ("https://pandas.pydata.org/pandas-docs/stable", None),
+    "iris": ("https://scitools.org.uk/iris/docs/latest", None),
+    "numpy": ("https://docs.scipy.org/doc/numpy", None),
+    "scipy": ("https://docs.scipy.org/doc/scipy/reference", None),
+    "numba": ("https://numba.pydata.org/numba-doc/latest", None),
+    "matplotlib": ("https://matplotlib.org", None),
 }
diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py
index a192fe08..5d0d6b48 100644
--- a/xarray/core/dataarray.py
+++ b/xarray/core/dataarray.py
@@ -2018,44 +2018,69 @@ class DataArray(AbstractArray, DataWithCoords):

     def interpolate_na(
         self,
-        dim=None,
+        dim: Hashable = None,
         method: str = "linear",
         limit: int = None,
         use_coordinate: Union[bool, str] = True,
+        max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,
         **kwargs: Any,
     ) -> "DataArray":
-        """Interpolate values according to different methods.
+        """Fill in NaNs by interpolating according to different methods.

         Parameters
         ----------
         dim : str
             Specifies the dimension along which to interpolate.
-        method : {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',
-                  'polynomial', 'barycentric', 'krog', 'pchip',
-                  'spline', 'akima'}, optional
+        method : str, optional
             String indicating which method to use for interpolation:

             - 'linear': linear interpolation (Default). Additional keyword
-              arguments are passed to ``numpy.interp``
-            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',
-              'polynomial': are passed to ``scipy.interpolate.interp1d``. If
-              method=='polynomial', the ``order`` keyword argument must also be
+              arguments are passed to :py:func:`numpy.interp`
+            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'polynomial':
+              are passed to :py:func:`scipy.interpolate.interp1d`. If
+              ``method='polynomial'``, the ``order`` keyword argument must also be
               provided.
-            - 'barycentric', 'krog', 'pchip', 'spline', and `akima`: use their
-              respective``scipy.interpolate`` classes.
-        use_coordinate : boolean or str, default True
+            - 'barycentric', 'krog', 'pchip', 'spline', 'akima': use their
+              respective :py:class:`scipy.interpolate` classes.
+        use_coordinate : bool, str, default True
             Specifies which index to use as the x values in the interpolation
             formulated as `y = f(x)`. If False, values are treated as if
-            eqaully-spaced along `dim`. If True, the IndexVariable `dim` is
-            used. If use_coordinate is a string, it specifies the name of a
+            eqaully-spaced along ``dim``. If True, the IndexVariable `dim` is
+            used. If ``use_coordinate`` is a string, it specifies the name of a
             coordinate variariable to use as the index.
         limit : int, default None
             Maximum number of consecutive NaNs to fill. Must be greater than 0
-            or None for no limit.
+            or None for no limit. This filling is done regardless of the size of
+            the gap in the data. To only interpolate over gaps less than a given length,
+            see ``max_gap``.
+        max_gap: int, float, str, pandas.Timedelta, numpy.timedelta64, default None.
+            Maximum size of gap, a continuous sequence of NaNs, that will be filled.
+            Use None for no limit. When interpolating along a datetime64 dimension
+            and ``use_coordinate=True``, ``max_gap`` can be one of the following:
+
+            - a string that is valid input for pandas.to_timedelta
+            - a :py:class:`numpy.timedelta64` object
+            - a :py:class:`pandas.Timedelta` object
+            Otherwise, ``max_gap`` must be an int or a float. Use of ``max_gap`` with unlabeled
+            dimensions has not been implemented yet. Gap length is defined as the difference
+            between coordinate values at the first data point after a gap and the last value
+            before a gap. For gaps at the beginning (end), gap length is defined as the difference
+            between coordinate values at the first (last) valid data point and the first (last) NaN.
+            For example, consider::
+
+                <xarray.DataArray (x: 9)>
+                array([nan, nan, nan,  1., nan, nan,  4., nan, nan])
+                Coordinates:
+                  * x        (x) int64 0 1 2 3 4 5 6 7 8
+
+            The gap lengths are 3-0 = 3; 6-3 = 3; and 8-6 = 2 respectively
+        kwargs : dict, optional
+            parameters passed verbatim to the underlying interpolation function

         Returns
         -------
-        DataArray
+        interpolated: DataArray
+            Filled in DataArray.

         See also
         --------
@@ -2070,6 +2095,7 @@ class DataArray(AbstractArray, DataWithCoords):
             method=method,
             limit=limit,
             use_coordinate=use_coordinate,
+            max_gap=max_gap,
             **kwargs,
         )

diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py
index 15a7209a..5b337b70 100644
--- a/xarray/core/dataset.py
+++ b/xarray/core/dataset.py
@@ -3900,42 +3900,65 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):
         method: str = "linear",
         limit: int = None,
         use_coordinate: Union[bool, Hashable] = True,
+        max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,
         **kwargs: Any,
     ) -> "Dataset":
-        """Interpolate values according to different methods.
+        """Fill in NaNs by interpolating according to different methods.

         Parameters
         ----------
-        dim : Hashable
+        dim : str
             Specifies the dimension along which to interpolate.
-        method : {'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',
-                  'polynomial', 'barycentric', 'krog', 'pchip',
-                  'spline'}, optional
+        method : str, optional
             String indicating which method to use for interpolation:

             - 'linear': linear interpolation (Default). Additional keyword
-              arguments are passed to ``numpy.interp``
-            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',
-              'polynomial': are passed to ``scipy.interpolate.interp1d``. If
-              method=='polynomial', the ``order`` keyword argument must also be
+              arguments are passed to :py:func:`numpy.interp`
+            - 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'polynomial':
+              are passed to :py:func:`scipy.interpolate.interp1d`. If
+              ``method='polynomial'``, the ``order`` keyword argument must also be
               provided.
-            - 'barycentric', 'krog', 'pchip', 'spline': use their respective
-              ``scipy.interpolate`` classes.
-        use_coordinate : boolean or str, default True
+            - 'barycentric', 'krog', 'pchip', 'spline', 'akima': use their
+              respective :py:class:`scipy.interpolate` classes.
+        use_coordinate : bool, str, default True
             Specifies which index to use as the x values in the interpolation
             formulated as `y = f(x)`. If False, values are treated as if
-            eqaully-spaced along `dim`. If True, the IndexVariable `dim` is
-            used. If use_coordinate is a string, it specifies the name of a
+            eqaully-spaced along ``dim``. If True, the IndexVariable `dim` is
+            used. If ``use_coordinate`` is a string, it specifies the name of a
             coordinate variariable to use as the index.
         limit : int, default None
             Maximum number of consecutive NaNs to fill. Must be greater than 0
-            or None for no limit.
-        kwargs : any
-            parameters passed verbatim to the underlying interplation function
+            or None for no limit. This filling is done regardless of the size of
+            the gap in the data. To only interpolate over gaps less than a given length,
+            see ``max_gap``.
+        max_gap: int, float, str, pandas.Timedelta, numpy.timedelta64, default None.
+            Maximum size of gap, a continuous sequence of NaNs, that will be filled.
+            Use None for no limit. When interpolating along a datetime64 dimension
+            and ``use_coordinate=True``, ``max_gap`` can be one of the following:
+
+            - a string that is valid input for pandas.to_timedelta
+            - a :py:class:`numpy.timedelta64` object
+            - a :py:class:`pandas.Timedelta` object
+            Otherwise, ``max_gap`` must be an int or a float. Use of ``max_gap`` with unlabeled
+            dimensions has not been implemented yet. Gap length is defined as the difference
+            between coordinate values at the first data point after a gap and the last value
+            before a gap. For gaps at the beginning (end), gap length is defined as the difference
+            between coordinate values at the first (last) valid data point and the first (last) NaN.
+            For example, consider::
+
+                <xarray.DataArray (x: 9)>
+                array([nan, nan, nan,  1., nan, nan,  4., nan, nan])
+                Coordinates:
+                  * x        (x) int64 0 1 2 3 4 5 6 7 8
+
+            The gap lengths are 3-0 = 3; 6-3 = 3; and 8-6 = 2 respectively
+        kwargs : dict, optional
+            parameters passed verbatim to the underlying interpolation function

         Returns
         -------
-        Dataset
+        interpolated: Dataset
+            Filled in Dataset.

         See also
         --------
@@ -3951,6 +3974,7 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):
             method=method,
             limit=limit,
             use_coordinate=use_coordinate,
+            max_gap=max_gap,
             **kwargs,
         )
         return new
diff --git a/xarray/core/missing.py b/xarray/core/missing.py
index 77dde664..117fcaf8 100644
--- a/xarray/core/missing.py
+++ b/xarray/core/missing.py
@@ -1,18 +1,46 @@
 import warnings
 from functools import partial
-from typing import Any, Callable, Dict, Sequence
+from numbers import Number
+from typing import Any, Callable, Dict, Hashable, Sequence, Union

 import numpy as np
 import pandas as pd

 from . import utils
-from .common import _contains_datetime_like_objects
+from .common import _contains_datetime_like_objects, ones_like
 from .computation import apply_ufunc
 from .duck_array_ops import dask_array_type
 from .utils import OrderedSet, is_scalar
 from .variable import Variable, broadcast_variables


+def _get_nan_block_lengths(obj, dim: Hashable, index: Variable):
+    """
+    Return an object where each NaN element in 'obj' is replaced by the
+    length of the gap the element is in.
+    """
+
+    # make variable so that we get broadcasting for free
+    index = Variable([dim], index)
+
+    # algorithm from https://github.com/pydata/xarray/pull/3302#discussion_r324707072
+    arange = ones_like(obj) * index
+    valid = obj.notnull()
+    valid_arange = arange.where(valid)
+    cumulative_nans = valid_arange.ffill(dim=dim).fillna(index[0])
+
+    nan_block_lengths = (
+        cumulative_nans.diff(dim=dim, label="upper")
+        .reindex({dim: obj[dim]})
+        .where(valid)
+        .bfill(dim=dim)
+        .where(~valid, 0)
+        .fillna(index[-1] - valid_arange.max())
+    )
+
+    return nan_block_lengths
+
+
 class BaseInterpolator:
     """Generic interpolator class for normalizing interpolation methods
     """
@@ -178,7 +206,7 @@ def _apply_over_vars_with_dim(func, self, dim=None, **kwargs):
     return ds


-def get_clean_interp_index(arr, dim, use_coordinate=True):
+def get_clean_interp_index(arr, dim: Hashable, use_coordinate: Union[str, bool] = True):
     """get index to use for x values in interpolation.

     If use_coordinate is True, the coordinate that shares the name of the
@@ -195,23 +223,33 @@ def get_clean_interp_index(arr, dim, use_coordinate=True):
             index = arr.coords[use_coordinate]
             if index.ndim != 1:
                 raise ValueError(
-                    "Coordinates used for interpolation must be 1D, "
-                    "%s is %dD." % (use_coordinate, index.ndim)
+                    f"Coordinates used for interpolation must be 1D, "
+                    f"{use_coordinate} is {index.ndim}D."
                 )
+            index = index.to_index()
+
+        # TODO: index.name is None for multiindexes
+        # set name for nice error messages below
+        if isinstance(index, pd.MultiIndex):
+            index.name = dim
+
+        if not index.is_monotonic:
+            raise ValueError(f"Index {index.name!r} must be monotonically increasing")
+
+        if not index.is_unique:
+            raise ValueError(f"Index {index.name!r} has duplicate values")

         # raise if index cannot be cast to a float (e.g. MultiIndex)
         try:
             index = index.values.astype(np.float64)
         except (TypeError, ValueError):
             # pandas raises a TypeError
-            # xarray/nuppy raise a ValueError
+            # xarray/numpy raise a ValueError
             raise TypeError(
-                "Index must be castable to float64 to support"
-                "interpolation, got: %s" % type(index)
+                f"Index {index.name!r} must be castable to float64 to support "
+                f"interpolation, got {type(index).__name__}."
             )
-        # check index sorting now so we can skip it later
-        if not (np.diff(index) > 0).all():
-            raise ValueError("Index must be monotonicly increasing")
+
     else:
         axis = arr.get_axis_num(dim)
         index = np.arange(arr.shape[axis], dtype=np.float64)
@@ -220,7 +258,13 @@ def get_clean_interp_index(arr, dim, use_coordinate=True):


 def interp_na(
-    self, dim=None, use_coordinate=True, method="linear", limit=None, **kwargs
+    self,
+    dim: Hashable = None,
+    use_coordinate: Union[bool, str] = True,
+    method: str = "linear",
+    limit: int = None,
+    max_gap: Union[int, float, str, pd.Timedelta, np.timedelta64] = None,
+    **kwargs,
 ):
     """Interpolate values according to different methods.
     """
@@ -230,6 +274,40 @@ def interp_na(
     if limit is not None:
         valids = _get_valid_fill_mask(self, dim, limit)

+    if max_gap is not None:
+        max_type = type(max_gap).__name__
+        if not is_scalar(max_gap):
+            raise ValueError("max_gap must be a scalar.")
+
+        if (
+            dim in self.indexes
+            and isinstance(self.indexes[dim], pd.DatetimeIndex)
+            and use_coordinate
+        ):
+            if not isinstance(max_gap, (np.timedelta64, pd.Timedelta, str)):
+                raise TypeError(
+                    f"Underlying index is DatetimeIndex. Expected max_gap of type str, pandas.Timedelta or numpy.timedelta64 but received {max_type}"
+                )
+
+            if isinstance(max_gap, str):
+                try:
+                    max_gap = pd.to_timedelta(max_gap)
+                except ValueError:
+                    raise ValueError(
+                        f"Could not convert {max_gap!r} to timedelta64 using pandas.to_timedelta"
+                    )
+
+            if isinstance(max_gap, pd.Timedelta):
+                max_gap = np.timedelta64(max_gap.value, "ns")
+
+            max_gap = np.timedelta64(max_gap, "ns").astype(np.float64)
+
+        if not use_coordinate:
+            if not isinstance(max_gap, (Number, np.number)):
+                raise TypeError(
+                    f"Expected integer or floating point max_gap since use_coordinate=False. Received {max_type}."
+                )
+
     # method
     index = get_clean_interp_index(self, dim, use_coordinate=use_coordinate)
     interp_class, kwargs = _get_interpolator(method, **kwargs)
@@ -253,6 +331,14 @@ def interp_na(
     if limit is not None:
         arr = arr.where(valids)

+    if max_gap is not None:
+        if dim not in self.coords:
+            raise NotImplementedError(
+                "max_gap not implemented for unlabeled coordinates yet."
+            )
+        nan_block_lengths = _get_nan_block_lengths(self, dim, index)
+        arr = arr.where(nan_block_lengths <= max_gap)
+
     return arr


diff --git a/xarray/tests/test_missing.py b/xarray/tests/test_missing.py
deleted file mode 100644
index cfce5d6f..00000000
--- a/xarray/tests/test_missing.py
+++ /dev/null
@@ -1,441 +0,0 @@
-import itertools
-
-import numpy as np
-import pandas as pd
-import pytest
-
-import xarray as xr
-from xarray.core.missing import NumpyInterpolator, ScipyInterpolator, SplineInterpolator
-from xarray.core.pycompat import dask_array_type
-from xarray.tests import (
-    assert_array_equal,
-    assert_equal,
-    raises_regex,
-    requires_bottleneck,
-    requires_dask,
-    requires_scipy,
-)
-
-
-@pytest.fixture
-def da():
-    return xr.DataArray([0, np.nan, 1, 2, np.nan, 3, 4, 5, np.nan, 6, 7], dims="time")
-
-
-@pytest.fixture
-def ds():
-    ds = xr.Dataset()
-    ds["var1"] = xr.DataArray(
-        [0, np.nan, 1, 2, np.nan, 3, 4, 5, np.nan, 6, 7], dims="time"
-    )
-    ds["var2"] = xr.DataArray(
-        [10, np.nan, 11, 12, np.nan, 13, 14, 15, np.nan, 16, 17], dims="x"
-    )
-    return ds
-
-
-def make_interpolate_example_data(shape, frac_nan, seed=12345, non_uniform=False):
-    rs = np.random.RandomState(seed)
-    vals = rs.normal(size=shape)
-    if frac_nan == 1:
-        vals[:] = np.nan
-    elif frac_nan == 0:
-        pass
-    else:
-        n_missing = int(vals.size * frac_nan)
-
-        ys = np.arange(shape[0])
-        xs = np.arange(shape[1])
-        if n_missing:
-            np.random.shuffle(ys)
-            ys = ys[:n_missing]
-
-            np.random.shuffle(xs)
-            xs = xs[:n_missing]
-
-            vals[ys, xs] = np.nan
-
-    if non_uniform:
-        # construct a datetime index that has irregular spacing
-        deltas = pd.TimedeltaIndex(unit="d", data=rs.normal(size=shape[0], scale=10))
-        coords = {"time": (pd.Timestamp("2000-01-01") + deltas).sort_values()}
-    else:
-        coords = {"time": pd.date_range("2000-01-01", freq="D", periods=shape[0])}
-    da = xr.DataArray(vals, dims=("time", "x"), coords=coords)
-    df = da.to_pandas()
-
-    return da, df
-
-
-@requires_scipy
-def test_interpolate_pd_compat():
-    shapes = [(8, 8), (1, 20), (20, 1), (100, 100)]
-    frac_nans = [0, 0.5, 1]
-    methods = ["linear", "nearest", "zero", "slinear", "quadratic", "cubic"]
-
-    for (shape, frac_nan, method) in itertools.product(shapes, frac_nans, methods):
-
-        da, df = make_interpolate_example_data(shape, frac_nan)
-
-        for dim in ["time", "x"]:
-            actual = da.interpolate_na(method=method, dim=dim, fill_value=np.nan)
-            expected = df.interpolate(
-                method=method, axis=da.get_axis_num(dim), fill_value=(np.nan, np.nan)
-            )
-            # Note, Pandas does some odd things with the left/right fill_value
-            # for the linear methods. This next line inforces the xarray
-            # fill_value convention on the pandas output. Therefore, this test
-            # only checks that interpolated values are the same (not nans)
-            expected.values[pd.isnull(actual.values)] = np.nan
-
-            np.testing.assert_allclose(actual.values, expected.values)
-
-
-@requires_scipy
-@pytest.mark.parametrize("method", ["barycentric", "krog", "pchip", "spline", "akima"])
-def test_scipy_methods_function(method):
-    # Note: Pandas does some wacky things with these methods and the full
-    # integration tests wont work.
-    da, _ = make_interpolate_example_data((25, 25), 0.4, non_uniform=True)
-    actual = da.interpolate_na(method=method, dim="time")
-    assert (da.count("time") <= actual.count("time")).all()
-
-
-@requires_scipy
-def test_interpolate_pd_compat_non_uniform_index():
-    shapes = [(8, 8), (1, 20), (20, 1), (100, 100)]
-    frac_nans = [0, 0.5, 1]
-    methods = ["time", "index", "values"]
-
-    for (shape, frac_nan, method) in itertools.product(shapes, frac_nans, methods):
-
-        da, df = make_interpolate_example_data(shape, frac_nan, non_uniform=True)
-        for dim in ["time", "x"]:
-            if method == "time" and dim != "time":
-                continue
-            actual = da.interpolate_na(
-                method="linear", dim=dim, use_coordinate=True, fill_value=np.nan
-            )
-            expected = df.interpolate(
-                method=method, axis=da.get_axis_num(dim), fill_value=np.nan
-            )
-
-            # Note, Pandas does some odd things with the left/right fill_value
-            # for the linear methods. This next line inforces the xarray
-            # fill_value convention on the pandas output. Therefore, this test
-            # only checks that interpolated values are the same (not nans)
-            expected.values[pd.isnull(actual.values)] = np.nan
-
-            np.testing.assert_allclose(actual.values, expected.values)
-
-
-@requires_scipy
-def test_interpolate_pd_compat_polynomial():
-    shapes = [(8, 8), (1, 20), (20, 1), (100, 100)]
-    frac_nans = [0, 0.5, 1]
-    orders = [1, 2, 3]
-
-    for (shape, frac_nan, order) in itertools.product(shapes, frac_nans, orders):
-
-        da, df = make_interpolate_example_data(shape, frac_nan)
-
-        for dim in ["time", "x"]:
-            actual = da.interpolate_na(
-                method="polynomial", order=order, dim=dim, use_coordinate=False
-            )
-            expected = df.interpolate(
-                method="polynomial", order=order, axis=da.get_axis_num(dim)
-            )
-            np.testing.assert_allclose(actual.values, expected.values)
-
-
-@requires_scipy
-def test_interpolate_unsorted_index_raises():
-    vals = np.array([1, 2, 3], dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x", coords={"x": [2, 1, 3]})
-    with raises_regex(ValueError, "Index must be monotonicly increasing"):
-        expected.interpolate_na(dim="x", method="index")
-
-
-def test_interpolate_no_dim_raises():
-    da = xr.DataArray(np.array([1, 2, np.nan, 5], dtype=np.float64), dims="x")
-    with raises_regex(NotImplementedError, "dim is a required argument"):
-        da.interpolate_na(method="linear")
-
-
-def test_interpolate_invalid_interpolator_raises():
-    da = xr.DataArray(np.array([1, 2, np.nan, 5], dtype=np.float64), dims="x")
-    with raises_regex(ValueError, "not a valid"):
-        da.interpolate_na(dim="x", method="foo")
-
-
-def test_interpolate_multiindex_raises():
-    data = np.random.randn(2, 3)
-    data[1, 1] = np.nan
-    da = xr.DataArray(data, coords=[("x", ["a", "b"]), ("y", [0, 1, 2])])
-    das = da.stack(z=("x", "y"))
-    with raises_regex(TypeError, "Index must be castable to float64"):
-        das.interpolate_na(dim="z")
-
-
-def test_interpolate_2d_coord_raises():
-    coords = {
-        "x": xr.Variable(("a", "b"), np.arange(6).reshape(2, 3)),
-        "y": xr.Variable(("a", "b"), np.arange(6).reshape(2, 3)) * 2,
-    }
-
-    data = np.random.randn(2, 3)
-    data[1, 1] = np.nan
-    da = xr.DataArray(data, dims=("a", "b"), coords=coords)
-    with raises_regex(ValueError, "interpolation must be 1D"):
-        da.interpolate_na(dim="a", use_coordinate="x")
-
-
-@requires_scipy
-def test_interpolate_kwargs():
-    da = xr.DataArray(np.array([4, 5, np.nan], dtype=np.float64), dims="x")
-    expected = xr.DataArray(np.array([4, 5, 6], dtype=np.float64), dims="x")
-    actual = da.interpolate_na(dim="x", fill_value="extrapolate")
-    assert_equal(actual, expected)
-
-    expected = xr.DataArray(np.array([4, 5, -999], dtype=np.float64), dims="x")
-    actual = da.interpolate_na(dim="x", fill_value=-999)
-    assert_equal(actual, expected)
-
-
-def test_interpolate():
-
-    vals = np.array([1, 2, 3, 4, 5, 6], dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x")
-    mvals = vals.copy()
-    mvals[2] = np.nan
-    missing = xr.DataArray(mvals, dims="x")
-
-    actual = missing.interpolate_na(dim="x")
-
-    assert_equal(actual, expected)
-
-
-def test_interpolate_nonans():
-
-    vals = np.array([1, 2, 3, 4, 5, 6], dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x")
-    actual = expected.interpolate_na(dim="x")
-    assert_equal(actual, expected)
-
-
-@requires_scipy
-def test_interpolate_allnans():
-    vals = np.full(6, np.nan, dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x")
-    actual = expected.interpolate_na(dim="x")
-
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-def test_interpolate_limits():
-    da = xr.DataArray(
-        np.array([1, 2, np.nan, np.nan, np.nan, 6], dtype=np.float64), dims="x"
-    )
-
-    actual = da.interpolate_na(dim="x", limit=None)
-    assert actual.isnull().sum() == 0
-
-    actual = da.interpolate_na(dim="x", limit=2)
-    expected = xr.DataArray(
-        np.array([1, 2, 3, 4, np.nan, 6], dtype=np.float64), dims="x"
-    )
-
-    assert_equal(actual, expected)
-
-
-@requires_scipy
-def test_interpolate_methods():
-    for method in ["linear", "nearest", "zero", "slinear", "quadratic", "cubic"]:
-        kwargs = {}
-        da = xr.DataArray(
-            np.array([0, 1, 2, np.nan, np.nan, np.nan, 6, 7, 8], dtype=np.float64),
-            dims="x",
-        )
-        actual = da.interpolate_na("x", method=method, **kwargs)
-        assert actual.isnull().sum() == 0
-
-        actual = da.interpolate_na("x", method=method, limit=2, **kwargs)
-        assert actual.isnull().sum() == 1
-
-
-@requires_scipy
-def test_interpolators():
-    for method, interpolator in [
-        ("linear", NumpyInterpolator),
-        ("linear", ScipyInterpolator),
-        ("spline", SplineInterpolator),
-    ]:
-        xi = np.array([-1, 0, 1, 2, 5], dtype=np.float64)
-        yi = np.array([-10, 0, 10, 20, 50], dtype=np.float64)
-        x = np.array([3, 4], dtype=np.float64)
-
-        f = interpolator(xi, yi, method=method)
-        out = f(x)
-        assert pd.isnull(out).sum() == 0
-
-
-def test_interpolate_use_coordinate():
-    xc = xr.Variable("x", [100, 200, 300, 400, 500, 600])
-    da = xr.DataArray(
-        np.array([1, 2, np.nan, np.nan, np.nan, 6], dtype=np.float64),
-        dims="x",
-        coords={"xc": xc},
-    )
-
-    # use_coordinate == False is same as using the default index
-    actual = da.interpolate_na(dim="x", use_coordinate=False)
-    expected = da.interpolate_na(dim="x")
-    assert_equal(actual, expected)
-
-    # possible to specify non index coordinate
-    actual = da.interpolate_na(dim="x", use_coordinate="xc")
-    expected = da.interpolate_na(dim="x")
-    assert_equal(actual, expected)
-
-    # possible to specify index coordinate by name
-    actual = da.interpolate_na(dim="x", use_coordinate="x")
-    expected = da.interpolate_na(dim="x")
-    assert_equal(actual, expected)
-
-
-@requires_dask
-def test_interpolate_dask():
-    da, _ = make_interpolate_example_data((40, 40), 0.5)
-    da = da.chunk({"x": 5})
-    actual = da.interpolate_na("time")
-    expected = da.load().interpolate_na("time")
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual.compute(), expected)
-
-    # with limit
-    da = da.chunk({"x": 5})
-    actual = da.interpolate_na("time", limit=3)
-    expected = da.load().interpolate_na("time", limit=3)
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual, expected)
-
-
-@requires_dask
-def test_interpolate_dask_raises_for_invalid_chunk_dim():
-    da, _ = make_interpolate_example_data((40, 40), 0.5)
-    da = da.chunk({"time": 5})
-    with raises_regex(ValueError, "dask='parallelized' consists of multiple"):
-        da.interpolate_na("time")
-
-
-@requires_bottleneck
-def test_ffill():
-    da = xr.DataArray(np.array([4, 5, np.nan], dtype=np.float64), dims="x")
-    expected = xr.DataArray(np.array([4, 5, 5], dtype=np.float64), dims="x")
-    actual = da.ffill("x")
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-@requires_dask
-def test_ffill_dask():
-    da, _ = make_interpolate_example_data((40, 40), 0.5)
-    da = da.chunk({"x": 5})
-    actual = da.ffill("time")
-    expected = da.load().ffill("time")
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual, expected)
-
-    # with limit
-    da = da.chunk({"x": 5})
-    actual = da.ffill("time", limit=3)
-    expected = da.load().ffill("time", limit=3)
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-@requires_dask
-def test_bfill_dask():
-    da, _ = make_interpolate_example_data((40, 40), 0.5)
-    da = da.chunk({"x": 5})
-    actual = da.bfill("time")
-    expected = da.load().bfill("time")
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual, expected)
-
-    # with limit
-    da = da.chunk({"x": 5})
-    actual = da.bfill("time", limit=3)
-    expected = da.load().bfill("time", limit=3)
-    assert isinstance(actual.data, dask_array_type)
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-def test_ffill_bfill_nonans():
-
-    vals = np.array([1, 2, 3, 4, 5, 6], dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x")
-
-    actual = expected.ffill(dim="x")
-    assert_equal(actual, expected)
-
-    actual = expected.bfill(dim="x")
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-def test_ffill_bfill_allnans():
-
-    vals = np.full(6, np.nan, dtype=np.float64)
-    expected = xr.DataArray(vals, dims="x")
-
-    actual = expected.ffill(dim="x")
-    assert_equal(actual, expected)
-
-    actual = expected.bfill(dim="x")
-    assert_equal(actual, expected)
-
-
-@requires_bottleneck
-def test_ffill_functions(da):
-    result = da.ffill("time")
-    assert result.isnull().sum() == 0
-
-
-@requires_bottleneck
-def test_ffill_limit():
-    da = xr.DataArray(
-        [0, np.nan, np.nan, np.nan, np.nan, 3, 4, 5, np.nan, 6, 7], dims="time"
-    )
-    result = da.ffill("time")
-    expected = xr.DataArray([0, 0, 0, 0, 0, 3, 4, 5, 5, 6, 7], dims="time")
-    assert_array_equal(result, expected)
-
-    result = da.ffill("time", limit=1)
-    expected = xr.DataArray(
-        [0, 0, np.nan, np.nan, np.nan, 3, 4, 5, 5, 6, 7], dims="time"
-    )
-    assert_array_equal(result, expected)
-
-
-def test_interpolate_dataset(ds):
-    actual = ds.interpolate_na(dim="time")
-    # no missing values in var1
-    assert actual["var1"].count("time") == actual.dims["time"]
-
-    # var2 should be the same as it was
-    assert_array_equal(actual["var2"], ds["var2"])
-
-
-@requires_bottleneck
-def test_ffill_dataset(ds):
-    ds.ffill(dim="time")
-
-
-@requires_bottleneck
-def test_bfill_dataset(ds):
-    ds.ffill(dim="time")
Obtaining file:///testbed
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: numpy>=1.14 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.14.0+58.g1dfb5359.dirty) (1.23.0)
Requirement already satisfied: pandas>=0.24 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.14.0+58.g1dfb5359.dirty) (1.5.3)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.24->xarray==0.14.0+58.g1dfb5359.dirty) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=0.24->xarray==0.14.0+58.g1dfb5359.dirty) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.24->xarray==0.14.0+58.g1dfb5359.dirty) (1.16.0)
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.14.0+58.g1dfb5359
    Uninstalling xarray-0.14.0+58.g1dfb5359:
      Successfully uninstalled xarray-0.14.0+58.g1dfb5359
  DEPRECATION: Legacy editable install of xarray==0.14.0+58.g1dfb5359.dirty from file:///testbed (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457
  Running setup.py develop for xarray
Successfully installed xarray
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, xdist-3.6.1
collected 10 items

xarray/tests/test_missing.py ..........                                  [100%]

=============================== warnings summary ===============================
xarray/core/formatting_html.py:2
  /testbed/xarray/core/formatting_html.py:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    import pkg_resources

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

xarray/core/pdcompat.py:45
  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) < "0.25.0":

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

xarray/core/dask_array_compat.py:7
xarray/core/dask_array_compat.py:7
  /testbed/xarray/core/dask_array_compat.py:7: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) >= LooseVersion("2.0.0"):

xarray/tests/test_missing.py::test_get_clean_interp_index
xarray/tests/test_missing.py::test_get_clean_interp_index_non_monotonic
xarray/tests/test_missing.py::test_interp_na
  /testbed/xarray/core/missing.py:236: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.
    if not index.is_monotonic:

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_missing.py::test_get_nan_block_lengths
PASSED xarray/tests/test_missing.py::test_numpy_interpolator_linear
PASSED xarray/tests/test_missing.py::test_numpy_interpolator_invalid_method
PASSED xarray/tests/test_missing.py::test_scipy_interpolator_linear
PASSED xarray/tests/test_missing.py::test_spline_interpolator
PASSED xarray/tests/test_missing.py::test_get_clean_interp_index
PASSED xarray/tests/test_missing.py::test_get_clean_interp_index_non_monotonic
PASSED xarray/tests/test_missing.py::test_interp_na
PASSED xarray/tests/test_missing.py::test_get_interpolator
PASSED xarray/tests/test_missing.py::test_get_valid_fill_mask
======================= 10 passed, 15 warnings in 3.42s ========================

