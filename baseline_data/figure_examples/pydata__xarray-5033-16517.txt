Instance ID: pydata__xarray-5033-16517

Baseline 1 (Pynguin):
Predicted Test Suite: 
Coverage: -1
Mutation Score: -1

Baseline 2 (CodaMosa):
Predicted Test Suite: import builtins as module_3
import datetime as module_1
import numbers as module_5
import numpy as module_2
import pathlib as module_4
import xarray.backends.api as module_0
import xarray.core.dataset as module_1
import xarray.core.dataset as module_6

def test_case_1():
    pass


def test_case_2():
    list_0 = []
    list_1 = [list_0]
    dict_0 = {}
    str_0 = 'by_ycoords'
    sequence_0 = None
    dict_1 = {str_0: sequence_0, str_0: sequence_0, str_0: sequence_0}
    var_0 = module_0.open_mfdataset(list_1, dict_0, dict_1)
    assert len(var_0) == 0
    assert module_0.TYPE_CHECKING is False
    assert module_0.DATAARRAY_NAME == '__xarray_dataarray_name__'
    assert module_0.DATAARRAY_VARIABLE == '__xarray_dataarray_variable__'
    assert len(module_0.ENGINES) == 8
    assert len(module_0.WRITEABLE_STORES) == 3
    assert module_1.Dataset.load_store is not None
    assert module_1.Dataset.from_dataframe is not None
    assert module_1.Dataset.from_dict is not None
    assert module_1.Dataset.plot is not None# Automatically generated by Pynguin.


def test_case_3():
    try:
        str_0 = '^'
        int_0 = -4249
        var_0 = module_0.to_netcdf(str_0, str_0, int_0, int_0)
    except BaseException:
        pass


def test_case_4():
    try:
        timedelta_0 = module_1.timedelta()
        var_0 = module_0.to_netcdf(timedelta_0)
    except BaseException:
        pass


def test_case_5():
    try:
        str_0 = 'H:._a6'
        dict_0 = {str_0: str_0}
        var_0 = module_0.load_dataset(dict_0)
    except BaseException:
        pass


def test_case_6():
    try:
        bool_0 = True
        var_0 = module_0.load_dataarray(bool_0)
    except BaseException:
        pass


def test_case_7():
    try:
        bytes_0 = b'\n7\x9f'
        var_0 = module_0.open_mfdataset(bytes_0)
    except BaseException:
        pass


def test_case_8():
    try:
        dict_0 = None
        list_0 = []
        list_1 = [list_0]
        float_0 = None
        list_2 = [float_0]
        str_0 = 'RwfQ]qgDcp6G:I>'
        dict_1 = {str_0: list_2, str_0: list_0, str_0: list_1, str_0: list_0}
        var_0 = module_0.open_dataarray(dict_0, *list_0, chunks=list_0, use_cftime=list_1, backend_kwargs=list_2, **dict_1)
    except BaseException:
        pass


def test_case_9():
    try:
        int_0 = -805
        var_0 = module_0.to_netcdf(int_0, int_0)
    except BaseException:
        pass


def test_case_10():
    try:
        timedelta64_0 = module_2.timedelta64()
        bool_0 = True
        object_0 = module_3.object()
        float_0 = 965.404
        dict_0 = {object_0: float_0}
        var_0 = module_0.dump_to_store(bool_0, object_0, dict_0)
    except BaseException:
        pass


def test_case_11():
    try:
        str_0 = ' $A/qz)8,bm;j8'
        var_0 = None
        str_1 = 'jv\x0cM2'
        sequence_0 = None
        dict_0 = {str_0: sequence_0, str_0: sequence_0, str_0: sequence_0}
        str_2 = '_all_output_core_dims'
        dict_1 = {str_0: var_0, str_1: dict_0, str_1: str_2}
        object_0 = module_3.object()
        dict_2 = None
        var_1 = module_0.dump_to_store(dict_1, object_0, dict_2, dict_1)
    except BaseException:
        pass


def test_case_12():
    try:
        dict_0 = {}
        var_0 = module_0.save_mfdataset(dict_0, dict_0, dict_0)
    except BaseException:
        pass


def test_case_13():
    try:
        dict_0 = {}
        path_0 = module_4.Path()
        bytes_0 = b'\xfa\x8bB\xb6y\xbb\x10@U=\x86'
        str_0 = '\nX(v1^2<J'
        str_1 = None
        sequence_0 = None
        str_2 = '>:qSeE\nkJ7Nf'
        str_3 = '\r>)}\x0bLYD'
        sequence_1 = None
        dict_1 = {str_0: dict_0, str_1: sequence_0, str_2: sequence_0, str_3: sequence_1}
        iterator_0 = None
        var_0 = module_0.open_dataarray(path_0, cache=bytes_0, use_cftime=dict_1, decode_coords=iterator_0)
    except BaseException:
        pass


def test_case_14():
    try:
        list_0 = []
        bytes_0 = b'&\xcf\xd9\xbe\xcd\x85\xc6Nsdx'
        str_0 = '\nopuNr0fhlsuQ]\\_'
        bool_0 = None
        float_0 = -1046.95499
        str_1 = 'rAj,9>'
        dict_0 = {str_0: bytes_0, str_0: float_0, str_1: list_0}
        path_0 = module_4.Path(**dict_0)
        var_0 = module_0.dump_to_store(bytes_0, str_0, bool_0, float_0, path_0)
    except BaseException:
        pass


def test_case_15():
    try:
        bool_0 = True
        set_0 = set()
        tuple_0 = (bool_0, bool_0, set_0)
        timedelta_0 = module_1.timedelta()
        list_0 = [tuple_0, bool_0, set_0]
        timedelta64_0 = module_2.timedelta64()
        float_0 = -1560.4
        str_0 = 'lRkG'
        dict_0 = {str_0: list_0, str_0: tuple_0, str_0: timedelta64_0, str_0: tuple_0}
        var_0 = module_0.open_dataarray(timedelta_0, *list_0, decode_timedelta=timedelta64_0, concat_characters=float_0, backend_kwargs=list_0, **dict_0)
    except BaseException:
        pass


def test_case_16():
    try:
        bytes_0 = b'\xc5\x9d\r\xb0\x13\xf0-\xd1**\xdf\x9db]\x9e\xedg\x8e'
        str_0 = '[\nK<'
        var_0 = module_0.save_mfdataset(bytes_0, str_0)
    except BaseException:
        pass


def test_case_17():
    try:
        dataset_0 = None
        var_0 = module_0.to_zarr(dataset_0)
    except BaseException:
        pass


def test_case_18():
    try:
        dataset_0 = None
        int_0 = 1
        str_0 = 'o7iv'
        var_0 = module_0.to_zarr(dataset_0, int_0, str_0)
    except BaseException:
        pass


def test_case_19():
    try:
        str_0 = '6!=tM$9z<9CO='
        dataset_0 = None
        bool_0 = True
        var_0 = module_0.to_zarr(dataset_0, str_0, bool_0, bool_0)
    except BaseException:
        pass


def test_case_20():
    try:
        number_0 = module_5.Number()
        int_0 = -1581
        dict_0 = {}
        int_1 = 0
        dataset_0 = module_6.Dataset()
        dataset_1 = dataset_0.tail(int_1)
        dataset_2 = dataset_1.compute()
        dataset_3 = dataset_2.map(int_0, **dict_0)
        str_0 = 'R@V\t!,9R0+>g^!#,l'
        bool_0 = None
        str_1 = 'g+!N9:oEw{'
        var_0 = module_0.to_zarr(dataset_3, str_0, number_0, str_0, bool_0, dict_0, str_1)
    except BaseException:
        pass


def test_case_21():
    try:
        str_0 = '6!=tM$9z<9CO='
        list_0 = [str_0, str_0, str_0]
        bytes_0 = b'\xf6K[\x85K\xcc\xba\xbd)\xa0\xaa\xfaH\xf5r\x8c\xa6\xf6'
        var_0 = module_0.open_mfdataset(list_0, bytes_0, str_0)
    except BaseException:
        pass


def test_case_22():
    try:
        tuple_0 = ()
        var_0 = module_0.open_mfdataset(tuple_0)
    except BaseException:
        pass


def test_case_23():
    try:
        str_0 = 'j&h,'
        dict_0 = {}
        var_0 = module_0.open_mfdataset(str_0, dict_0)
    except BaseException:
        pass


def test_case_24():
    try:
        bool_0 = True
        str_0 = None
        str_1 = 'sMuj=Vb`MF4~B?[#4#'
        dict_0 = {str_1: str_1}
        str_2 = 'libnetcdf'
        str_3 = None
        dict_1 = None
        dict_2 = {str_3: dict_1}
        dict_3 = {str_2: dict_2}
        str_4 = 'T-_:f'
        str_5 = '`u&'
        hashable_0 = None
        dict_4 = {str_0: dict_0, str_1: dict_3, str_4: bool_0, str_5: hashable_0}
        bytes_0 = b'-\x0b\x1d#\x9b\x7f\xe0>I\xe8\x9b\x01\xad'
        str_6 = 'wUy,'
        bool_1 = True
        var_0 = module_0.open_dataarray(bool_0, engine=dict_4, decode_cf=bytes_0, use_cftime=str_6, decode_coords=bool_1)
    except BaseException:
        pass


def test_case_25():
    try:
        str_0 = ':Zf9%-Fn<567z<'
        list_0 = [str_0, str_0, str_0]
        bytes_0 = b'\xf6K[\x85K\xcc\xba\xbd)\xa0\xaa\xda\xfaH\xf5r\xa6\xf6'
        float_0 = 0.9
        dict_0 = None
        bool_0 = True
        dict_1 = {bytes_0: dict_0, bytes_0: float_0, bytes_0: bool_0}
        dict_2 = {dict_0: dict_1}
        list_1 = None
        var_0 = module_0.open_dataset(float_0, *list_0, engine=dict_0, chunks=bool_0, cache=dict_2, decode_times=list_1, use_cftime=dict_2)
    except BaseException:
        pass


def test_case_26():
    try:
        bool_0 = False
        path_0 = module_4.Path()
        timedelta64_0 = None
        var_0 = module_0.to_netcdf(bool_0, path_0, timedelta64_0)
    except BaseException:
        pass


def test_case_27():
    try:
        dict_0 = None
        dataset_0 = module_6.Dataset(dict_0)
        var_0 = module_0.to_zarr(dataset_0)
    except BaseException:
        pass


def test_case_28():
    try:
        bool_0 = False
        bytes_0 = b'\xd5\xf6j\x19\x00u\xa7\xb7\x86\x82V\xd2\xc2\xcd\xf0<\xcd\xee'
        var_0 = module_0.save_mfdataset(bool_0, bytes_0)
    except BaseException:
        pass


def test_case_29():
    try:
        dict_0 = {}
        timedelta64_0 = module_2.timedelta64()
        bytes_0 = b'\xaf\xe2j\xf0\xfd\x8e\x97g;[C\x12'
        var_0 = module_0.save_mfdataset(dict_0, bytes_0, timedelta64_0, bytes_0, bytes_0)
    except BaseException:
        pass


def test_case_30():
    try:
        list_0 = []
        str_0 = '8Y/FD6^`'
        dict_0 = {str_0: str_0, str_0: list_0, str_0: list_0, str_0: list_0}
        str_1 = 'rr6'
        var_0 = module_0.save_mfdataset(list_0, str_0, dict_0, str_1)
    except BaseException:
        pass


def test_case_31():
    try:
        dataset_0 = None
        var_0 = None
        path_0 = module_4.Path()
        str_0 = ''
        dict_0 = {str_0: var_0, str_0: dataset_0}
        var_1 = module_0.to_zarr(dataset_0, var_0, path_0, dict_0)
    except BaseException:
        pass


def test_case_32():
    try:
        float_0 = 1000.2276165147545
        float_1 = None
        var_0 = module_0.to_netcdf(float_1, float_0, float_1, float_0, float_1, float_0, float_0)
    except BaseException:
        pass


def test_case_33():
    try:
        index_0 = None
        str_0 = ''
        float_0 = 753.306
        data_array_0 = None
        dict_0 = {data_array_0: float_0, index_0: str_0, index_0: data_array_0, float_0: index_0}
        var_0 = module_0.to_netcdf(float_0, data_array_0, dict_0, dict_0, dict_0, float_0)
    except BaseException:
        pass


def test_case_34():
    try:
        float_0 = 3664.2275850352485
        set_0 = {float_0}
        str_0 = ',`A?l)\\oJ+nfQFiiTL8'
        path_0 = module_4.Path()
        str_1 = ' must not be empty'
        timedelta_0 = module_1.timedelta()
        float_1 = 4768.0
        var_0 = module_0.to_netcdf(set_0, str_0, path_0, str_1, timedelta_0, float_1)
    except BaseException:
        pass

Coverage: 41.58163265306123
Mutation Score: 2.200000000000003

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import os
import pytest
import numpy as np
from unittest.mock import patch, MagicMock
from xarray.backends.api import (
    _get_default_engine_remote_uri,
    _get_default_engine_gz,
    _get_default_engine_netcdf,
    _get_default_engine,
    _normalize_path,
    _validate_dataset_names,
    _validate_attrs,
    _resolve_decoders_kwargs,
    _get_mtime,
    _protect_dataset_variables_inplace,
    _finalize_store,
    load_dataset,
    load_dataarray,
    open_dataset,
    open_dataarray,
    open_mfdataset,
    to_netcdf,
    dump_to_store,
    save_mfdataset,
    to_zarr,
)

from xarray.core.dataset import Dataset
from xarray.core.dataarray import DataArray

@pytest.fixture
def mock_dataset():
    return Dataset({"var": ("dim", np.arange(10))})

@pytest.fixture
def mock_dataarray():
    return DataArray(np.arange(10), dims="dim")

def test_get_default_engine_remote_uri():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        assert _get_default_engine_remote_uri() == "netcdf4"

def test_get_default_engine_gz():
    with patch("xarray.backends.api.is_remote_uri", return_value=False):
        assert _get_default_engine_gz() == "scipy"

def test_get_default_engine_netcdf():
    with patch("xarray.backends.api.is_remote_uri", return_value=False):
        assert _get_default_engine_netcdf() == "netcdf4"

def test_get_default_engine():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        assert _get_default_engine("http://example.com") == "netcdf4"
    assert _get_default_engine("file.gz") == "scipy"
    assert _get_default_engine("file.nc") == "netcdf4"

def test_normalize_path():
    assert _normalize_path("~") == os.path.abspath(os.path.expanduser("~"))

def test_validate_dataset_names(mock_dataset):
    with pytest.raises(ValueError):
        mock_dataset[""] = mock_dataset["var"]
        _validate_dataset_names(mock_dataset)

def test_validate_attrs(mock_dataset):
    mock_dataset.attrs["valid_attr"] = "value"
    _validate_attrs(mock_dataset)
    mock_dataset.attrs[123] = "value"
    with pytest.raises(TypeError):
        _validate_attrs(mock_dataset)

def test_resolve_decoders_kwargs():
    decoders = {"mask_and_scale": None, "decode_times": True}
    result = _resolve_decoders_kwargs(False, ["mask_and_scale"], **decoders)
    assert result == {"decode_times": True}

def test_get_mtime():
    with patch("os.path.getmtime", return_value=123456789):
        assert _get_mtime("somefile") == 123456789

def test_protect_dataset_variables_inplace(mock_dataset):
    cache = True
    _protect_dataset_variables_inplace(mock_dataset, cache)
    assert isinstance(mock_dataset["var"].data, np.ndarray)

def test_finalize_store():
    mock_store = MagicMock()
    _finalize_store(None, mock_store)
    mock_store.close.assert_called_once()

def test_load_dataset(mock_dataset):
    with patch("xarray.backends.api.open_dataset", return_value=mock_dataset):
        ds = load_dataset("mock_file.nc")
        assert ds.equals(mock_dataset)

def test_load_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataarray", return_value=mock_dataarray):
        da = load_dataarray("mock_file.nc")
        assert da.equals(mock_dataarray)

def test_open_dataset(mock_dataset):
    with patch("xarray.backends.api.plugins.get_backend") as mock_backend:
        mock_backend.return_value.open_dataset.return_value = mock_dataset
        ds = open_dataset("mock_file.nc")
        assert ds.equals(mock_dataset)

def test_open_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataset", return_value=Dataset({"var": mock_dataarray})):
        da = open_dataarray("mock_file.nc")
        assert da.equals(mock_dataarray)

def test_open_mfdataset(mock_dataset):
    with patch("xarray.backends.api.open_dataset", return_value=mock_dataset):
        ds = open_mfdataset(["mock_file1.nc", "mock_file2.nc"])
        assert ds.equals(mock_dataset)

def test_to_netcdf(mock_dataset):
    with patch("xarray.backends.api.WRITEABLE_STORES", {"netcdf4": MagicMock()}):
        to_netcdf(mock_dataset, path_or_file="mock_file.nc", engine="netcdf4")

def test_dump_to_store(mock_dataset):
    mock_store = MagicMock()
    dump_to_store(mock_dataset, mock_store)
    mock_store.store.assert_called()

def test_save_mfdataset(mock_dataset):
    with patch("xarray.backends.api.to_netcdf") as mock_to_netcdf:
        save_mfdataset([mock_dataset], ["mock_file.nc"])
        mock_to_netcdf.assert_called()

def test_to_zarr(mock_dataset):
    with patch("xarray.backends.api.backends.ZarrStore.open_group") as mock_open_group:
        mock_open_group.return_value = MagicMock()
        to_zarr(mock_dataset, store="mock_store.zarr")
        mock_open_group.assert_called()

Coverage: 51.275510204081634
Mutation Score: 12.769999999999996

Approach:
Predicted Test Suite: import os
import pytest
import numpy as np
from unittest.mock import patch, MagicMock
from xarray.backends.api import (
    _get_default_engine_remote_uri,
    _get_default_engine_gz,
    _get_default_engine_netcdf,
    _get_default_engine,
    _normalize_path,
    _validate_dataset_names,
    _validate_attrs,
    _resolve_decoders_kwargs,
    _get_mtime,
    _protect_dataset_variables_inplace,
    _finalize_store,
    load_dataset,
    load_dataarray,
    open_dataset,
    open_dataarray,
    open_mfdataset,
    to_netcdf,
    dump_to_store,
    save_mfdataset,
    to_zarr,
)

from xarray.core.dataset import Dataset
from xarray.core.dataarray import DataArray

@pytest.fixture
def mock_dataset():
    return Dataset({"var": ("dim", np.arange(10))})

@pytest.fixture
def mock_dataarray():
    return DataArray(np.arange(10), dims="dim")

def test_get_default_engine_remote_uri():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        assert _get_default_engine_remote_uri() == "netcdf4"

def test_get_default_engine_gz():
    with patch("xarray.backends.api.is_remote_uri", return_value=False):
        assert _get_default_engine_gz() == "scipy"

def test_get_default_engine_netcdf():
    with patch("xarray.backends.api.is_remote_uri", return_value=False):
        assert _get_default_engine_netcdf() == "netcdf4"

def test_get_default_engine():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        assert _get_default_engine("http://example.com") == "netcdf4"
    assert _get_default_engine("file.gz") == "scipy"
    assert _get_default_engine("file.nc") == "netcdf4"

def test_normalize_path():
    assert _normalize_path("~") == os.path.abspath(os.path.expanduser("~"))

def test_validate_dataset_names(mock_dataset):
    with pytest.raises(ValueError):
        mock_dataset[""] = mock_dataset["var"]
        _validate_dataset_names(mock_dataset)

def test_validate_attrs(mock_dataset):
    mock_dataset.attrs["valid_attr"] = "value"
    _validate_attrs(mock_dataset)
    mock_dataset.attrs[123] = "value"
    with pytest.raises(TypeError):
        _validate_attrs(mock_dataset)

def test_resolve_decoders_kwargs():
    decoders = {"mask_and_scale": None, "decode_times": True}
    result = _resolve_decoders_kwargs(False, ["mask_and_scale"], **decoders)
    assert result == {"decode_times": True, "mask_and_scale": False}

def test_get_mtime():
    with patch("os.path.getmtime", return_value=123456789):
        assert _get_mtime("somefile") == 123456789

def test_protect_dataset_variables_inplace(mock_dataset):
    cache = True
    _protect_dataset_variables_inplace(mock_dataset, cache)
    assert isinstance(mock_dataset["var"].data, np.ndarray)

def test_finalize_store():
    mock_store = MagicMock()
    _finalize_store(None, mock_store)
    mock_store.close.assert_called_once()

def test_load_dataset(mock_dataset):
    with patch("xarray.backends.api.open_dataset", return_value=mock_dataset):
        ds = load_dataset("mock_file.nc")
        assert ds.equals(mock_dataset)

def test_load_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataarray", return_value=mock_dataarray):
        da = load_dataarray("mock_file.nc")
        assert da.equals(mock_dataarray)

def test_open_dataset(mock_dataset):
    with patch("xarray.backends.api.plugins.get_backend") as mock_backend:
        mock_backend.return_value.open_dataset.return_value = mock_dataset
        ds = open_dataset("mock_file.nc")
        assert ds.equals(mock_dataset)

def test_open_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataset", return_value=Dataset({"var": mock_dataarray})):
        da = open_dataarray("mock_file.nc")
        assert da.equals(mock_dataarray)

def test_open_mfdataset(mock_dataset):
    with patch("xarray.backends.api.open_dataset", return_value=mock_dataset):
        ds = open_mfdataset(["mock_file1.nc", "mock_file2.nc"])
        assert ds.equals(mock_dataset)

def test_to_netcdf(mock_dataset):
    with patch("xarray.backends.api.WRITEABLE_STORES", {"netcdf4": MagicMock()}):
        to_netcdf(mock_dataset, path_or_file="mock_file.nc", engine="netcdf4")

def test_dump_to_store(mock_dataset):
    mock_store = MagicMock()
    dump_to_store(mock_dataset, mock_store)
    mock_store.store.assert_called()

def test_save_mfdataset(mock_dataset):
    with patch("xarray.backends.api.to_netcdf") as mock_to_netcdf:
        save_mfdataset([mock_dataset], ["mock_file.nc"])
        mock_to_netcdf.assert_called()

def test_to_zarr(mock_dataset):
    with patch("xarray.backends.api.backends.ZarrStore.open_group") as mock_open_group:
        mock_open_group.return_value = MagicMock()
        to_zarr(mock_dataset, store="mock_store.zarr")
        mock_open_group.assert_called()
Coverage: 51.53061224489796
Mutation Score: 14.569999999999993
Output: On branch main
Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        deleted:    .coveragerc

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_backends_api.py

no changes added to commit (use "git add" and/or "git commit -a")
commit e267bc684c590530f9a2976211c3fe20ee8168fc
Author: TestGenEval <>
Date:   Wed Dec 11 12:34:14 2024 +0000

    Testing fixes

diff --git a/xarray/backends/api.py b/xarray/backends/api.py
index ab6ea3b1..29d442f1 100644
--- a/xarray/backends/api.py
+++ b/xarray/backends/api.py
@@ -375,10 +375,11 @@ def open_dataset(
         scipy.io.netcdf (only netCDF3 supported). Byte-strings or file-like
         objects are opened by scipy.io.netcdf (netCDF3) or h5py (netCDF4/HDF).
     engine : {"netcdf4", "scipy", "pydap", "h5netcdf", "pynio", "cfgrib", \
-        "pseudonetcdf", "zarr"}, optional
+        "pseudonetcdf", "zarr"} or subclass of xarray.backends.BackendEntrypoint, optional
         Engine to use when reading files. If not provided, the default engine
         is chosen based on available dependencies, with a preference for
-        "netcdf4".
+        "netcdf4". A custom backend class (a subclass of ``BackendEntrypoint``)
+        can also be used.
     chunks : int or dict, optional
         If chunks is provided, it is used to load the new dataset into dask
         arrays. ``chunks=-1`` loads the dataset with dask using a single
diff --git a/xarray/backends/plugins.py b/xarray/backends/plugins.py
index f9790cfa..23e83b00 100644
--- a/xarray/backends/plugins.py
+++ b/xarray/backends/plugins.py
@@ -5,7 +5,7 @@ import warnings

 import pkg_resources

-from .common import BACKEND_ENTRYPOINTS
+from .common import BACKEND_ENTRYPOINTS, BackendEntrypoint

 STANDARD_BACKENDS_ORDER = ["netcdf4", "h5netcdf", "scipy"]

@@ -113,10 +113,22 @@ def guess_engine(store_spec):


 def get_backend(engine):
-    """Select open_dataset method based on current engine"""
-    engines = list_engines()
-    if engine not in engines:
-        raise ValueError(
-            f"unrecognized engine {engine} must be one of: {list(engines)}"
+    """Select open_dataset method based on current engine."""
+    if isinstance(engine, str):
+        engines = list_engines()
+        if engine not in engines:
+            raise ValueError(
+                f"unrecognized engine {engine} must be one of: {list(engines)}"
+            )
+        backend = engines[engine]
+    elif isinstance(engine, type) and issubclass(engine, BackendEntrypoint):
+        backend = engine
+    else:
+        raise TypeError(
+            (
+                "engine must be a string or a subclass of "
+                f"xarray.backends.BackendEntrypoint: {engine}"
+            )
         )
-    return engines[engine]
+
+    return backend
diff --git a/xarray/tests/test_backends_api.py b/xarray/tests/test_backends_api.py
deleted file mode 100644
index 340495d4..00000000
--- a/xarray/tests/test_backends_api.py
+++ /dev/null
@@ -1,16 +0,0 @@
-from xarray.backends.api import _get_default_engine
-
-from . import requires_netCDF4, requires_scipy
-
-
-@requires_netCDF4
-@requires_scipy
-def test__get_default_engine():
-    engine_remote = _get_default_engine("http://example.org/test.nc", allow_remote=True)
-    assert engine_remote == "netcdf4"
-
-    engine_gz = _get_default_engine("/example.gz")
-    assert engine_gz == "scipy"
-
-    engine_default = _get_default_engine("/example")
-    assert engine_default == "netcdf4"
Obtaining file:///testbed
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.17.1.dev58+ge267bc68.d20250207) (1.23.0)
Requirement already satisfied: pandas>=1.0 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.17.1.dev58+ge267bc68.d20250207) (1.5.3)
Requirement already satisfied: setuptools>=40.4 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.17.1.dev58+ge267bc68.d20250207) (68.0.0)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.0->xarray==0.17.1.dev58+ge267bc68.d20250207) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.0->xarray==0.17.1.dev58+ge267bc68.d20250207) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0->xarray==0.17.1.dev58+ge267bc68.d20250207) (1.16.0)
Building wheels for collected packages: xarray
  Building editable for xarray (pyproject.toml): started
  Building editable for xarray (pyproject.toml): finished with status 'done'
  Created wheel for xarray: filename=xarray-0.17.1.dev58+ge267bc68.d20250207-0.editable-py3-none-any.whl size=9078 sha256=ef230b984eddc4fd176721236e2d15d19e9a43215569b57dbbdaf3959fff6e97
  Stored in directory: /tmp/pip-ephem-wheel-cache-ygxhicub/wheels/0d/a6/cb/465a7b303d624cc531250fa27c75d038ddc29430bdb6ba7c9f
Successfully built xarray
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.17.1.dev58+ge267bc68
    Uninstalling xarray-0.17.1.dev58+ge267bc68:
      Successfully uninstalled xarray-0.17.1.dev58+ge267bc68
Successfully installed xarray-0.17.1.dev58+ge267bc68.d20250207
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, xdist-3.6.1
collected 18 items

xarray/tests/test_backends_api.py ..................                     [100%]

=============================== warnings summary ===============================
xarray/__init__.py:1
  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    import pkg_resources

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

xarray/core/dask_array_compat.py:61
xarray/core/dask_array_compat.py:61
  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) > LooseVersion("2.9.0"):

xarray/core/dask_array_compat.py:98
xarray/core/dask_array_compat.py:98
  /testbed/xarray/core/dask_array_compat.py:98: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) > LooseVersion("2.30.0"):

xarray/core/dask_array_compat.py:155
xarray/core/dask_array_compat.py:155
  /testbed/xarray/core/dask_array_compat.py:155: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(dask_version) > LooseVersion("2021.03.0"):

xarray/core/npcompat.py:87
  /testbed/xarray/core/npcompat.py:87: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(np.__version__) >= "1.20.0":

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

xarray/core/pdcompat.py:45
  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) < "0.25.0":

xarray/coding/cftimeindex.py:62
xarray/coding/cftimeindex.py:62
  /testbed/xarray/coding/cftimeindex.py:62: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) > LooseVersion("1.2.3"):

xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
xarray/tests/__init__.py:59
  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    return version.LooseVersion(vstring)

xarray/tests/test_backends_api.py::test_open_dataset
  /testbed/xarray/backends/plugins.py:61: RuntimeWarning: Engine 'pseudonetcdf' loading failed:
  cannot import name '_normalize_path' from 'xarray.backends.common' (/testbed/xarray/backends/common.py)
    warnings.warn(f"Engine {name!r} loading failed:\n{ex}", RuntimeWarning)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_remote_uri
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_gz
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_netcdf
PASSED xarray/tests/test_backends_api.py::test_get_default_engine
PASSED xarray/tests/test_backends_api.py::test_normalize_path
PASSED xarray/tests/test_backends_api.py::test_validate_dataset_names
PASSED xarray/tests/test_backends_api.py::test_validate_attrs
PASSED xarray/tests/test_backends_api.py::test_resolve_decoders_kwargs
PASSED xarray/tests/test_backends_api.py::test_get_mtime
PASSED xarray/tests/test_backends_api.py::test_protect_dataset_variables_inplace
PASSED xarray/tests/test_backends_api.py::test_finalize_store
PASSED xarray/tests/test_backends_api.py::test_load_dataset
PASSED xarray/tests/test_backends_api.py::test_load_dataarray
PASSED xarray/tests/test_backends_api.py::test_open_dataset
PASSED xarray/tests/test_backends_api.py::test_open_dataarray
PASSED xarray/tests/test_backends_api.py::test_to_netcdf
PASSED xarray/tests/test_backends_api.py::test_dump_to_store
PASSED xarray/tests/test_backends_api.py::test_to_zarr
======================= 18 passed, 27 warnings in 3.87s ========================

