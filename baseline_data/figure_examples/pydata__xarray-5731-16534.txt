Instance ID: pydata__xarray-5731-16534

Baseline 1 (Pynguin):
Predicted Test Suite: # Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import xarray.core.computation as module_0
import numpy.lib._datasource as module_1
import llvmlite.binding.targets as module_2
import yaml.constructor as module_3
import http.cookiejar as module_4
import scipy.fftpack._pseudo_diffs as module_5
import pandas.io.sql as module_6
import numpy as module_7
import numba.np.ufunc_db as module_8
import matplotlib as module_9
import scipy.linalg.decomp_schur as module_10
import numba.core.codegen as module_11


def test_case_0():
    var_0 = module_0.unify_chunks()


@pytest.mark.xfail(strict=True)
def test_case_1():
    file_openers_0 = module_1._FileOpeners()
    module_0.where(file_openers_0, file_openers_0, file_openers_0)


def test_case_2():
    none_type_0 = None
    var_0 = module_0.where(none_type_0, none_type_0, none_type_0)
    assert f"{type(var_0).__module__}.{type(var_0).__qualname__}" == "numpy.ndarray"


def test_case_3():
    annotate_types_0 = module_2.get_host_cpu_name()
    var_0 = module_0.result_name(annotate_types_0)


@pytest.mark.xfail(strict=True)
def test_case_4():
    var_0 = module_0.unify_chunks()
    dict_0 = module_0.unified_dim_sizes(var_0)
    module_0.where(dict_0, dict_0, var_0)


@pytest.mark.xfail(strict=True)
def test_case_5():
    var_0 = module_3.Constructor()
    module_0.apply_dataset_vfunc(
        var_0, signature=var_0, fill_value=var_0, keep_attrs=var_0
    )


@pytest.mark.xfail(strict=True)
def test_case_6():
    var_0 = module_4.time2netscape()
    assert var_0 == "Tue, 14-Jan-2025 23:19:48 GMT"
    iterable_0 = module_0.ordered_set_union(var_0)
    module_5.cc_diff(var_0, var_0, var_0, var_0)


def test_case_7():
    var_0 = module_6.SQLAlchemyEngine()
    with pytest.raises(AssertionError):
        module_0.apply_groupby_func(var_0)


@pytest.mark.xfail(strict=True)
def test_case_8():
    var_0 = module_0.unify_chunks()
    module_0.apply_variable_ufunc(var_0, *var_0, signature=var_0, output_dtypes=var_0)


def test_case_9():
    none_type_0 = None
    with pytest.raises(TypeError):
        module_0.corr(none_type_0, none_type_0, none_type_0)


def test_case_10():
    with pytest.raises(TypeError):
        module_0.dot()


@pytest.mark.xfail(strict=True)
def test_case_11():
    var_0 = module_0.unify_chunks()
    tuple_0 = (var_0, var_0, var_0)
    module_0.unify_chunks(*tuple_0)


@pytest.mark.xfail(strict=True)
def test_case_12():
    var_0 = module_0.unify_chunks()
    module_0.polyval(var_0, var_0, var_0)


@pytest.mark.xfail(strict=True)
def test_case_13():
    none_type_0 = None
    module_0.apply_dataarray_vfunc(
        none_type_0, signature=none_type_0, keep_attrs=none_type_0
    )


def test_case_14():
    var_0 = module_0.unify_chunks()
    with pytest.raises(TypeError):
        module_0.apply_dataset_vfunc(var_0, *var_0, signature=var_0, dataset_join=var_0)


def test_case_15():
    none_type_0 = None
    with pytest.raises(TypeError):
        module_0.cov(none_type_0, none_type_0)


def test_case_16():
    var_0 = module_0.unify_chunks()
    with pytest.raises(TypeError):
        module_0.apply_ufunc(var_0, keep_attrs=var_0, dask=var_0, output_sizes=var_0)


def test_case_17():
    list_0 = module_7.geterr()
    with pytest.raises(TypeError):
        module_0.dot(*list_0, dims=list_0)


def test_case_18():
    var_0 = module_8.get_ufuncs()
    with pytest.raises(AssertionError):
        module_0.apply_groupby_func(var_0, *var_0)


def test_case_19():
    var_0 = module_9.get_configdir()
    list_0 = module_0.collect_dict_values(var_0, var_0)
    var_1 = var_0.__eq__(list_0)


@pytest.mark.xfail(strict=True)
def test_case_20():
    var_0 = module_10.__dir__()
    module_0.unified_dim_sizes(var_0)


@pytest.mark.xfail(strict=True)
def test_case_21():
    var_0 = module_8.get_ufuncs()
    module_0.apply_variable_ufunc(var_0, *var_0, signature=var_0, output_dtypes=var_0)


def test_case_22():
    var_0 = module_0.unify_chunks()
    with pytest.raises(TypeError):
        module_0.apply_ufunc(
            var_0,
            *var_0,
            output_core_dims=var_0,
            kwargs=var_0,
            dask_gufunc_kwargs=var_0,
        )


@pytest.mark.xfail(strict=True)
def test_case_23():
    none_type_0 = None
    list_0 = [none_type_0, none_type_0]
    module_0.apply_dataarray_vfunc(
        list_0,
        *list_0,
        signature=none_type_0,
        join=list_0,
        exclude_dims=none_type_0,
        keep_attrs=list_0,
    )


@pytest.mark.xfail(strict=True)
def test_case_24():
    var_0 = module_0.unify_chunks()
    var_1 = module_0.where(var_0, var_0, var_0)
    assert f"{type(var_1).__module__}.{type(var_1).__qualname__}" == "numpy.ndarray"
    assert len(var_1) == 0
    var_2 = module_7.delete(var_1, var_0)
    module_0.apply_dataset_vfunc(
        var_0, *var_2, signature=var_0, dataset_join=var_0, fill_value=var_1
    )


def test_case_25():
    var_0 = module_0.unify_chunks()
    dict_0 = module_0.unified_dim_sizes(var_0)
    var_1 = module_11.get_host_cpu_features()
    var_2 = module_0.where(var_0, var_0, var_0)
    assert f"{type(var_2).__module__}.{type(var_2).__qualname__}" == "numpy.ndarray"
    assert len(var_2) == 0
    var_3 = var_0.__repr__()
    iterable_0 = module_0.ordered_set_intersection(var_1)
    var_4 = module_0.result_name(var_2)
    var_5 = module_0.where(var_0, var_4, var_3)


def test_case_26():
    var_0 = module_0.unify_chunks()
    var_1 = var_0.__ne__(var_0)
    dict_0 = module_0.unified_dim_sizes(var_0)
    var_2 = module_0.where(var_0, var_0, var_0)
    assert f"{type(var_2).__module__}.{type(var_2).__qualname__}" == "numpy.ndarray"
    assert len(var_2) == 0
    var_3 = module_0.where(var_0, var_0, var_0)
    var_4 = var_0.__repr__()
    with pytest.raises(ValueError):
        module_0.assert_and_return_exact_match(var_4)

Coverage: 40.48059149722736
Mutation Score: 8.64

Baseline 2 (CodaMosa):
Predicted Test Suite: import builtins as module_1
import xarray.core.computation as module_0
import xarray.core.variable as module_2

def test_case_1():
    try:
        float_0 = -830.6
        int_0 = 1006
        var_0 = module_0.apply_dataset_vfunc(float_0, signature=int_0)
    except BaseException:
        pass


def test_case_2():
    try:
        list_0 = []
        iterable_0 = module_0.ordered_set_union(list_0)
        assert module_0.TYPE_CHECKING is False
        dict_0 = None
        var_0 = module_0.dot(dims=iterable_0, **dict_0)
    except BaseException:
        pass


def test_case_3():
    try:
        list_0 = []
        iterable_0 = module_0.ordered_set_union(list_0)
        assert module_0.TYPE_CHECKING is False
        list_1 = [iterable_0, iterable_0]
        iterable_1 = module_0.ordered_set_intersection(list_1)
        list_2 = [iterable_1, iterable_1, iterable_0]
        iterable_2 = module_0.ordered_set_union(list_2)
        var_0 = module_0.apply_groupby_func(iterable_2)
    except BaseException:
        pass


def test_case_4():
    try:
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        str_0 = '5;9J7. \x0c'
        iterable_0 = module_0.join_dict_keys(str_0)
    except BaseException:
        pass


def test_case_5():
    try:
        object_0 = module_1.object()
        var_0 = module_0.assert_and_return_exact_match(object_0)
    except BaseException:
        pass


def test_case_6():
    try:
        list_0 = []
        var_0 = module_0.apply_array_ufunc(list_0)
    except BaseException:
        pass


def test_case_7():
    try:
        var_0 = module_0.dot()
    except BaseException:
        pass


def test_case_8():
    try:
        list_0 = []
        list_1 = [list_0, list_0, list_0, list_0]
        var_0 = module_0.unify_chunks(*list_1)
    except BaseException:
        pass


def test_case_9():
    try:
        list_0 = None
        list_1 = [list_0, list_0, list_0, list_0]
        var_0 = module_0.unify_chunks(*list_1)
    except BaseException:
        pass


def test_case_10():
    try:
        dict_0 = {}
        u_func_signature_0 = module_0._UFuncSignature(dict_0)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        var_0 = u_func_signature_0.__repr__()
        assert var_0 == '_UFuncSignature([], [()])'
        complex_0 = None
        tuple_0 = None
        var_1 = module_0.where(complex_0, dict_0, tuple_0)
    except BaseException:
        pass


def test_case_11():
    try:
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        int_0 = 13
        bytes_0 = b'\x8c\x8c\x86h\xb5\x95\x08\x81\x87\xda\x99\x8d\x93'
        list_0 = []
        set_0 = set()
        variable_0 = module_2.Variable(list_0, set_0)
        list_1 = []
        bool_0 = True
        var_1 = module_0.apply_dataset_vfunc(list_1, signature=int_0, dataset_join=bytes_0, fill_value=int_0, exclude_dims=bool_0)
    except BaseException:
        pass


def test_case_12():
    try:
        dict_0 = {}
        list_0 = [dict_0]
        var_0 = module_0.apply_dataarray_vfunc(dict_0, signature=list_0)
    except BaseException:
        pass


def test_case_13():
    try:
        list_0 = None
        str_0 = '\n-qr,Xu|>or'
        dict_0 = {}
        var_0 = module_0.where(dict_0, list_0, str_0)
    except BaseException:
        pass


def test_case_14():
    try:
        list_0 = []
        var_0 = module_0.apply_groupby_func(list_0)
    except BaseException:
        pass


def test_case_15():
    try:
        str_0 = "vD;i\x0c'M:u,fF\r=>"
        var_0 = module_0.corr(str_0, str_0)
    except BaseException:
        pass


def test_case_16():
    try:
        object_0 = module_1.object()
        variable_0 = None
        str_0 = "'NIl\t<PoO"
        list_0 = [variable_0]
        optional_0 = None
        dict_0 = None
        any_0 = module_0.apply_ufunc(str_0, *list_0, input_core_dims=object_0, output_core_dims=optional_0, kwargs=dict_0)
    except BaseException:
        pass


def test_case_17():
    try:
        list_0 = None
        str_0 = '|<[\x0c9#H/Fy'
        dict_0 = {str_0: list_0, str_0: list_0}
        var_0 = module_0.where(dict_0, dict_0, list_0)
    except BaseException:
        pass


def test_case_18():
    try:
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        list_0 = None
        object_0 = module_1.object()
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        str_0 = '\n-qr,Xu|>or'
        var_1 = module_0.where(object_0, str_0, list_0)
        str_1 = 'raise'
        var_2 = module_0.assert_and_return_exact_match(str_1)
    except BaseException:
        pass


def test_case_19():
    try:
        list_0 = None
        str_0 = '_I_invert_'
        list_1 = [list_0, list_0, list_0, list_0, list_0, list_0, list_0, list_0]
        variable_0 = module_2.Variable(str_0, list_1)
        var_0 = module_0.where(variable_0, list_0, variable_0)
        assert len(variable_0) == 8
        assert len(var_0) == 8
        assert module_2.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_2.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_2.annotations.compiler_flag == 16777216
        assert module_2.TYPE_CHECKING is False
        assert module_2.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        assert module_2.cupy_array_type == ()
        assert module_2.dask_array_type == ()
        assert len(module_2.integer_types) == 2
        assert module_2.sparse_array_type == ()
        assert len(module_2.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
        assert len(module_2.BASIC_INDEXING_TYPES) == 3
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        assert module_2.Variable.concat is not None
        list_2 = [str_0, list_0, list_0, variable_0]
        var_1 = module_0.dot(*list_2)
    except BaseException:
        pass


def test_case_20():
    try:
        hashable_0 = None
        int_0 = 1
        int_1 = None
        int_2 = 0
        dict_0 = {hashable_0: int_0, hashable_0: int_1, hashable_0: int_0, hashable_0: int_2}
        variable_0 = None
        var_0 = module_0.polyval(dict_0, variable_0)
    except BaseException:
        pass


def test_case_21():
    try:
        bytes_0 = b'\xe7]\x87\xab'
        var_0 = module_0.cov(bytes_0, bytes_0)
    except BaseException:
        pass


def test_case_22():
    try:
        list_0 = None
        str_0 = '\n-qr,Xu|>or'
        dict_0 = {str_0: list_0}
        var_0 = module_0.where(dict_0, list_0, str_0)
    except BaseException:
        pass


def test_case_23():
    try:
        list_0 = None
        list_1 = [list_0, list_0, list_0, list_0, list_0, list_0]
        list_2 = [list_1]
        var_0 = module_0.apply_dataarray_vfunc(list_0, *list_2, signature=list_1)
    except BaseException:
        pass


def test_case_24():
    try:
        float_0 = 1064.0413
        list_0 = [float_0, float_0]
        list_1 = [list_0, list_0]
        var_0 = module_0.apply_dataarray_vfunc(float_0, *list_1, signature=list_0)
    except BaseException:
        pass


def test_case_25():
    try:
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        list_0 = []
        iterable_0 = module_0.ordered_set_union(list_0)
        assert len(iterable_0) == 0
        list_1 = [var_0]
        any_0 = module_0.result_name(list_1)
        dict_0 = {var_0: var_0, any_0: list_1}
        int_0 = -1932
        set_0 = set()
        var_1 = module_0.where(int_0, set_0, dict_0)
    except BaseException:
        pass


def test_case_26():
    try:
        float_0 = 781.595
        list_0 = [float_0, float_0]
        var_0 = module_0.apply_groupby_func(float_0, *list_0)
    except BaseException:
        pass


def test_case_27():
    try:
        set_0 = None
        dict_0 = {set_0: set_0, set_0: set_0, set_0: set_0, set_0: set_0}
        list_0 = [set_0]
        list_1 = [list_0, list_0, dict_0]
        str_0 = '_m*'
        u_func_signature_0 = module_0._UFuncSignature(list_1, str_0)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        var_0 = u_func_signature_0.__eq__(u_func_signature_0)
        assert var_0 is True
        iterable_0 = None
        list_2 = [iterable_0, iterable_0, iterable_0]
        iterable_1 = module_0.ordered_set_union(list_2)
    except BaseException:
        pass


def test_case_28():
    try:
        list_0 = None
        dict_0 = {}
        u_func_signature_0 = module_0._UFuncSignature(dict_0)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        str_0 = 'e~hoC,L)f"IZ#K%OjJ:'
        u_func_signature_1 = module_0._UFuncSignature(str_0)
        var_0 = u_func_signature_1.__ne__(u_func_signature_0)
        assert var_0 is True
        str_1 = '\n-qr,Xu|>5or'
        dict_1 = {str_1: list_0, str_1: list_0}
        var_1 = module_0.where(dict_1, list_0, str_1)
    except BaseException:
        pass


def test_case_29():
    try:
        str_0 = '^Bq'
        callable_0 = None
        set_0 = {callable_0}
        bool_0 = True
        bytes_0 = b'\xa1\xe9'
        optional_0 = None
        list_0 = []
        any_0 = module_0.result_name(list_0)
        assert any_0 is None
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        any_1 = module_0.apply_ufunc(callable_0, input_core_dims=set_0, vectorize=bool_0, kwargs=bytes_0, dask=str_0, output_sizes=optional_0, meta=any_0)
    except BaseException:
        pass


def test_case_30():
    try:
        list_0 = None
        str_0 = 'allowed'
        dict_0 = {str_0: list_0, str_0: list_0}
        list_1 = [dict_0, dict_0]
        iterable_0 = module_0.join_dict_keys(list_1)
        assert iterable_0 == ['allowed']
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        object_0 = module_1.object()
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        list_2 = [list_0]
        var_0 = module_0.apply_variable_ufunc(iterable_0, *list_1, signature=list_0, dask=object_0, output_dtypes=list_2)
    except BaseException:
        pass


def test_case_31():
    try:
        bytes_0 = b'\xf4t'
        list_0 = []
        u_func_signature_0 = module_0._UFuncSignature(list_0)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        var_0 = u_func_signature_0.to_gufunc_string(bytes_0)
    except BaseException:
        pass


def test_case_32():
    try:
        list_0 = []
        str_0 = '-fL`zBDPiY.0Nc:]!'
        none_type_0 = None
        optional_0 = None
        object_0 = module_1.object(*list_0)
        int_0 = 11
        bool_0 = True
        any_0 = module_0.apply_ufunc(str_0, input_core_dims=none_type_0, output_core_dims=optional_0, dataset_fill_value=object_0, kwargs=int_0, dask=str_0, meta=bool_0)
    except BaseException:
        pass


def test_case_33():
    try:
        int_0 = 40
        str_0 = '<z'
        str_1 = '6 '
        dict_0 = {str_0: str_0, str_1: int_0}
        tuple_0 = (dict_0,)
        list_0 = [str_1]
        object_0 = module_1.object()
        iterable_0 = module_0.join_dict_keys(tuple_0)
        assert iterable_0 == ['<z', '6 ']
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        list_1 = [iterable_0]
        iterable_1 = module_0.ordered_set_union(list_1)
        assert len(iterable_1) == 2
        float_0 = 695.47251
        list_2 = [list_0]
        variable_0 = module_2.Variable(iterable_1, float_0, list_2)
    except BaseException:
        pass


def test_case_34():
    try:
        hashable_0 = None
        bytes_0 = b''
        str_0 = ';xM21('
        variable_0 = module_2.Variable(bytes_0, str_0)
        tuple_0 = (hashable_0, variable_0)
        any_0 = module_0.broadcast_compat_data(variable_0, tuple_0, tuple_0)
    except BaseException:
        pass


def test_case_35():
    try:
        callable_0 = None
        list_0 = []
        var_0 = module_0.unify_chunks(*list_0)
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        set_0 = {var_0}
        any_0 = module_0.apply_ufunc(callable_0, *list_0, input_core_dims=list_0, exclude_dims=set_0)
    except BaseException:
        pass


def test_case_36():
    try:
        list_0 = None
        str_0 = 'CH&'
        list_1 = [list_0, list_0, list_0, list_0]
        variable_0 = module_2.Variable(str_0, list_1)
        dict_0 = {str_0: list_1}
        var_0 = module_0.where(variable_0, list_0, dict_0)
    except BaseException:
        pass


def test_case_37():
    try:
        callable_0 = None
        str_0 = 'x&\t"\'j\r//D!>\'H'
        any_0 = module_0.apply_ufunc(callable_0, exclude_dims=str_0, dataset_join=str_0, keep_attrs=str_0, dask=str_0)
    except BaseException:
        pass


def test_case_38():
    try:
        str_0 = '~.A>$4q0T,YiQ.I;1'
        str_1 = ';y!vLD&W`|v4th2q;S'
        list_0 = [str_1, str_0, str_1, str_1]
        float_0 = -84.945595
        var_0 = module_0.apply_dataset_vfunc(str_1, *list_0, signature=str_0, dataset_join=float_0)
    except BaseException:
        pass


def test_case_39():
    try:
        str_0 = 't'
        float_0 = 18.0
        tuple_0 = ()
        u_func_signature_0 = module_0._UFuncSignature(tuple_0, str_0)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        var_0 = u_func_signature_0.to_gufunc_string(float_0)
    except BaseException:
        pass


def test_case_40():
    try:
        list_0 = None
        str_0 = '\nqr,Xu|>or'
        int_0 = 0
        object_0 = module_1.object()
        var_0 = module_0.where(list_0, int_0, object_0)
        float_0 = 366.14335
        sequence_0 = None
        u_func_signature_0 = None
        optional_0 = None
        any_0 = module_0.apply_ufunc(float_0, input_core_dims=sequence_0, exclude_dims=u_func_signature_0, keep_attrs=str_0, output_dtypes=optional_0)
    except BaseException:
        pass


def test_case_41():
    try:
        ndarray_0 = None
        list_0 = [ndarray_0, ndarray_0, ndarray_0, ndarray_0]
        object_0 = module_1.object()
        hashable_0 = None
        int_0 = 3
        dict_0 = {hashable_0: int_0}
        list_1 = None
        variable_0 = None
        bool_0 = True
        list_2 = [int_0, list_1, list_0, dict_0]
        list_3 = [list_2, list_2, list_2, list_2]
        any_0 = module_0.apply_ufunc(variable_0, *list_0, vectorize=bool_0, keep_attrs=bool_0, kwargs=list_2, output_dtypes=list_3)
    except BaseException:
        pass


def test_case_42():
    try:
        int_0 = 1
        int_1 = 2
        int_2 = 3
        int_3 = [int_0, int_1, int_2]
        int_4 = 4
        int_5 = [int_1, int_2, int_4]
        int_6 = 5
        int_7 = [int_2, int_4, int_6]
        int_8 = [int_3, int_5, int_7]
        iterable_0 = module_0.ordered_set_intersection(int_8)
        assert iterable_0 == [3]
        assert module_0.TYPE_CHECKING is False
        int_9 = [int_0, int_1]
        int_10 = [int_2, int_4]
        int_11 = 6
        int_12 = [int_6, int_11]
        int_13 = [int_9, int_10, int_12]
        iterable_1 = module_0.ordered_set_intersection(int_13)
        assert iterable_1 == []
        int_14 = [int_0, int_1, int_2]
        var_0 = []
        int_15 = [int_2, int_4, int_6]
        var_1 = [int_14, var_0, int_15]
        iterable_2 = module_0.ordered_set_intersection(var_1)
        assert iterable_2 == []
        var_2 = []
        var_3 = []
        var_4 = [var_2, int_13, var_3]
        iterable_3 = module_0.ordered_set_intersection(var_4)
    except BaseException:
        pass# Automatically generated by Pynguin.


def test_case_43():
    pass


def test_case_44():
    str_0 = '\n-qr,Xu|>or'
    u_func_signature_0 = module_0._UFuncSignature(str_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.to_gufunc_string()
    assert var_0 == '(dim0),(dim2),(dim6),(dim7),(dim1),(dim4),(dim8),(dim9),(dim3),(dim5),(dim7)->()'


def test_case_45():
    list_0 = []
    any_0 = module_0.result_name(list_0)
    assert any_0 is None
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_46():
    object_0 = module_1.object()
    set_0 = set()
    dict_0 = module_0.unified_dim_sizes(set_0)
    assert dict_0 == {}
    assert module_1.None is None
    assert module_1.False is False
    assert module_1.True is True
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_47():
    list_0 = None
    str_0 = '7q}OcDjP\t\x0b!2i?Sn-U'
    list_1 = [list_0, list_0, list_0, list_0]
    variable_0 = module_2.Variable(str_0, list_1)
    var_0 = module_0.where(variable_0, list_0, variable_0)
    assert len(variable_0) == 4
    assert len(var_0) == 4
    assert module_2.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_2.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_2.annotations.compiler_flag == 16777216
    assert module_2.TYPE_CHECKING is False
    assert module_2.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_2.cupy_array_type == ()
    assert module_2.dask_array_type == ()
    assert len(module_2.integer_types) == 2
    assert module_2.sparse_array_type == ()
    assert len(module_2.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
    assert len(module_2.BASIC_INDEXING_TYPES) == 3
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_2.Variable.concat is not None


def test_case_48():
    list_0 = []
    object_0 = None
    var_0 = module_0.where(list_0, object_0, list_0)
    assert len(var_0) == 0
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_49():
    var_0 = module_0.unify_chunks()
    assert var_0 == ()
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_50():
    float_0 = None
    list_0 = [float_0, float_0]
    any_0 = module_0.result_name(list_0)
    assert any_0 is None
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_51():
    list_0 = []
    iterable_0 = module_0.ordered_set_union(list_0)
    assert module_0.TYPE_CHECKING is False
    iterable_1 = module_0.ordered_set_union(list_0)
    list_1 = [iterable_1, iterable_0]
    iterable_2 = module_0.ordered_set_union(list_1)


def test_case_52():
    dict_0 = {}
    u_func_signature_0 = module_0._UFuncSignature(dict_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.__eq__(dict_0)
    assert var_0 is False


def test_case_53():
    object_0 = module_1.object()
    str_0 = '\n-qr,Xu|>or'
    u_func_signature_0 = module_0._UFuncSignature(str_0)
    assert module_1.None is None
    assert module_1.False is False
    assert module_1.True is True
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.__ne__(object_0)
    assert var_0 is True


def test_case_54():
    list_0 = None
    str_0 = '7q}OuDjP\t\x0b!ai?Sn-'
    list_1 = [list_0, list_0, list_0, list_0, list_0, list_0, list_0]
    variable_0 = module_2.Variable(str_0, list_1)
    var_0 = variable_0.fillna(variable_0)
    var_1 = module_0.where(variable_0, list_0, variable_0)
    assert len(variable_0) == 7
    assert len(var_0) == 7
    assert len(var_1) == 7
    assert module_2.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_2.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_2.annotations.compiler_flag == 16777216
    assert module_2.TYPE_CHECKING is False
    assert module_2.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_2.cupy_array_type == ()
    assert module_2.dask_array_type == ()
    assert len(module_2.integer_types) == 2
    assert module_2.sparse_array_type == ()
    assert len(module_2.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
    assert len(module_2.BASIC_INDEXING_TYPES) == 3
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_2.Variable.concat is not None


def test_case_55():
    list_0 = []
    str_0 = '.IV1cVm}_>8RW\r'
    u_func_signature_0 = module_0._UFuncSignature(str_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    list_1 = module_0.build_output_coords(list_0, u_func_signature_0, str_0)
    assert list_1 == [{}]

Coverage: 52.310536044362294
Mutation Score: 8.0

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import pytest
import numpy as np
import pandas as pd
from xarray import DataArray, Dataset
from xarray.core.computation import (
    _UFuncSignature,
    apply_ufunc,
    broadcast_compat_data,
    collect_dict_values,
    join_dict_keys,
    ordered_set_intersection,
    ordered_set_union,
    result_name,
    unified_dim_sizes,
    apply_variable_ufunc,
    apply_dataarray_vfunc,
    apply_dataset_vfunc,
    apply_groupby_func,
    _calc_idxminmax,
    cov,
    corr,
    dot,
    where,
    polyval,
)

def test_result_name():
    class Obj:
        def __init__(self, name):
            self.name = name

    assert result_name([Obj("a"), Obj("a")]) == "a"
    assert result_name([Obj("a"), Obj("b")]) is None
    assert result_name([Obj(None), Obj(None)]) is None

def test_ordered_set_union():
    assert list(ordered_set_union([[1, 2], [2, 3]])) == [1, 2, 3]

def test_ordered_set_intersection():
    assert list(ordered_set_intersection([[1, 2], [2, 3]])) == [2]

def test_join_dict_keys():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert list(join_dict_keys([dict1, dict2], how='inner')) == ['b']
    assert list(join_dict_keys([dict1, dict2], how='outer')) == ['a', 'b', 'c']

def test_collect_dict_values():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert collect_dict_values([dict1, dict2], ['a', 'b', 'c'], fill_value=0) == [[1, 0], [2, 3], [0, 4]]

def test_unified_dim_sizes():
    var1 = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    var2 = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    assert unified_dim_sizes([var1, var2]) == {'x': 3, 'y': 4}

def test_apply_ufunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = apply_ufunc(np.sum, array, input_core_dims=[['x']], kwargs={'axis': -1})
    assert result.dims == ('y',)

def test_apply_variable_ufunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    signature = _UFuncSignature([['x']], [['y']])
    result = apply_variable_ufunc(np.sum, array, signature=signature)
    assert result.dims == ('y',)

def test_apply_dataarray_vfunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    signature = _UFuncSignature([['x']], [['y']])
    result = apply_dataarray_vfunc(np.sum, array, signature=signature)
    assert result.dims == ('y',)

def test_apply_dataset_vfunc():
    ds = Dataset({'a': ('x', np.random.rand(3)), 'b': ('x', np.random.rand(3))})
    signature = _UFuncSignature([['x']], [['y']])
    result = apply_dataset_vfunc(np.sum, ds, signature=signature)
    assert 'y' in result.dims

def test_apply_groupby_func():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    grouped = array.groupby('x')
    result = apply_groupby_func(np.sum, grouped)
    assert result.dims == ('x', 'y')

def test_cov():
    da_a = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = cov(da_a, da_b, dim='x')
    assert 'x' not in result.dims

def test_corr():
    da_a = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = corr(da_a, da_b, dim='x')
    assert 'x' not in result.dims

def test_dot():
    da_a = DataArray(np.random.rand(3, 2), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(2, 4), dims=['y', 'z'])
    result = dot(da_a, da_b, dims='y')
    assert result.dims == ('x', 'z')

def test_where():
    cond = DataArray([True, False], dims='x')
    x = DataArray([1, 2], dims='x')
    y = DataArray([3, 4], dims='x')
    result = where(cond, x, y)
    assert result.equals(DataArray([1, 4], dims='x'))

def test_polyval():
    coord = DataArray(np.linspace(0, 1, 10), dims='x')
    coeffs = DataArray([1, 0, -1], dims='degree')
    result = polyval(coord, coeffs)
    assert result.dims == ('x',)

Coverage: 49.90757855822551
Mutation Score: 33.43000000000001

Approach:
Predicted Test Suite: import pytest
import numpy as np
import pandas as pd
from xarray import DataArray, Dataset
from xarray.core.computation import (
    _UFuncSignature,
    apply_ufunc,
    broadcast_compat_data,
    collect_dict_values,
    join_dict_keys,
    ordered_set_intersection,
    ordered_set_union,
    result_name,
    unified_dim_sizes,
    apply_variable_ufunc,
    apply_dataarray_vfunc,
    apply_dataset_vfunc,
    apply_groupby_func,
    _calc_idxminmax,
    cov,
    corr,
    dot,
    where,
    polyval,
)

def test_result_name():
    class Obj:
        def __init__(self, name):
            self.name = name

    assert result_name([Obj("a"), Obj("a")]) == "a"
    assert result_name([Obj("a"), Obj("b")]) is None
    assert result_name([Obj(None), Obj(None)]) is None

def test_ordered_set_union():
    assert list(ordered_set_union([[1, 2], [2, 3]])) == [1, 2, 3]

def test_ordered_set_intersection():
    assert list(ordered_set_intersection([[1, 2], [2, 3]])) == [2]

def test_join_dict_keys():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert list(join_dict_keys([dict1, dict2], how='inner')) == ['b']
    assert list(join_dict_keys([dict1, dict2], how='outer')) == ['a', 'b', 'c']

def test_collect_dict_values():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert collect_dict_values([dict1, dict2], ['a', 'b', 'c'], fill_value=0) == [[1, 0], [2, 3], [0, 4]]

def test_unified_dim_sizes():
    var1 = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    var2 = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    assert unified_dim_sizes([var1, var2]) == {'x': 3, 'y': 4}

def test_apply_ufunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = apply_ufunc(np.sum, array, input_core_dims=[['x']], kwargs={'axis': -1})
    assert result.dims == ('y',)

def test_apply_variable_ufunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    signature = _UFuncSignature([['x']], [[]])
    result = apply_variable_ufunc(np.sum, array, signature=signature)
    assert result.dims == ()

def test_apply_dataarray_vfunc():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    signature = _UFuncSignature([['x']], [[]])
    result = apply_dataarray_vfunc(np.sum, array, signature=signature)
    assert result.dims == ()

def test_apply_dataset_vfunc():
    ds = Dataset({'a': ('x', np.random.rand(3)), 'b': ('x', np.random.rand(3))})
    signature = _UFuncSignature([['x']], [[]])
    result = apply_dataset_vfunc(np.sum, ds, signature=signature)
    assert 'x' not in result.dims

def test_apply_groupby_func():
    array = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    grouped = array.groupby('x')
    result = apply_groupby_func(np.sum, grouped)
    assert result.dims == ('x', 'y')

def test_cov():
    da_a = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = cov(da_a, da_b, dim='x')
    assert 'x' not in result.dims

def test_corr():
    da_a = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(3, 4), dims=['x', 'y'])
    result = corr(da_a, da_b, dim='x')
    assert 'x' not in result.dims

def test_dot():
    da_a = DataArray(np.random.rand(3, 2), dims=['x', 'y'])
    da_b = DataArray(np.random.rand(2, 4), dims=['y', 'z'])
    result = dot(da_a, da_b, dims='y')
    assert result.dims == ('x', 'z')

def test_where():
    cond = DataArray([True, False], dims='x')
    x = DataArray([1, 2], dims='x')
    y = DataArray([3, 4], dims='x')
    result = where(cond, x, y)
    assert result.equals(DataArray([1, 4], dims='x'))

def test_polyval():
    coord = DataArray(np.linspace(0, 1, 10), dims='x', name='x')
    coeffs = DataArray([1, 0, -1], dims='degree')
    result = polyval(coord, coeffs)
    assert result.dims == ('x', 'y')
Coverage: 55.63770794824399
Mutation Score: 35.91
Output: On branch main
Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        deleted:    .coveragerc

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_computation.py

no changes added to commit (use "git add" and/or "git commit -a")
commit 5158b9f686b505b09197b6b3c31c655344e6c014
Author: TestGenEval <>
Date:   Wed Dec 11 12:48:54 2024 +0000

    Testing fixes

diff --git a/xarray/core/computation.py b/xarray/core/computation.py
index 0c21ca07..04fda5a7 100644
--- a/xarray/core/computation.py
+++ b/xarray/core/computation.py
@@ -1359,7 +1359,8 @@ def _cov_corr(da_a, da_b, dim=None, ddof=0, method=None):
             da = da.where(~missing_vals)
             return da
         else:
-            return da
+            # ensure consistent return dtype
+            return da.astype(float)

     da_a = da_a.map_blocks(_get_valid_values, args=[da_b])
     da_b = da_b.map_blocks(_get_valid_values, args=[da_a])
diff --git a/xarray/core/parallel.py b/xarray/core/parallel.py
index 4917714a..f2025634 100644
--- a/xarray/core/parallel.py
+++ b/xarray/core/parallel.py
@@ -23,6 +23,7 @@ import numpy as np
 from .alignment import align
 from .dataarray import DataArray
 from .dataset import Dataset
+from .pycompat import is_dask_collection

 try:
     import dask
@@ -328,13 +329,13 @@ def map_blocks(
         raise TypeError("kwargs must be a mapping (for example, a dict)")

     for value in kwargs.values():
-        if dask.is_dask_collection(value):
+        if is_dask_collection(value):
             raise TypeError(
                 "Cannot pass dask collections in kwargs yet. Please compute or "
                 "load values before passing to map_blocks."
             )

-    if not dask.is_dask_collection(obj):
+    if not is_dask_collection(obj):
         return func(obj, *args, **kwargs)

     all_args = [obj] + list(args)
diff --git a/xarray/core/pycompat.py b/xarray/core/pycompat.py
index d1649235..d95dced9 100644
--- a/xarray/core/pycompat.py
+++ b/xarray/core/pycompat.py
@@ -43,15 +43,19 @@ class DuckArrayModule:
         self.available = duck_array_module is not None


-def is_duck_dask_array(x):
+def is_dask_collection(x):
     if DuckArrayModule("dask").available:
         from dask.base import is_dask_collection

-        return is_duck_array(x) and is_dask_collection(x)
+        return is_dask_collection(x)
     else:
         return False


+def is_duck_dask_array(x):
+    return is_duck_array(x) and is_dask_collection(x)
+
+
 dsk = DuckArrayModule("dask")
 dask_version = dsk.version
 dask_array_type = dsk.type
diff --git a/xarray/tests/test_computation.py b/xarray/tests/test_computation.py
deleted file mode 100644
index 22a3efce..00000000
--- a/xarray/tests/test_computation.py
+++ /dev/null
@@ -1,1932 +0,0 @@
-import functools
-import operator
-import pickle
-
-import numpy as np
-import pandas as pd
-import pytest
-from numpy.testing import assert_allclose, assert_array_equal
-
-import xarray as xr
-from xarray.core.alignment import broadcast
-from xarray.core.computation import (
-    _UFuncSignature,
-    apply_ufunc,
-    broadcast_compat_data,
-    collect_dict_values,
-    join_dict_keys,
-    ordered_set_intersection,
-    ordered_set_union,
-    result_name,
-    unified_dim_sizes,
-)
-from xarray.core.pycompat import dask_version
-
-from . import has_dask, raise_if_dask_computes, requires_dask
-
-dask = pytest.importorskip("dask")
-
-
-def assert_identical(a, b):
-    """A version of this function which accepts numpy arrays"""
-    __tracebackhide__ = True
-    from xarray.testing import assert_identical as assert_identical_
-
-    if hasattr(a, "identical"):
-        assert_identical_(a, b)
-    else:
-        assert_array_equal(a, b)
-
-
-def test_signature_properties() -> None:
-    sig = _UFuncSignature([["x"], ["x", "y"]], [["z"]])
-    assert sig.input_core_dims == (("x",), ("x", "y"))
-    assert sig.output_core_dims == (("z",),)
-    assert sig.all_input_core_dims == frozenset(["x", "y"])
-    assert sig.all_output_core_dims == frozenset(["z"])
-    assert sig.num_inputs == 2
-    assert sig.num_outputs == 1
-    assert str(sig) == "(x),(x,y)->(z)"
-    assert sig.to_gufunc_string() == "(dim0),(dim0,dim1)->(dim2)"
-    assert (
-        sig.to_gufunc_string(exclude_dims=set("x")) == "(dim0_0),(dim0_1,dim1)->(dim2)"
-    )
-    # dimension names matter
-    assert _UFuncSignature([["x"]]) != _UFuncSignature([["y"]])
-
-
-def test_result_name() -> None:
-    class Named:
-        def __init__(self, name=None):
-            self.name = name
-
-    assert result_name([1, 2]) is None
-    assert result_name([Named()]) is None
-    assert result_name([Named("foo"), 2]) == "foo"
-    assert result_name([Named("foo"), Named("bar")]) is None
-    assert result_name([Named("foo"), Named()]) is None
-
-
-def test_ordered_set_union() -> None:
-    assert list(ordered_set_union([[1, 2]])) == [1, 2]
-    assert list(ordered_set_union([[1, 2], [2, 1]])) == [1, 2]
-    assert list(ordered_set_union([[0], [1, 2], [1, 3]])) == [0, 1, 2, 3]
-
-
-def test_ordered_set_intersection() -> None:
-    assert list(ordered_set_intersection([[1, 2]])) == [1, 2]
-    assert list(ordered_set_intersection([[1, 2], [2, 1]])) == [1, 2]
-    assert list(ordered_set_intersection([[1, 2], [1, 3]])) == [1]
-    assert list(ordered_set_intersection([[1, 2], [2]])) == [2]
-
-
-def test_join_dict_keys() -> None:
-    dicts = [dict.fromkeys(keys) for keys in [["x", "y"], ["y", "z"]]]
-    assert list(join_dict_keys(dicts, "left")) == ["x", "y"]
-    assert list(join_dict_keys(dicts, "right")) == ["y", "z"]
-    assert list(join_dict_keys(dicts, "inner")) == ["y"]
-    assert list(join_dict_keys(dicts, "outer")) == ["x", "y", "z"]
-    with pytest.raises(ValueError):
-        join_dict_keys(dicts, "exact")
-    with pytest.raises(KeyError):
-        join_dict_keys(dicts, "foobar")
-
-
-def test_collect_dict_values() -> None:
-    dicts = [{"x": 1, "y": 2, "z": 3}, {"z": 4}, 5]
-    expected = [[1, 0, 5], [2, 0, 5], [3, 4, 5]]
-    collected = collect_dict_values(dicts, ["x", "y", "z"], fill_value=0)
-    assert collected == expected
-
-
-def identity(x):
-    return x
-
-
-def test_apply_identity() -> None:
-    array = np.arange(10)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    apply_identity = functools.partial(apply_ufunc, identity)
-
-    assert_identical(array, apply_identity(array))
-    assert_identical(variable, apply_identity(variable))
-    assert_identical(data_array, apply_identity(data_array))
-    assert_identical(data_array, apply_identity(data_array.groupby("x")))
-    assert_identical(dataset, apply_identity(dataset))
-    assert_identical(dataset, apply_identity(dataset.groupby("x")))
-
-
-def add(a, b):
-    return apply_ufunc(operator.add, a, b)
-
-
-def test_apply_two_inputs() -> None:
-    array = np.array([1, 2, 3])
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    zero_array = np.zeros_like(array)
-    zero_variable = xr.Variable("x", zero_array)
-    zero_data_array = xr.DataArray(zero_variable, [("x", -array)])
-    zero_dataset = xr.Dataset({"y": zero_variable}, {"x": -array})
-
-    assert_identical(array, add(array, zero_array))
-    assert_identical(array, add(zero_array, array))
-
-    assert_identical(variable, add(variable, zero_array))
-    assert_identical(variable, add(variable, zero_variable))
-    assert_identical(variable, add(zero_array, variable))
-    assert_identical(variable, add(zero_variable, variable))
-
-    assert_identical(data_array, add(data_array, zero_array))
-    assert_identical(data_array, add(data_array, zero_variable))
-    assert_identical(data_array, add(data_array, zero_data_array))
-    assert_identical(data_array, add(zero_array, data_array))
-    assert_identical(data_array, add(zero_variable, data_array))
-    assert_identical(data_array, add(zero_data_array, data_array))
-
-    assert_identical(dataset, add(dataset, zero_array))
-    assert_identical(dataset, add(dataset, zero_variable))
-    assert_identical(dataset, add(dataset, zero_data_array))
-    assert_identical(dataset, add(dataset, zero_dataset))
-    assert_identical(dataset, add(zero_array, dataset))
-    assert_identical(dataset, add(zero_variable, dataset))
-    assert_identical(dataset, add(zero_data_array, dataset))
-    assert_identical(dataset, add(zero_dataset, dataset))
-
-    assert_identical(data_array, add(data_array.groupby("x"), zero_data_array))
-    assert_identical(data_array, add(zero_data_array, data_array.groupby("x")))
-
-    assert_identical(dataset, add(data_array.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_dataset, data_array.groupby("x")))
-
-    assert_identical(dataset, add(dataset.groupby("x"), zero_data_array))
-    assert_identical(dataset, add(dataset.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_data_array, dataset.groupby("x")))
-    assert_identical(dataset, add(zero_dataset, dataset.groupby("x")))
-
-
-def test_apply_1d_and_0d() -> None:
-    array = np.array([1, 2, 3])
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    zero_array = 0
-    zero_variable = xr.Variable((), zero_array)
-    zero_data_array = xr.DataArray(zero_variable)
-    zero_dataset = xr.Dataset({"y": zero_variable})
-
-    assert_identical(array, add(array, zero_array))
-    assert_identical(array, add(zero_array, array))
-
-    assert_identical(variable, add(variable, zero_array))
-    assert_identical(variable, add(variable, zero_variable))
-    assert_identical(variable, add(zero_array, variable))
-    assert_identical(variable, add(zero_variable, variable))
-
-    assert_identical(data_array, add(data_array, zero_array))
-    assert_identical(data_array, add(data_array, zero_variable))
-    assert_identical(data_array, add(data_array, zero_data_array))
-    assert_identical(data_array, add(zero_array, data_array))
-    assert_identical(data_array, add(zero_variable, data_array))
-    assert_identical(data_array, add(zero_data_array, data_array))
-
-    assert_identical(dataset, add(dataset, zero_array))
-    assert_identical(dataset, add(dataset, zero_variable))
-    assert_identical(dataset, add(dataset, zero_data_array))
-    assert_identical(dataset, add(dataset, zero_dataset))
-    assert_identical(dataset, add(zero_array, dataset))
-    assert_identical(dataset, add(zero_variable, dataset))
-    assert_identical(dataset, add(zero_data_array, dataset))
-    assert_identical(dataset, add(zero_dataset, dataset))
-
-    assert_identical(data_array, add(data_array.groupby("x"), zero_data_array))
-    assert_identical(data_array, add(zero_data_array, data_array.groupby("x")))
-
-    assert_identical(dataset, add(data_array.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_dataset, data_array.groupby("x")))
-
-    assert_identical(dataset, add(dataset.groupby("x"), zero_data_array))
-    assert_identical(dataset, add(dataset.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_data_array, dataset.groupby("x")))
-    assert_identical(dataset, add(zero_dataset, dataset.groupby("x")))
-
-
-def test_apply_two_outputs() -> None:
-    array = np.arange(5)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    def twice(obj):
-        def func(x):
-            return (x, x)
-
-        return apply_ufunc(func, obj, output_core_dims=[[], []])
-
-    out0, out1 = twice(array)
-    assert_identical(out0, array)
-    assert_identical(out1, array)
-
-    out0, out1 = twice(variable)
-    assert_identical(out0, variable)
-    assert_identical(out1, variable)
-
-    out0, out1 = twice(data_array)
-    assert_identical(out0, data_array)
-    assert_identical(out1, data_array)
-
-    out0, out1 = twice(dataset)
-    assert_identical(out0, dataset)
-    assert_identical(out1, dataset)
-
-    out0, out1 = twice(data_array.groupby("x"))
-    assert_identical(out0, data_array)
-    assert_identical(out1, data_array)
-
-    out0, out1 = twice(dataset.groupby("x"))
-    assert_identical(out0, dataset)
-    assert_identical(out1, dataset)
-
-
-@requires_dask
-def test_apply_dask_parallelized_two_outputs() -> None:
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-
-    def twice(obj):
-        def func(x):
-            return (x, x)
-
-        return apply_ufunc(func, obj, output_core_dims=[[], []], dask="parallelized")
-
-    out0, out1 = twice(data_array.chunk({"x": 1}))
-    assert_identical(data_array, out0)
-    assert_identical(data_array, out1)
-
-
-def test_apply_input_core_dimension() -> None:
-    def first_element(obj, dim):
-        def func(x):
-            return x[..., 0]
-
-        return apply_ufunc(func, obj, input_core_dims=[[dim]])
-
-    array = np.array([[1, 2], [3, 4]])
-    variable = xr.Variable(["x", "y"], array)
-    data_array = xr.DataArray(variable, {"x": ["a", "b"], "y": [-1, -2]})
-    dataset = xr.Dataset({"data": data_array})
-
-    expected_variable_x = xr.Variable(["y"], [1, 2])
-    expected_data_array_x = xr.DataArray(expected_variable_x, {"y": [-1, -2]})
-    expected_dataset_x = xr.Dataset({"data": expected_data_array_x})
-
-    expected_variable_y = xr.Variable(["x"], [1, 3])
-    expected_data_array_y = xr.DataArray(expected_variable_y, {"x": ["a", "b"]})
-    expected_dataset_y = xr.Dataset({"data": expected_data_array_y})
-
-    assert_identical(expected_variable_x, first_element(variable, "x"))
-    assert_identical(expected_variable_y, first_element(variable, "y"))
-
-    assert_identical(expected_data_array_x, first_element(data_array, "x"))
-    assert_identical(expected_data_array_y, first_element(data_array, "y"))
-
-    assert_identical(expected_dataset_x, first_element(dataset, "x"))
-    assert_identical(expected_dataset_y, first_element(dataset, "y"))
-
-    assert_identical(expected_data_array_x, first_element(data_array.groupby("y"), "x"))
-    assert_identical(expected_dataset_x, first_element(dataset.groupby("y"), "x"))
-
-    def multiply(*args):
-        val = args[0]
-        for arg in args[1:]:
-            val = val * arg
-        return val
-
-    # regression test for GH:2341
-    with pytest.raises(ValueError):
-        apply_ufunc(
-            multiply,
-            data_array,
-            data_array["y"].values,
-            input_core_dims=[["y"]],
-            output_core_dims=[["y"]],
-        )
-    expected = xr.DataArray(
-        multiply(data_array, data_array["y"]), dims=["x", "y"], coords=data_array.coords
-    )
-    actual = apply_ufunc(
-        multiply,
-        data_array,
-        data_array["y"].values,
-        input_core_dims=[["y"], []],
-        output_core_dims=[["y"]],
-    )
-    assert_identical(expected, actual)
-
-
-def test_apply_output_core_dimension() -> None:
-    def stack_negative(obj):
-        def func(x):
-            return np.stack([x, -x], axis=-1)
-
-        result = apply_ufunc(func, obj, output_core_dims=[["sign"]])
-        if isinstance(result, (xr.Dataset, xr.DataArray)):
-            result.coords["sign"] = [1, -1]
-        return result
-
-    array = np.array([[1, 2], [3, 4]])
-    variable = xr.Variable(["x", "y"], array)
-    data_array = xr.DataArray(variable, {"x": ["a", "b"], "y": [-1, -2]})
-    dataset = xr.Dataset({"data": data_array})
-
-    stacked_array = np.array([[[1, -1], [2, -2]], [[3, -3], [4, -4]]])
-    stacked_variable = xr.Variable(["x", "y", "sign"], stacked_array)
-    stacked_coords = {"x": ["a", "b"], "y": [-1, -2], "sign": [1, -1]}
-    stacked_data_array = xr.DataArray(stacked_variable, stacked_coords)
-    stacked_dataset = xr.Dataset({"data": stacked_data_array})
-
-    assert_identical(stacked_array, stack_negative(array))
-    assert_identical(stacked_variable, stack_negative(variable))
-    assert_identical(stacked_data_array, stack_negative(data_array))
-    assert_identical(stacked_dataset, stack_negative(dataset))
-    assert_identical(stacked_data_array, stack_negative(data_array.groupby("x")))
-    assert_identical(stacked_dataset, stack_negative(dataset.groupby("x")))
-
-    def original_and_stack_negative(obj):
-        def func(x):
-            return (x, np.stack([x, -x], axis=-1))
-
-        result = apply_ufunc(func, obj, output_core_dims=[[], ["sign"]])
-        if isinstance(result[1], (xr.Dataset, xr.DataArray)):
-            result[1].coords["sign"] = [1, -1]
-        return result
-
-    out0, out1 = original_and_stack_negative(array)
-    assert_identical(array, out0)
-    assert_identical(stacked_array, out1)
-
-    out0, out1 = original_and_stack_negative(variable)
-    assert_identical(variable, out0)
-    assert_identical(stacked_variable, out1)
-
-    out0, out1 = original_and_stack_negative(data_array)
-    assert_identical(data_array, out0)
-    assert_identical(stacked_data_array, out1)
-
-    out0, out1 = original_and_stack_negative(dataset)
-    assert_identical(dataset, out0)
-    assert_identical(stacked_dataset, out1)
-
-    out0, out1 = original_and_stack_negative(data_array.groupby("x"))
-    assert_identical(data_array, out0)
-    assert_identical(stacked_data_array, out1)
-
-    out0, out1 = original_and_stack_negative(dataset.groupby("x"))
-    assert_identical(dataset, out0)
-    assert_identical(stacked_dataset, out1)
-
-
-def test_apply_exclude() -> None:
-    def concatenate(objects, dim="x"):
-        def func(*x):
-            return np.concatenate(x, axis=-1)
-
-        result = apply_ufunc(
-            func,
-            *objects,
-            input_core_dims=[[dim]] * len(objects),
-            output_core_dims=[[dim]],
-            exclude_dims={dim},
-        )
-        if isinstance(result, (xr.Dataset, xr.DataArray)):
-            # note: this will fail if dim is not a coordinate on any input
-            new_coord = np.concatenate([obj.coords[dim] for obj in objects])
-            result.coords[dim] = new_coord
-        return result
-
-    arrays = [np.array([1]), np.array([2, 3])]
-    variables = [xr.Variable("x", a) for a in arrays]
-    data_arrays = [
-        xr.DataArray(v, {"x": c, "y": ("x", range(len(c)))})
-        for v, c in zip(variables, [["a"], ["b", "c"]])
-    ]
-    datasets = [xr.Dataset({"data": data_array}) for data_array in data_arrays]
-
-    expected_array = np.array([1, 2, 3])
-    expected_variable = xr.Variable("x", expected_array)
-    expected_data_array = xr.DataArray(expected_variable, [("x", list("abc"))])
-    expected_dataset = xr.Dataset({"data": expected_data_array})
-
-    assert_identical(expected_array, concatenate(arrays))
-    assert_identical(expected_variable, concatenate(variables))
-    assert_identical(expected_data_array, concatenate(data_arrays))
-    assert_identical(expected_dataset, concatenate(datasets))
-
-    # must also be a core dimension
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, variables[0], exclude_dims={"x"})
-
-
-def test_apply_groupby_add() -> None:
-    array = np.arange(5)
-    variable = xr.Variable("x", array)
-    coords = {"x": -array, "y": ("x", [0, 0, 1, 1, 2])}
-    data_array = xr.DataArray(variable, coords, dims="x")
-    dataset = xr.Dataset({"z": variable}, coords)
-
-    other_variable = xr.Variable("y", [0, 10])
-    other_data_array = xr.DataArray(other_variable, dims="y")
-    other_dataset = xr.Dataset({"z": other_variable})
-
-    expected_variable = xr.Variable("x", [0, 1, 12, 13, np.nan])
-    expected_data_array = xr.DataArray(expected_variable, coords, dims="x")
-    expected_dataset = xr.Dataset({"z": expected_variable}, coords)
-
-    assert_identical(
-        expected_data_array, add(data_array.groupby("y"), other_data_array)
-    )
-    assert_identical(expected_dataset, add(data_array.groupby("y"), other_dataset))
-    assert_identical(expected_dataset, add(dataset.groupby("y"), other_data_array))
-    assert_identical(expected_dataset, add(dataset.groupby("y"), other_dataset))
-
-    # cannot be performed with xarray.Variable objects that share a dimension
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), other_variable)
-
-    # if they are all grouped the same way
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array[:4].groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array[1:].groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), other_data_array.groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array.groupby("x"))
-
-
-def test_unified_dim_sizes() -> None:
-    assert unified_dim_sizes([xr.Variable((), 0)]) == {}
-    assert unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("x", [1])]) == {"x": 1}
-    assert unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("y", [1, 2])]) == {
-        "x": 1,
-        "y": 2,
-    }
-    assert (
-        unified_dim_sizes(
-            [xr.Variable(("x", "z"), [[1]]), xr.Variable(("y", "z"), [[1, 2], [3, 4]])],
-            exclude_dims={"z"},
-        )
-        == {"x": 1, "y": 2}
-    )
-
-    # duplicate dimensions
-    with pytest.raises(ValueError):
-        unified_dim_sizes([xr.Variable(("x", "x"), [[1]])])
-
-    # mismatched lengths
-    with pytest.raises(ValueError):
-        unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("x", [1, 2])])
-
-
-def test_broadcast_compat_data_1d() -> None:
-    data = np.arange(5)
-    var = xr.Variable("x", data)
-
-    assert_identical(data, broadcast_compat_data(var, ("x",), ()))
-    assert_identical(data, broadcast_compat_data(var, (), ("x",)))
-    assert_identical(data[:], broadcast_compat_data(var, ("w",), ("x",)))
-    assert_identical(data[:, None], broadcast_compat_data(var, ("w", "x", "y"), ()))
-
-    with pytest.raises(ValueError):
-        broadcast_compat_data(var, ("x",), ("w",))
-
-    with pytest.raises(ValueError):
-        broadcast_compat_data(var, (), ())
-
-
-def test_broadcast_compat_data_2d() -> None:
-    data = np.arange(12).reshape(3, 4)
-    var = xr.Variable(["x", "y"], data)
-
-    assert_identical(data, broadcast_compat_data(var, ("x", "y"), ()))
-    assert_identical(data, broadcast_compat_data(var, ("x",), ("y",)))
-    assert_identical(data, broadcast_compat_data(var, (), ("x", "y")))
-    assert_identical(data.T, broadcast_compat_data(var, ("y", "x"), ()))
-    assert_identical(data.T, broadcast_compat_data(var, ("y",), ("x",)))
-    assert_identical(data, broadcast_compat_data(var, ("w", "x"), ("y",)))
-    assert_identical(data, broadcast_compat_data(var, ("w",), ("x", "y")))
-    assert_identical(data.T, broadcast_compat_data(var, ("w",), ("y", "x")))
-    assert_identical(
-        data[:, :, None], broadcast_compat_data(var, ("w", "x", "y", "z"), ())
-    )
-    assert_identical(
-        data[None, :, :].T, broadcast_compat_data(var, ("w", "y", "x", "z"), ())
-    )
-
-
-def test_keep_attrs() -> None:
-    def add(a, b, keep_attrs):
-        if keep_attrs:
-            return apply_ufunc(operator.add, a, b, keep_attrs=keep_attrs)
-        else:
-            return apply_ufunc(operator.add, a, b)
-
-    a = xr.DataArray([0, 1], [("x", [0, 1])])
-    a.attrs["attr"] = "da"
-    a["x"].attrs["attr"] = "da_coord"
-    b = xr.DataArray([1, 2], [("x", [0, 1])])
-
-    actual = add(a, b, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(a, b, keep_attrs=True)
-    assert_identical(actual.attrs, a.attrs)
-    assert_identical(actual["x"].attrs, a["x"].attrs)
-
-    actual = add(a.variable, b.variable, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(a.variable, b.variable, keep_attrs=True)
-    assert_identical(actual.attrs, a.attrs)
-
-    ds_a = xr.Dataset({"x": [0, 1]})
-    ds_a.attrs["attr"] = "ds"
-    ds_a.x.attrs["attr"] = "da"
-    ds_b = xr.Dataset({"x": [0, 1]})
-
-    actual = add(ds_a, ds_b, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(ds_a, ds_b, keep_attrs=True)
-    assert_identical(actual.attrs, ds_a.attrs)
-    assert_identical(actual.x.attrs, ds_a.x.attrs)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_variable(strategy, attrs, expected, error) -> None:
-    a = xr.Variable("x", [0, 1], attrs=attrs[0])
-    b = xr.Variable("x", [0, 1], attrs=attrs[1])
-    c = xr.Variable("x", [0, 1], attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.Variable("x", [0, 3], attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataarray(strategy, attrs, expected, error) -> None:
-    a = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[0])
-    b = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[1])
-    c = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.DataArray(dims="x", data=[0, 3], attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize("variant", ("dim", "coord"))
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataarray_variables(
-    variant, strategy, attrs, expected, error
-):
-    compute_attrs = {
-        "dim": lambda attrs, default: (attrs, default),
-        "coord": lambda attrs, default: (default, attrs),
-    }.get(variant)
-
-    dim_attrs, coord_attrs = compute_attrs(attrs, [{}, {}, {}])
-
-    a = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[0]), "u": ("x", [0, 1], coord_attrs[0])},
-    )
-    b = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[1]), "u": ("x", [0, 1], coord_attrs[1])},
-    )
-    c = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[2]), "u": ("x", [0, 1], coord_attrs[2])},
-    )
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        dim_attrs, coord_attrs = compute_attrs(expected, {})
-        expected = xr.DataArray(
-            dims="x",
-            data=[0, 3],
-            coords={"x": ("x", [0, 1], dim_attrs), "u": ("x", [0, 1], coord_attrs)},
-        )
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataset(strategy, attrs, expected, error) -> None:
-    a = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[0])
-    b = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[1])
-    c = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.Dataset({"a": ("x", [0, 3])}, attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize("variant", ("data", "dim", "coord"))
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataset_variables(
-    variant, strategy, attrs, expected, error
-):
-    compute_attrs = {
-        "data": lambda attrs, default: (attrs, default, default),
-        "dim": lambda attrs, default: (default, attrs, default),
-        "coord": lambda attrs, default: (default, default, attrs),
-    }.get(variant)
-    data_attrs, dim_attrs, coord_attrs = compute_attrs(attrs, [{}, {}, {}])
-
-    a = xr.Dataset(
-        {"a": ("x", [], data_attrs[0])},
-        coords={"x": ("x", [], dim_attrs[0]), "u": ("x", [], coord_attrs[0])},
-    )
-    b = xr.Dataset(
-        {"a": ("x", [], data_attrs[1])},
-        coords={"x": ("x", [], dim_attrs[1]), "u": ("x", [], coord_attrs[1])},
-    )
-    c = xr.Dataset(
-        {"a": ("x", [], data_attrs[2])},
-        coords={"x": ("x", [], dim_attrs[2]), "u": ("x", [], coord_attrs[2])},
-    )
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        data_attrs, dim_attrs, coord_attrs = compute_attrs(expected, {})
-        expected = xr.Dataset(
-            {"a": ("x", [], data_attrs)},
-            coords={"x": ("x", [], dim_attrs), "u": ("x", [], coord_attrs)},
-        )
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-def test_dataset_join() -> None:
-    ds0 = xr.Dataset({"a": ("x", [1, 2]), "x": [0, 1]})
-    ds1 = xr.Dataset({"a": ("x", [99, 3]), "x": [1, 2]})
-
-    # by default, cannot have different labels
-    with pytest.raises(ValueError, match=r"indexes .* are not equal"):
-        apply_ufunc(operator.add, ds0, ds1)
-    with pytest.raises(TypeError, match=r"must supply"):
-        apply_ufunc(operator.add, ds0, ds1, dataset_join="outer")
-
-    def add(a, b, join, dataset_join):
-        return apply_ufunc(
-            operator.add,
-            a,
-            b,
-            join=join,
-            dataset_join=dataset_join,
-            dataset_fill_value=np.nan,
-        )
-
-    actual = add(ds0, ds1, "outer", "inner")
-    expected = xr.Dataset({"a": ("x", [np.nan, 101, np.nan]), "x": [0, 1, 2]})
-    assert_identical(actual, expected)
-
-    actual = add(ds0, ds1, "outer", "outer")
-    assert_identical(actual, expected)
-
-    with pytest.raises(ValueError, match=r"data variable names"):
-        apply_ufunc(operator.add, ds0, xr.Dataset({"b": 1}))
-
-    ds2 = xr.Dataset({"b": ("x", [99, 3]), "x": [1, 2]})
-    actual = add(ds0, ds2, "outer", "inner")
-    expected = xr.Dataset({"x": [0, 1, 2]})
-    assert_identical(actual, expected)
-
-    # we used np.nan as the fill_value in add() above
-    actual = add(ds0, ds2, "outer", "outer")
-    expected = xr.Dataset(
-        {
-            "a": ("x", [np.nan, np.nan, np.nan]),
-            "b": ("x", [np.nan, np.nan, np.nan]),
-            "x": [0, 1, 2],
-        }
-    )
-    assert_identical(actual, expected)
-
-
-@requires_dask
-def test_apply_dask() -> None:
-    import dask.array as da
-
-    array = da.ones((2,), chunks=2)
-    variable = xr.Variable("x", array)
-    coords = xr.DataArray(variable).coords.variables
-    data_array = xr.DataArray(variable, dims=["x"], coords=coords)
-    dataset = xr.Dataset({"y": variable})
-
-    # encountered dask array, but did not set dask='allowed'
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, array)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, variable)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, data_array)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, dataset)
-
-    # unknown setting for dask array handling
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, array, dask="unknown")
-
-    def dask_safe_identity(x):
-        return apply_ufunc(identity, x, dask="allowed")
-
-    assert array is dask_safe_identity(array)
-
-    actual = dask_safe_identity(variable)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(variable, actual)
-
-    actual = dask_safe_identity(data_array)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(data_array, actual)
-
-    actual = dask_safe_identity(dataset)
-    assert isinstance(actual["y"].data, da.Array)
-    assert_identical(dataset, actual)
-
-
-@requires_dask
-def test_apply_dask_parallelized_one_arg() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    def parallel_identity(x):
-        return apply_ufunc(identity, x, dask="parallelized", output_dtypes=[x.dtype])
-
-    actual = parallel_identity(data_array)
-    assert isinstance(actual.data, da.Array)
-    assert actual.data.chunks == array.chunks
-    assert_identical(data_array, actual)
-
-    computed = data_array.compute()
-    actual = parallel_identity(computed)
-    assert_identical(computed, actual)
-
-
-@requires_dask
-def test_apply_dask_parallelized_two_args() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1), dtype=np.int64)
-    data_array = xr.DataArray(array, dims=("x", "y"))
-    data_array.name = None
-
-    def parallel_add(x, y):
-        return apply_ufunc(
-            operator.add, x, y, dask="parallelized", output_dtypes=[np.int64]
-        )
-
-    def check(x, y):
-        actual = parallel_add(x, y)
-        assert isinstance(actual.data, da.Array)
-        assert actual.data.chunks == array.chunks
-        assert_identical(data_array, actual)
-
-    check(data_array, 0),
-    check(0, data_array)
-    check(data_array, xr.DataArray(0))
-    check(data_array, 0 * data_array)
-    check(data_array, 0 * data_array[0])
-    check(data_array[:, 0], 0 * data_array[0])
-    check(data_array, 0 * data_array.compute())
-
-
-@requires_dask
-def test_apply_dask_parallelized_errors() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    # from apply_array_ufunc
-    with pytest.raises(ValueError, match=r"at least one input is an xarray object"):
-        apply_ufunc(identity, array, dask="parallelized")
-
-    # formerly from _apply_blockwise, now from apply_variable_ufunc
-    with pytest.raises(ValueError, match=r"consists of multiple chunks"):
-        apply_ufunc(
-            identity,
-            data_array,
-            dask="parallelized",
-            output_dtypes=[float],
-            input_core_dims=[("y",)],
-            output_core_dims=[("y",)],
-        )
-
-
-# it's currently impossible to silence these warnings from inside dask.array:
-# https://github.com/dask/dask/issues/3245
-@requires_dask
-@pytest.mark.filterwarnings("ignore:Mean of empty slice")
-def test_apply_dask_multiple_inputs() -> None:
-    import dask.array as da
-
-    def covariance(x, y):
-        return (
-            (x - x.mean(axis=-1, keepdims=True)) * (y - y.mean(axis=-1, keepdims=True))
-        ).mean(axis=-1)
-
-    rs = np.random.RandomState(42)
-    array1 = da.from_array(rs.randn(4, 4), chunks=(2, 4))
-    array2 = da.from_array(rs.randn(4, 4), chunks=(2, 4))
-    data_array_1 = xr.DataArray(array1, dims=("x", "z"))
-    data_array_2 = xr.DataArray(array2, dims=("y", "z"))
-
-    expected = apply_ufunc(
-        covariance,
-        data_array_1.compute(),
-        data_array_2.compute(),
-        input_core_dims=[["z"], ["z"]],
-    )
-    allowed = apply_ufunc(
-        covariance,
-        data_array_1,
-        data_array_2,
-        input_core_dims=[["z"], ["z"]],
-        dask="allowed",
-    )
-    assert isinstance(allowed.data, da.Array)
-    xr.testing.assert_allclose(expected, allowed.compute())
-
-    parallelized = apply_ufunc(
-        covariance,
-        data_array_1,
-        data_array_2,
-        input_core_dims=[["z"], ["z"]],
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert isinstance(parallelized.data, da.Array)
-    xr.testing.assert_allclose(expected, parallelized.compute())
-
-
-@requires_dask
-def test_apply_dask_new_output_dimension() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    def stack_negative(obj):
-        def func(x):
-            return np.stack([x, -x], axis=-1)
-
-        return apply_ufunc(
-            func,
-            obj,
-            output_core_dims=[["sign"]],
-            dask="parallelized",
-            output_dtypes=[obj.dtype],
-            dask_gufunc_kwargs=dict(output_sizes={"sign": 2}),
-        )
-
-    expected = stack_negative(data_array.compute())
-
-    actual = stack_negative(data_array)
-    assert actual.dims == ("x", "y", "sign")
-    assert actual.shape == (2, 2, 2)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_apply_dask_new_output_sizes() -> None:
-    ds = xr.Dataset({"foo": (["lon", "lat"], np.arange(10 * 10).reshape((10, 10)))})
-    ds["bar"] = ds["foo"]
-    newdims = {"lon_new": 3, "lat_new": 6}
-
-    def extract(obj):
-        def func(da):
-            return da[1:4, 1:7]
-
-        return apply_ufunc(
-            func,
-            obj,
-            dask="parallelized",
-            input_core_dims=[["lon", "lat"]],
-            output_core_dims=[["lon_new", "lat_new"]],
-            dask_gufunc_kwargs=dict(output_sizes=newdims),
-        )
-
-    expected = extract(ds)
-
-    actual = extract(ds.chunk())
-    assert actual.dims == {"lon_new": 3, "lat_new": 6}
-    assert_identical(expected.chunk(), actual)
-
-
-def pandas_median(x):
-    return pd.Series(x).median()
-
-
-def test_vectorize() -> None:
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median, data_array, input_core_dims=[["y"]], vectorize=True
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_dask() -> None:
-    # run vectorization in dask.array.gufunc by using `dask='parallelized'`
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_dask_dtype() -> None:
-    # ensure output_dtypes is preserved with vectorize=True
-    # GH4015
-
-    # integer
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[int],
-    )
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-    # complex
-    data_array = xr.DataArray([[0 + 0j, 1 + 2j, 2 + 1j]], dims=("x", "y"))
-    expected = data_array.copy()
-    actual = apply_ufunc(
-        identity,
-        data_array.chunk({"x": 1}),
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[complex],
-    )
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-
-@requires_dask
-@pytest.mark.parametrize(
-    "data_array",
-    [
-        xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y")),
-        xr.DataArray([[0 + 0j, 1 + 2j, 2 + 1j]], dims=("x", "y")),
-    ],
-)
-def test_vectorize_dask_dtype_without_output_dtypes(data_array) -> None:
-    # ensure output_dtypes is preserved with vectorize=True
-    # GH4015
-
-    expected = data_array.copy()
-    actual = apply_ufunc(
-        identity,
-        data_array.chunk({"x": 1}),
-        vectorize=True,
-        dask="parallelized",
-    )
-
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-
-@pytest.mark.skipif(
-    dask_version > "2021.06",
-    reason="dask/dask#7669: can no longer pass output_dtypes and meta",
-)
-@requires_dask
-def test_vectorize_dask_dtype_meta() -> None:
-    # meta dtype takes precedence
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[int],
-        dask_gufunc_kwargs=dict(meta=np.ndarray((0, 0), dtype=float)),
-    )
-
-    assert_identical(expected, actual)
-    assert float == actual.dtype
-
-
-def pandas_median_add(x, y):
-    # function which can consume input of unequal length
-    return pd.Series(x).median() + pd.Series(y).median()
-
-
-def test_vectorize_exclude_dims() -> None:
-    # GH 3890
-    data_array_a = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    data_array_b = xr.DataArray([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dims=("x", "y"))
-
-    expected = xr.DataArray([3, 5], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median_add,
-        data_array_a,
-        data_array_b,
-        input_core_dims=[["y"], ["y"]],
-        vectorize=True,
-        exclude_dims=set("y"),
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_exclude_dims_dask() -> None:
-    # GH 3890
-    data_array_a = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    data_array_b = xr.DataArray([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dims=("x", "y"))
-
-    expected = xr.DataArray([3, 5], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median_add,
-        data_array_a.chunk({"x": 1}),
-        data_array_b.chunk({"x": 1}),
-        input_core_dims=[["y"], ["y"]],
-        exclude_dims=set("y"),
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert_identical(expected, actual)
-
-
-def test_corr_only_dataarray() -> None:
-    with pytest.raises(TypeError, match="Only xr.DataArray is supported"):
-        xr.corr(xr.Dataset(), xr.Dataset())
-
-
-def arrays_w_tuples():
-    da = xr.DataArray(
-        np.random.random((3, 21, 4)),
-        coords={"time": pd.date_range("2000-01-01", freq="1D", periods=21)},
-        dims=("a", "time", "x"),
-    )
-
-    arrays = [
-        da.isel(time=range(0, 18)),
-        da.isel(time=range(2, 20)).rolling(time=3, center=True).mean(),
-        xr.DataArray([[1, 2], [1, np.nan]], dims=["x", "time"]),
-        xr.DataArray([[1, 2], [np.nan, np.nan]], dims=["x", "time"]),
-        xr.DataArray([[1, 2], [2, 1]], dims=["x", "time"]),
-    ]
-
-    array_tuples = [
-        (arrays[0], arrays[0]),
-        (arrays[0], arrays[1]),
-        (arrays[1], arrays[1]),
-        (arrays[2], arrays[2]),
-        (arrays[2], arrays[3]),
-        (arrays[2], arrays[4]),
-        (arrays[4], arrays[2]),
-        (arrays[3], arrays[3]),
-        (arrays[4], arrays[4]),
-    ]
-
-    return arrays, array_tuples
-
-
-@pytest.mark.parametrize("ddof", [0, 1])
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [
-        arrays_w_tuples()[1][3],
-        arrays_w_tuples()[1][4],
-        arrays_w_tuples()[1][5],
-        arrays_w_tuples()[1][6],
-        arrays_w_tuples()[1][7],
-        arrays_w_tuples()[1][8],
-    ],
-)
-@pytest.mark.parametrize("dim", [None, "x", "time"])
-def test_lazy_corrcov(da_a, da_b, dim, ddof) -> None:
-    # GH 5284
-    from dask import is_dask_collection
-
-    with raise_if_dask_computes():
-        cov = xr.cov(da_a.chunk(), da_b.chunk(), dim=dim, ddof=ddof)
-        assert is_dask_collection(cov)
-
-        corr = xr.corr(da_a.chunk(), da_b.chunk(), dim=dim)
-        assert is_dask_collection(corr)
-
-
-@pytest.mark.parametrize("ddof", [0, 1])
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [arrays_w_tuples()[1][0], arrays_w_tuples()[1][1], arrays_w_tuples()[1][2]],
-)
-@pytest.mark.parametrize("dim", [None, "time"])
-def test_cov(da_a, da_b, dim, ddof) -> None:
-    if dim is not None:
-
-        def np_cov_ind(ts1, ts2, a, x):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            # While dropping isn't ideal here, numpy will return nan
-            # if any segment contains a NaN.
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.cov(
-                np.ma.masked_invalid(ts1.sel(a=a, x=x).data.flatten()),
-                np.ma.masked_invalid(ts2.sel(a=a, x=x).data.flatten()),
-                ddof=ddof,
-            )[0, 1]
-
-        expected = np.zeros((3, 4))
-        for a in [0, 1, 2]:
-            for x in [0, 1, 2, 3]:
-                expected[a, x] = np_cov_ind(da_a, da_b, a=a, x=x)
-        actual = xr.cov(da_a, da_b, dim=dim, ddof=ddof)
-        assert_allclose(actual, expected)
-
-    else:
-
-        def np_cov(ts1, ts2):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.cov(
-                np.ma.masked_invalid(ts1.data.flatten()),
-                np.ma.masked_invalid(ts2.data.flatten()),
-                ddof=ddof,
-            )[0, 1]
-
-        expected = np_cov(da_a, da_b)
-        actual = xr.cov(da_a, da_b, dim=dim, ddof=ddof)
-        assert_allclose(actual, expected)
-
-
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [arrays_w_tuples()[1][0], arrays_w_tuples()[1][1], arrays_w_tuples()[1][2]],
-)
-@pytest.mark.parametrize("dim", [None, "time"])
-def test_corr(da_a, da_b, dim) -> None:
-    if dim is not None:
-
-        def np_corr_ind(ts1, ts2, a, x):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.corrcoef(
-                np.ma.masked_invalid(ts1.sel(a=a, x=x).data.flatten()),
-                np.ma.masked_invalid(ts2.sel(a=a, x=x).data.flatten()),
-            )[0, 1]
-
-        expected = np.zeros((3, 4))
-        for a in [0, 1, 2]:
-            for x in [0, 1, 2, 3]:
-                expected[a, x] = np_corr_ind(da_a, da_b, a=a, x=x)
-        actual = xr.corr(da_a, da_b, dim)
-        assert_allclose(actual, expected)
-
-    else:
-
-        def np_corr(ts1, ts2):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.corrcoef(
-                np.ma.masked_invalid(ts1.data.flatten()),
-                np.ma.masked_invalid(ts2.data.flatten()),
-            )[0, 1]
-
-        expected = np_corr(da_a, da_b)
-        actual = xr.corr(da_a, da_b, dim)
-        assert_allclose(actual, expected)
-
-
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    arrays_w_tuples()[1],
-)
-@pytest.mark.parametrize("dim", [None, "time", "x"])
-def test_covcorr_consistency(da_a, da_b, dim) -> None:
-    # Testing that xr.corr and xr.cov are consistent with each other
-    # 1. Broadcast the two arrays
-    da_a, da_b = broadcast(da_a, da_b)
-    # 2. Ignore the nans
-    valid_values = da_a.notnull() & da_b.notnull()
-    da_a = da_a.where(valid_values)
-    da_b = da_b.where(valid_values)
-
-    expected = xr.cov(da_a, da_b, dim=dim, ddof=0) / (
-        da_a.std(dim=dim) * da_b.std(dim=dim)
-    )
-    actual = xr.corr(da_a, da_b, dim=dim)
-    assert_allclose(actual, expected)
-
-
-@pytest.mark.parametrize(
-    "da_a",
-    arrays_w_tuples()[0],
-)
-@pytest.mark.parametrize("dim", [None, "time", "x", ["time", "x"]])
-def test_autocov(da_a, dim) -> None:
-    # Testing that the autocovariance*(N-1) is ~=~ to the variance matrix
-    # 1. Ignore the nans
-    valid_values = da_a.notnull()
-    # Because we're using ddof=1, this requires > 1 value in each sample
-    da_a = da_a.where(valid_values.sum(dim=dim) > 1)
-    expected = ((da_a - da_a.mean(dim=dim)) ** 2).sum(dim=dim, skipna=True, min_count=1)
-    actual = xr.cov(da_a, da_a, dim=dim) * (valid_values.sum(dim) - 1)
-    assert_allclose(actual, expected)
-
-
-@requires_dask
-def test_vectorize_dask_new_output_dims() -> None:
-    # regression test for GH3574
-    # run vectorization in dask.array.gufunc by using `dask='parallelized'`
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    func = lambda x: x[np.newaxis, ...]
-    expected = data_array.expand_dims("z")
-    actual = apply_ufunc(
-        func,
-        data_array.chunk({"x": 1}),
-        output_core_dims=[["z"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-        dask_gufunc_kwargs=dict(output_sizes={"z": 1}),
-    ).transpose(*expected.dims)
-    assert_identical(expected, actual)
-
-    with pytest.raises(
-        ValueError, match=r"dimension 'z1' in 'output_sizes' must correspond"
-    ):
-        apply_ufunc(
-            func,
-            data_array.chunk({"x": 1}),
-            output_core_dims=[["z"]],
-            vectorize=True,
-            dask="parallelized",
-            output_dtypes=[float],
-            dask_gufunc_kwargs=dict(output_sizes={"z1": 1}),
-        )
-
-    with pytest.raises(
-        ValueError, match=r"dimension 'z' in 'output_core_dims' needs corresponding"
-    ):
-        apply_ufunc(
-            func,
-            data_array.chunk({"x": 1}),
-            output_core_dims=[["z"]],
-            vectorize=True,
-            dask="parallelized",
-            output_dtypes=[float],
-        )
-
-
-def test_output_wrong_number() -> None:
-    variable = xr.Variable("x", np.arange(10))
-
-    def identity(x):
-        return x
-
-    def tuple3x(x):
-        return (x, x, x)
-
-    with pytest.raises(ValueError, match=r"number of outputs"):
-        apply_ufunc(identity, variable, output_core_dims=[(), ()])
-
-    with pytest.raises(ValueError, match=r"number of outputs"):
-        apply_ufunc(tuple3x, variable, output_core_dims=[(), ()])
-
-
-def test_output_wrong_dims() -> None:
-    variable = xr.Variable("x", np.arange(10))
-
-    def add_dim(x):
-        return x[..., np.newaxis]
-
-    def remove_dim(x):
-        return x[..., 0]
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(add_dim, variable, output_core_dims=[("y", "z")])
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(add_dim, variable)
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(remove_dim, variable)
-
-
-def test_output_wrong_dim_size() -> None:
-    array = np.arange(10)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    def truncate(array):
-        return array[:5]
-
-    def apply_truncate_broadcast_invalid(obj):
-        return apply_ufunc(truncate, obj)
-
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(variable)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(data_array)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(dataset)
-
-    def apply_truncate_x_x_invalid(obj):
-        return apply_ufunc(
-            truncate, obj, input_core_dims=[["x"]], output_core_dims=[["x"]]
-        )
-
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(variable)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(data_array)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(dataset)
-
-    def apply_truncate_x_z(obj):
-        return apply_ufunc(
-            truncate, obj, input_core_dims=[["x"]], output_core_dims=[["z"]]
-        )
-
-    assert_identical(xr.Variable("z", array[:5]), apply_truncate_x_z(variable))
-    assert_identical(
-        xr.DataArray(array[:5], dims=["z"]), apply_truncate_x_z(data_array)
-    )
-    assert_identical(xr.Dataset({"y": ("z", array[:5])}), apply_truncate_x_z(dataset))
-
-    def apply_truncate_x_x_valid(obj):
-        return apply_ufunc(
-            truncate,
-            obj,
-            input_core_dims=[["x"]],
-            output_core_dims=[["x"]],
-            exclude_dims={"x"},
-        )
-
-    assert_identical(xr.Variable("x", array[:5]), apply_truncate_x_x_valid(variable))
-    assert_identical(
-        xr.DataArray(array[:5], dims=["x"]), apply_truncate_x_x_valid(data_array)
-    )
-    assert_identical(
-        xr.Dataset({"y": ("x", array[:5])}), apply_truncate_x_x_valid(dataset)
-    )
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-def test_dot(use_dask) -> None:
-    if use_dask:
-        if not has_dask:
-            pytest.skip("test for dask.")
-
-    a = np.arange(30 * 4).reshape(30, 4)
-    b = np.arange(30 * 4 * 5).reshape(30, 4, 5)
-    c = np.arange(5 * 60).reshape(5, 60)
-    da_a = xr.DataArray(a, dims=["a", "b"], coords={"a": np.linspace(0, 1, 30)})
-    da_b = xr.DataArray(b, dims=["a", "b", "c"], coords={"a": np.linspace(0, 1, 30)})
-    da_c = xr.DataArray(c, dims=["c", "e"])
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-        da_c = da_c.chunk({"c": 3})
-    actual = xr.dot(da_a, da_b, dims=["a", "b"])
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    actual = xr.dot(da_a, da_b)
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    # for only a single array is passed without dims argument, just return
-    # as is
-    actual = xr.dot(da_a)
-    assert_identical(da_a, actual)
-
-    # test for variable
-    actual = xr.dot(da_a.variable, da_b.variable)
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.data, type(da_a.variable.data))
-
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-        actual = xr.dot(da_a, da_b, dims=["b"])
-        assert actual.dims == ("a", "c")
-        assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-        assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    actual = xr.dot(da_a, da_b, dims=["b"])
-    assert actual.dims == ("a", "c")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="b")
-    assert actual.dims == ("a", "c")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="a")
-    assert actual.dims == ("b", "c")
-    assert (actual.data == np.einsum("ij,ijk->jk", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="c")
-    assert actual.dims == ("a", "b")
-    assert (actual.data == np.einsum("ij,ijk->ij", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, da_c, dims=["a", "b"])
-    assert actual.dims == ("c", "e")
-    assert (actual.data == np.einsum("ij,ijk,kl->kl ", a, b, c)).all()
-
-    # should work with tuple
-    actual = xr.dot(da_a, da_b, dims=("c",))
-    assert actual.dims == ("a", "b")
-    assert (actual.data == np.einsum("ij,ijk->ij", a, b)).all()
-
-    # default dims
-    actual = xr.dot(da_a, da_b, da_c)
-    assert actual.dims == ("e",)
-    assert (actual.data == np.einsum("ij,ijk,kl->l ", a, b, c)).all()
-
-    # 1 array summation
-    actual = xr.dot(da_a, dims="a")
-    assert actual.dims == ("b",)
-    assert (actual.data == np.einsum("ij->j ", a)).all()
-
-    # empty dim
-    actual = xr.dot(da_a.sel(a=[]), da_a.sel(a=[]), dims="a")
-    assert actual.dims == ("b",)
-    assert (actual.data == np.zeros(actual.shape)).all()
-
-    # Ellipsis (...) sums over all dimensions
-    actual = xr.dot(da_a, da_b, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij,ijk->", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, da_c, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij,ijk,kl-> ", a, b, c)).all()
-
-    actual = xr.dot(da_a, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij-> ", a)).all()
-
-    actual = xr.dot(da_a.sel(a=[]), da_a.sel(a=[]), dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.zeros(actual.shape)).all()
-
-    # Invalid cases
-    if not use_dask:
-        with pytest.raises(TypeError):
-            xr.dot(da_a, dims="a", invalid=None)
-    with pytest.raises(TypeError):
-        xr.dot(da_a.to_dataset(name="da"), dims="a")
-    with pytest.raises(TypeError):
-        xr.dot(dims="a")
-
-    # einsum parameters
-    actual = xr.dot(da_a, da_b, dims=["b"], order="C")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-    assert actual.values.flags["C_CONTIGUOUS"]
-    assert not actual.values.flags["F_CONTIGUOUS"]
-    actual = xr.dot(da_a, da_b, dims=["b"], order="F")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-    # dask converts Fortran arrays to C order when merging the final array
-    if not use_dask:
-        assert not actual.values.flags["C_CONTIGUOUS"]
-        assert actual.values.flags["F_CONTIGUOUS"]
-
-    # einsum has a constant string as of the first parameter, which makes
-    # it hard to pass to xarray.apply_ufunc.
-    # make sure dot() uses functools.partial(einsum, subscripts), which
-    # can be pickled, and not a lambda, which can't.
-    pickle.loads(pickle.dumps(xr.dot(da_a)))
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-def test_dot_align_coords(use_dask) -> None:
-    # GH 3694
-
-    if use_dask:
-        if not has_dask:
-            pytest.skip("test for dask.")
-
-    a = np.arange(30 * 4).reshape(30, 4)
-    b = np.arange(30 * 4 * 5).reshape(30, 4, 5)
-
-    # use partially overlapping coords
-    coords_a = {"a": np.arange(30), "b": np.arange(4)}
-    coords_b = {"a": np.arange(5, 35), "b": np.arange(1, 5)}
-
-    da_a = xr.DataArray(a, dims=["a", "b"], coords=coords_a)
-    da_b = xr.DataArray(b, dims=["a", "b", "c"], coords=coords_b)
-
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-
-    # join="inner" is the default
-    actual = xr.dot(da_a, da_b)
-    # `dot` sums over the common dimensions of the arguments
-    expected = (da_a * da_b).sum(["a", "b"])
-    xr.testing.assert_allclose(expected, actual)
-
-    actual = xr.dot(da_a, da_b, dims=...)
-    expected = (da_a * da_b).sum()
-    xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="exact"):
-        with pytest.raises(ValueError, match=r"indexes along dimension"):
-            xr.dot(da_a, da_b)
-
-    # NOTE: dot always uses `join="inner"` because `(a * b).sum()` yields the same for all
-    # join method (except "exact")
-    with xr.set_options(arithmetic_join="left"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="right"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="outer"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-
-def test_where() -> None:
-    cond = xr.DataArray([True, False], dims="x")
-    actual = xr.where(cond, 1, 0)
-    expected = xr.DataArray([1, 0], dims="x")
-    assert_identical(expected, actual)
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-@pytest.mark.parametrize("use_datetime", [True, False])
-def test_polyval(use_dask, use_datetime) -> None:
-    if use_dask and not has_dask:
-        pytest.skip("requires dask")
-
-    if use_datetime:
-        xcoord = xr.DataArray(
-            pd.date_range("2000-01-01", freq="D", periods=10), dims=("x",), name="x"
-        )
-        x = xr.core.missing.get_clean_interp_index(xcoord, "x")
-    else:
-        xcoord = x = np.arange(10)
-
-    da = xr.DataArray(
-        np.stack((1.0 + x + 2.0 * x ** 2, 1.0 + 2.0 * x + 3.0 * x ** 2)),
-        dims=("d", "x"),
-        coords={"x": xcoord, "d": [0, 1]},
-    )
-    coeffs = xr.DataArray(
-        [[2, 1, 1], [3, 2, 1]],
-        dims=("d", "degree"),
-        coords={"d": [0, 1], "degree": [2, 1, 0]},
-    )
-    if use_dask:
-        coeffs = coeffs.chunk({"d": 2})
-
-    da_pv = xr.polyval(da.x, coeffs)
-
-    xr.testing.assert_allclose(da, da_pv.T)
Obtaining file:///testbed
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.18 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.20.2.dev19+g5158b9f6.d20250207) (1.23.0)
Requirement already satisfied: pandas>=1.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.20.2.dev19+g5158b9f6.d20250207) (1.5.3)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.1->xarray==0.20.2.dev19+g5158b9f6.d20250207) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.1->xarray==0.20.2.dev19+g5158b9f6.d20250207) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1->xarray==0.20.2.dev19+g5158b9f6.d20250207) (1.16.0)
Building wheels for collected packages: xarray
  Building editable for xarray (pyproject.toml): started
  Building editable for xarray (pyproject.toml): finished with status 'done'
  Created wheel for xarray: filename=xarray-0.20.2.dev19+g5158b9f6.d20250207-0.editable-py3-none-any.whl size=9121 sha256=5cd9f3d9f26f834c119d6fb2914299c5409d9a5ac1fede4d6b6efb5b24d1afde
  Stored in directory: /tmp/pip-ephem-wheel-cache-pwruftli/wheels/0d/a6/cb/465a7b303d624cc531250fa27c75d038ddc29430bdb6ba7c9f
Successfully built xarray
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.20.2.dev19+g5158b9f6
    Uninstalling xarray-0.20.2.dev19+g5158b9f6:
      Successfully uninstalled xarray-0.20.2.dev19+g5158b9f6
Successfully installed xarray-0.20.2.dev19+g5158b9f6.d20250207
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, xdist-3.6.1
collected 13 items

xarray/tests/test_computation.py .............                           [100%]

=============================== warnings summary ===============================
xarray/core/pycompat.py:22: 2 warnings
xarray/tests/test_computation.py: 39 warnings
  /testbed/xarray/core/pycompat.py:22: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    duck_array_version = LooseVersion(duck_array_module.__version__)

xarray/core/pycompat.py:37
  /testbed/xarray/core/pycompat.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    duck_array_version = LooseVersion("0.0.0")

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

xarray/core/npcompat.py:82
  /testbed/xarray/core/npcompat.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(np.__version__) >= "1.20.0":

xarray/core/pdcompat.py:45
  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(pd.__version__) < "0.25.0":

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    from pkg_resources import get_distribution

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

xarray/tests/__init__.py:60
xarray/tests/__init__.py:60
  /testbed/xarray/tests/__init__.py:60: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    return version.LooseVersion(vstring)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_computation.py::test_result_name
PASSED xarray/tests/test_computation.py::test_ordered_set_union
PASSED xarray/tests/test_computation.py::test_ordered_set_intersection
PASSED xarray/tests/test_computation.py::test_join_dict_keys
PASSED xarray/tests/test_computation.py::test_collect_dict_values
PASSED xarray/tests/test_computation.py::test_unified_dim_sizes
PASSED xarray/tests/test_computation.py::test_apply_ufunc
PASSED xarray/tests/test_computation.py::test_apply_dataarray_vfunc
PASSED xarray/tests/test_computation.py::test_apply_dataset_vfunc
PASSED xarray/tests/test_computation.py::test_cov
PASSED xarray/tests/test_computation.py::test_corr
PASSED xarray/tests/test_computation.py::test_dot
PASSED xarray/tests/test_computation.py::test_where
======================= 13 passed, 58 warnings in 0.22s ========================

