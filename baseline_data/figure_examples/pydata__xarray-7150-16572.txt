Instance ID: pydata__xarray-7150-16572

Baseline 1 (Pynguin):
Predicted Test Suite: 
Coverage: -1
Mutation Score: -1

Baseline 2 (CodaMosa):
Predicted Test Suite: 
Coverage: -1
Mutation Score: -1

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import os
import pytest
import numpy as np
from unittest.mock import patch, MagicMock
from xarray.backends.api import (
    _get_default_engine_remote_uri,
    _get_default_engine_gz,
    _get_default_engine_netcdf,
    _get_default_engine,
    _validate_dataset_names,
    _validate_attrs,
    _resolve_decoders_kwargs,
    _get_mtime,
    _protect_dataset_variables_inplace,
    _finalize_store,
    _multi_file_closer,
    load_dataset,
    load_dataarray,
    open_dataset,
    open_dataarray,
    open_mfdataset,
    to_netcdf,
    save_mfdataset,
    to_zarr,
)
from xarray.core.dataset import Dataset
from xarray.core.dataarray import DataArray
from xarray.core.indexes import Index
from xarray.core.utils import is_remote_uri
from xarray.backends.common import AbstractDataStore

# Mock Dataset and DataArray for testing
@pytest.fixture
def mock_dataset():
    return Dataset()

@pytest.fixture
def mock_dataarray():
    return DataArray()

def test_get_default_engine_remote_uri():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        with patch("xarray.backends.api._get_default_engine_remote_uri", return_value="netcdf4"):
            assert _get_default_engine("http://example.com") == "netcdf4"

def test_get_default_engine_gz():
    with patch("xarray.backends.api._get_default_engine_gz", return_value="scipy"):
        assert _get_default_engine("file.gz") == "scipy"

def test_get_default_engine_netcdf():
    with patch("xarray.backends.api._get_default_engine_netcdf", return_value="netcdf4"):
        assert _get_default_engine("file.nc") == "netcdf4"

def test_validate_dataset_names(mock_dataset):
    mock_dataset.variables = {"valid_name": None}
    _validate_dataset_names(mock_dataset)

    mock_dataset.variables = {None: None}
    with pytest.raises(TypeError):
        _validate_dataset_names(mock_dataset)

def test_validate_attrs(mock_dataset):
    mock_dataset.attrs = {"valid_attr": 1}
    mock_dataset.variables = {"var": MagicMock(attrs={"valid_attr": 1})}
    _validate_attrs(mock_dataset)

    mock_dataset.attrs = {None: 1}
    with pytest.raises(TypeError):
        _validate_attrs(mock_dataset)

def test_resolve_decoders_kwargs():
    decoders = {"mask_and_scale": None, "decode_times": True}
    result = _resolve_decoders_kwargs(False, ["mask_and_scale"], **decoders)
    assert result == {"decode_times": True}

def test_get_mtime():
    with patch("os.path.getmtime", return_value=123456789):
        assert _get_mtime("file.nc") == 123456789

def test_protect_dataset_variables_inplace(mock_dataset):
    mock_dataset.variables = {"var": MagicMock(_data=MagicMock())}
    _protect_dataset_variables_inplace(mock_dataset, cache=True)

def test_finalize_store():
    mock_store = MagicMock()
    _finalize_store(None, mock_store)
    mock_store.close.assert_called_once()

def test_multi_file_closer():
    mock_closer = MagicMock()
    _multi_file_closer([mock_closer])
    mock_closer.assert_called_once()

def test_load_dataset():
    with patch("xarray.backends.api.open_dataset", return_value=MagicMock(load=MagicMock(return_value="loaded"))):
        assert load_dataset("file.nc") == "loaded"

def test_load_dataarray():
    with patch("xarray.backends.api.open_dataarray", return_value=MagicMock(load=MagicMock(return_value="loaded"))):
        assert load_dataarray("file.nc") == "loaded"

def test_open_dataset(mock_dataset):
    with patch("xarray.backends.api.plugins.get_backend", return_value=MagicMock(open_dataset=MagicMock(return_value=mock_dataset))):
        result = open_dataset("file.nc")
        assert isinstance(result, Dataset)

def test_open_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataset", return_value=MagicMock(data_vars={"var": mock_dataarray})):
        result = open_dataarray("file.nc")
        assert isinstance(result, DataArray)

def test_open_mfdataset():
    with patch("xarray.backends.api.open_dataset", return_value=MagicMock()):
        result = open_mfdataset(["file1.nc", "file2.nc"])
        assert isinstance(result, Dataset)

def test_to_netcdf(mock_dataset):
    with patch("xarray.backends.api.WRITEABLE_STORES", {"netcdf4": MagicMock()}):
        to_netcdf(mock_dataset, "file.nc")

def test_save_mfdataset(mock_dataset):
    with patch("xarray.backends.api.to_netcdf", return_value=(MagicMock(), MagicMock())):
        save_mfdataset([mock_dataset], ["file1.nc", "file2.nc"])

def test_to_zarr(mock_dataset):
    with patch("xarray.backends.api.backends.ZarrStore.open_group", return_value=MagicMock()):
        to_zarr(mock_dataset, "store.zarr")

Coverage: 45.79207920792079
Mutation Score: 6.150000000000006

Approach:
Predicted Test Suite: import os
import pytest
import numpy as np
from unittest.mock import patch, MagicMock
from xarray.backends.api import (
    _get_default_engine_remote_uri,
    _get_default_engine_gz,
    _get_default_engine_netcdf,
    _get_default_engine,
    _validate_dataset_names,
    _validate_attrs,
    _resolve_decoders_kwargs,
    _get_mtime,
    _protect_dataset_variables_inplace,
    _finalize_store,
    _multi_file_closer,
    load_dataset,
    load_dataarray,
    open_dataset,
    open_dataarray,
    open_mfdataset,
    to_netcdf,
    save_mfdataset,
    to_zarr,
)
from xarray.core.dataset import Dataset
from xarray.core.dataarray import DataArray
from xarray.core.indexes import Index
from xarray.core.utils import is_remote_uri
from xarray.backends.common import AbstractDataStore

# Mock Dataset and DataArray for testing
@pytest.fixture
def mock_dataset():
    return Dataset()

@pytest.fixture
def mock_dataarray():
    return DataArray()

def test_get_default_engine_remote_uri():
    with patch("xarray.backends.api.is_remote_uri", return_value=True):
        with patch("xarray.backends.api._get_default_engine_remote_uri", return_value="netcdf4"):
            assert _get_default_engine("http://example.com") == "netcdf4"

def test_get_default_engine_gz():
    with patch("xarray.backends.api._get_default_engine_gz", return_value="scipy"):
        assert _get_default_engine("file.gz") == "scipy"

def test_get_default_engine_netcdf():
    with patch("xarray.backends.api._get_default_engine_netcdf", return_value="netcdf4"):
        assert _get_default_engine("file.nc") == "netcdf4"

def test_validate_dataset_names(mock_dataset):
    mock_dataset = Dataset(data_vars={"valid_name": ([], 0)})
    _validate_dataset_names(mock_dataset)

    mock_dataset = Dataset(data_vars={None: ([], 0)})
    with pytest.raises(TypeError):
        _validate_dataset_names(mock_dataset)

def test_validate_attrs(mock_dataset):
    mock_dataset.attrs = {"valid_attr": 1}
    mock_dataset = Dataset(data_vars={"var": ([], 0)}, attrs={"valid_attr": 1})
    _validate_attrs(mock_dataset)

    mock_dataset = Dataset(attrs={None: 1})
    with pytest.raises(TypeError):
        _validate_attrs(mock_dataset)

def test_resolve_decoders_kwargs():
    decoders = {"mask_and_scale": None, "decode_times": True}
    result = _resolve_decoders_kwargs(False, ["mask_and_scale"], **decoders)
    assert result == {"decode_times": True, "mask_and_scale": False}

def test_get_mtime():
    with patch("os.path.getmtime", return_value=123456789):
        assert _get_mtime("file.nc") == 123456789

def test_protect_dataset_variables_inplace(mock_dataset):
    mock_dataset = Dataset(data_vars={"var": ("x", np.array([1, 2, 3]))})
    _protect_dataset_variables_inplace(mock_dataset, cache=True)

def test_finalize_store():
    mock_store = MagicMock()
    _finalize_store(None, mock_store)
    mock_store.close.assert_called_once()

def test_multi_file_closer():
    mock_closer = MagicMock()
    _multi_file_closer([mock_closer])
    mock_closer.assert_called_once()

def test_load_dataset():
    with patch("xarray.backends.api.open_dataset", return_value=MagicMock(load=MagicMock(return_value="loaded"))):
        assert load_dataset("file.nc").load() == "loaded"

def test_load_dataarray():
    with patch("xarray.backends.api.open_dataarray", return_value=MagicMock(load=MagicMock(return_value="loaded"))):
        assert load_dataarray("file.nc").load() == "loaded"

def test_open_dataset(mock_dataset):
    with patch("xarray.backends.api.plugins.get_backend", return_value=MagicMock(open_dataset=MagicMock(return_value=mock_dataset))):
        result = open_dataset("file.nc")
        assert isinstance(result, Dataset)

def test_open_dataarray(mock_dataarray):
    with patch("xarray.backends.api.open_dataset", return_value=MagicMock(data_vars={"var": mock_dataarray})):
        result = open_dataarray("file.nc")
        assert isinstance(result, DataArray)

def test_open_mfdataset():
    with patch("xarray.backends.api.open_dataset", return_value=Dataset()):
        result = open_mfdataset(["file1.nc", "file2.nc"], combine="nested", concat_dim="time")
        assert isinstance(result, Dataset)

def test_to_netcdf(mock_dataset):
    with patch("xarray.backends.api.WRITEABLE_STORES", {"netcdf4": MagicMock()}):
        to_netcdf(mock_dataset, "file.nc")

def test_save_mfdataset(mock_dataset):
    with patch("xarray.backends.api.to_netcdf", return_value=(MagicMock(), MagicMock())):
        save_mfdataset([mock_dataset, mock_dataset], ["file1.nc", "file2.nc"])

def test_to_zarr(mock_dataset):
    with patch("xarray.backends.api.backends.ZarrStore.open_group", return_value=MagicMock()):
        to_zarr(mock_dataset, "store.zarr")
Coverage: 57.67326732673267
Mutation Score: 9.719999999999999
Output: On branch main
Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_backends_api.py

nothing added to commit but untracked files present (use "git add" to track)
commit f4f567f4296ce4a45f055e3d4490a98a27b0a9f5
Author: TestGenEval <>
Date:   Wed Dec 11 13:16:24 2024 +0000

    Testing fixes

diff --git a/xarray/backends/api.py b/xarray/backends/api.py
index 3e34af08..13bcf046 100644
--- a/xarray/backends/api.py
+++ b/xarray/backends/api.py
@@ -234,7 +234,7 @@ def _get_mtime(filename_or_obj):

 def _protect_dataset_variables_inplace(dataset, cache):
     for name, variable in dataset.variables.items():
-        if name not in variable.dims:
+        if name not in dataset._indexes:
             # no need to protect IndexVariable objects
             data = indexing.CopyOnWriteArray(variable._data)
             if cache:
diff --git a/xarray/tests/test_backends_api.py b/xarray/tests/test_backends_api.py
deleted file mode 100644
index e14234bc..00000000
--- a/xarray/tests/test_backends_api.py
+++ /dev/null
@@ -1,181 +0,0 @@
-from __future__ import annotations
-
-from numbers import Number
-
-import numpy as np
-import pytest
-
-import xarray as xr
-from xarray.backends.api import _get_default_engine
-
-from . import (
-    assert_identical,
-    assert_no_warnings,
-    requires_dask,
-    requires_netCDF4,
-    requires_scipy,
-)
-
-
-@requires_netCDF4
-@requires_scipy
-def test__get_default_engine() -> None:
-    engine_remote = _get_default_engine("http://example.org/test.nc", allow_remote=True)
-    assert engine_remote == "netcdf4"
-
-    engine_gz = _get_default_engine("/example.gz")
-    assert engine_gz == "scipy"
-
-    engine_default = _get_default_engine("/example")
-    assert engine_default == "netcdf4"
-
-
-def test_custom_engine() -> None:
-    expected = xr.Dataset(
-        dict(a=2 * np.arange(5)), coords=dict(x=("x", np.arange(5), dict(units="s")))
-    )
-
-    class CustomBackend(xr.backends.BackendEntrypoint):
-        def open_dataset(
-            self,
-            filename_or_obj,
-            drop_variables=None,
-            **kwargs,
-        ) -> xr.Dataset:
-            return expected.copy(deep=True)
-
-    actual = xr.open_dataset("fake_filename", engine=CustomBackend)
-    assert_identical(expected, actual)
-
-
-class PassThroughBackendEntrypoint(xr.backends.BackendEntrypoint):
-    """Access an object passed to the `open_dataset` method."""
-
-    def open_dataset(self, dataset, *, drop_variables=None):
-        """Return the first argument."""
-        return dataset
-
-
-def explicit_chunks(chunks, shape):
-    """Return explicit chunks, expanding any integer member to a tuple of integers."""
-    # Emulate `dask.array.core.normalize_chunks` but for simpler inputs.
-    return tuple(
-        (
-            (size // chunk) * (chunk,)
-            + ((size % chunk,) if size % chunk or size == 0 else ())
-        )
-        if isinstance(chunk, Number)
-        else chunk
-        for chunk, size in zip(chunks, shape)
-    )
-
-
-@requires_dask
-class TestPreferredChunks:
-    """Test behaviors related to the backend's preferred chunks."""
-
-    var_name = "data"
-
-    def create_dataset(self, shape, pref_chunks):
-        """Return a dataset with a variable with the given shape and preferred chunks."""
-        dims = tuple(f"dim_{idx}" for idx in range(len(shape)))
-        return xr.Dataset(
-            {
-                self.var_name: xr.Variable(
-                    dims,
-                    np.empty(shape, dtype=np.dtype("V1")),
-                    encoding={"preferred_chunks": dict(zip(dims, pref_chunks))},
-                )
-            }
-        )
-
-    def check_dataset(self, initial, final, expected_chunks):
-        assert_identical(initial, final)
-        assert final[self.var_name].chunks == expected_chunks
-
-    @pytest.mark.parametrize(
-        "shape,pref_chunks",
-        [
-            # Represent preferred chunking with int.
-            ((5,), (2,)),
-            # Represent preferred chunking with tuple.
-            ((5,), ((2, 2, 1),)),
-            # Represent preferred chunking with int in two dims.
-            ((5, 6), (4, 2)),
-            # Represent preferred chunking with tuple in second dim.
-            ((5, 6), (4, (2, 2, 2))),
-        ],
-    )
-    @pytest.mark.parametrize("request_with_empty_map", [False, True])
-    def test_honor_chunks(self, shape, pref_chunks, request_with_empty_map):
-        """Honor the backend's preferred chunks when opening a dataset."""
-        initial = self.create_dataset(shape, pref_chunks)
-        # To keep the backend's preferred chunks, the `chunks` argument must be an
-        # empty mapping or map dimensions to `None`.
-        chunks = (
-            {}
-            if request_with_empty_map
-            else dict.fromkeys(initial[self.var_name].dims, None)
-        )
-        final = xr.open_dataset(
-            initial, engine=PassThroughBackendEntrypoint, chunks=chunks
-        )
-        self.check_dataset(initial, final, explicit_chunks(pref_chunks, shape))
-
-    @pytest.mark.parametrize(
-        "shape,pref_chunks,req_chunks",
-        [
-            # Preferred chunking is int; requested chunking is int.
-            ((5,), (2,), (3,)),
-            # Preferred chunking is int; requested chunking is tuple.
-            ((5,), (2,), ((2, 1, 1, 1),)),
-            # Preferred chunking is tuple; requested chunking is int.
-            ((5,), ((2, 2, 1),), (3,)),
-            # Preferred chunking is tuple; requested chunking is tuple.
-            ((5,), ((2, 2, 1),), ((2, 1, 1, 1),)),
-            # Split chunks along a dimension other than the first.
-            ((1, 5), (1, 2), (1, 3)),
-        ],
-    )
-    def test_split_chunks(self, shape, pref_chunks, req_chunks):
-        """Warn when the requested chunks separate the backend's preferred chunks."""
-        initial = self.create_dataset(shape, pref_chunks)
-        with pytest.warns(UserWarning):
-            final = xr.open_dataset(
-                initial,
-                engine=PassThroughBackendEntrypoint,
-                chunks=dict(zip(initial[self.var_name].dims, req_chunks)),
-            )
-        self.check_dataset(initial, final, explicit_chunks(req_chunks, shape))
-
-    @pytest.mark.parametrize(
-        "shape,pref_chunks,req_chunks",
-        [
-            # Keep preferred chunks using int representation.
-            ((5,), (2,), (2,)),
-            # Keep preferred chunks using tuple representation.
-            ((5,), (2,), ((2, 2, 1),)),
-            # Join chunks, leaving a final short chunk.
-            ((5,), (2,), (4,)),
-            # Join all chunks with an int larger than the dimension size.
-            ((5,), (2,), (6,)),
-            # Join one chunk using tuple representation.
-            ((5,), (1,), ((1, 1, 2, 1),)),
-            # Join one chunk using int representation.
-            ((5,), ((1, 1, 2, 1),), (2,)),
-            # Join multiple chunks using tuple representation.
-            ((5,), ((1, 1, 2, 1),), ((2, 3),)),
-            # Join chunks in multiple dimensions.
-            ((5, 5), (2, (1, 1, 2, 1)), (4, (2, 3))),
-        ],
-    )
-    def test_join_chunks(self, shape, pref_chunks, req_chunks):
-        """Don't warn when the requested chunks join or keep the preferred chunks."""
-        initial = self.create_dataset(shape, pref_chunks)
-        with assert_no_warnings():
-            final = xr.open_dataset(
-                initial,
-                engine=PassThroughBackendEntrypoint,
-                chunks=dict(zip(initial[self.var_name].dims, req_chunks)),
-            )
-        self.check_dataset(initial, final, explicit_chunks(req_chunks, shape))
Obtaining file:///testbed
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.19 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev16+gf4f567f4) (1.23.0)
Requirement already satisfied: pandas>=1.2 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev16+gf4f567f4) (1.5.3)
Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev16+gf4f567f4) (23.1)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.2->xarray==2022.9.1.dev16+gf4f567f4) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.2->xarray==2022.9.1.dev16+gf4f567f4) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->xarray==2022.9.1.dev16+gf4f567f4) (1.16.0)
Building wheels for collected packages: xarray
  Building editable for xarray (pyproject.toml): started
  Building editable for xarray (pyproject.toml): finished with status 'done'
  Created wheel for xarray: filename=xarray-2022.9.1.dev16+gf4f567f4-0.editable-py3-none-any.whl size=8986 sha256=ac54e7db35874a3e599c05a8e7eb4ce9f68b26cc93c5f68bbba292709231c98a
  Stored in directory: /tmp/pip-ephem-wheel-cache-35lirsts/wheels/0d/a6/cb/465a7b303d624cc531250fa27c75d038ddc29430bdb6ba7c9f
Successfully built xarray
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 2022.9.1.dev16+gf4f567f4
    Uninstalling xarray-2022.9.1.dev16+gf4f567f4:
      Successfully uninstalled xarray-2022.9.1.dev16+gf4f567f4
Successfully installed xarray-2022.9.1.dev16+gf4f567f4
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, timeout-2.3.1, xdist-3.6.1
collected 15 items

xarray/tests/test_backends_api.py ...............                        [100%]

=============================== warnings summary ===============================
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    from pkg_resources import get_distribution

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_remote_uri
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_gz
PASSED xarray/tests/test_backends_api.py::test_get_default_engine_netcdf
PASSED xarray/tests/test_backends_api.py::test_validate_attrs
PASSED xarray/tests/test_backends_api.py::test_resolve_decoders_kwargs
PASSED xarray/tests/test_backends_api.py::test_get_mtime
PASSED xarray/tests/test_backends_api.py::test_protect_dataset_variables_inplace
PASSED xarray/tests/test_backends_api.py::test_finalize_store
PASSED xarray/tests/test_backends_api.py::test_multi_file_closer
PASSED xarray/tests/test_backends_api.py::test_open_dataset
PASSED xarray/tests/test_backends_api.py::test_open_dataarray
PASSED xarray/tests/test_backends_api.py::test_open_mfdataset
PASSED xarray/tests/test_backends_api.py::test_to_netcdf
PASSED xarray/tests/test_backends_api.py::test_save_mfdataset
PASSED xarray/tests/test_backends_api.py::test_to_zarr
======================== 15 passed, 8 warnings in 0.25s ========================

