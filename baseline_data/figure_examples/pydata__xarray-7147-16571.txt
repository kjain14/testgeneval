Instance ID: pydata__xarray-7147-16571

Baseline 1 (Pynguin):
Predicted Test Suite: # Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import xarray.conventions as module_0
import dask.array.chunk as module_1


@pytest.mark.xfail(strict=True)
def test_case_0():
    none_type_0 = None
    module_0.encode_cf_variable(none_type_0, none_type_0)


def test_case_1():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0, none_type_0, decode_times=none_type_0
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")


def test_case_2():
    none_type_0 = None
    with pytest.raises(TypeError):
        module_0.decode_cf(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_3():
    none_type_0 = None
    module_0.maybe_encode_bools(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_4():
    none_type_0 = None
    module_0.NativeEndiannessArray(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_5():
    str_0 = '"!&X\x0cJR'
    module_0.BoolTypeArray(str_0)


@pytest.mark.xfail(strict=True)
def test_case_6():
    none_type_0 = None
    module_0.cf_decoder(none_type_0, none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_7():
    none_type_0 = None
    module_0.encode_dataset_coordinates(none_type_0)


def test_case_8():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")


@pytest.mark.xfail(strict=True)
def test_case_9():
    none_type_0 = None
    var_0 = module_0.ensure_not_multiindex(none_type_0)
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.decode_cf_variable(
        none_type_0, none_type_0, decode_endianness=none_type_0
    )
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.decode_cf_variable(
        none_type_0, none_type_0, decode_timedelta=var_1
    )
    var_3 = module_0.maybe_encode_bools(var_1)
    assert (
        f"{type(var_3).__module__}.{type(var_3).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    module_0.encode_dataset_coordinates(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_10():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(none_type_0, none_type_0, none_type_0)
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    module_0.maybe_encode_bools(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_11():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0,
        none_type_0,
        mask_and_scale=none_type_0,
        decode_timedelta=none_type_0,
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    module_0.maybe_encode_bools(none_type_0)


def test_case_12():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0, none_type_0, decode_endianness=none_type_0
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")


@pytest.mark.xfail(strict=True)
def test_case_13():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.maybe_encode_bools(var_0)
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    module_0.encode_dataset_coordinates(var_0)


@pytest.mark.xfail(strict=True)
def test_case_14():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(none_type_0, none_type_0, none_type_0)
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.maybe_encode_bools(var_0)
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.ensure_dtype_not_object(var_1, none_type_0)
    assert (
        f"{type(var_2).__module__}.{type(var_2).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    module_0.maybe_encode_bools(none_type_0)


def test_case_15():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0,
        none_type_0,
        decode_times=none_type_0,
        stack_char_dim=none_type_0,
        decode_timedelta=none_type_0,
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.maybe_encode_nonstring_dtype(var_0)
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )


def test_case_16():
    none_type_0 = None
    var_0 = module_0.ensure_not_multiindex(none_type_0)
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.encode_cf_variable(var_1)
    assert (
        f"{type(var_2).__module__}.{type(var_2).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_3 = module_0.ensure_dtype_not_object(var_2)
    with pytest.raises(AssertionError):
        module_1.argtopk_aggregate(var_2, var_0, var_3, var_0)


def test_case_17():
    none_type_0 = None
    var_0 = module_0.ensure_not_multiindex(none_type_0)
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.encode_cf_variable(var_1)
    assert (
        f"{type(var_2).__module__}.{type(var_2).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_3 = module_0.encode_cf_variable(var_2)
    assert (
        f"{type(var_3).__module__}.{type(var_3).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    with pytest.raises(TypeError):
        module_0.decode_cf(var_2, drop_variables=var_2, decode_timedelta=var_0)


def test_case_18():
    none_type_0 = None
    var_0 = module_0.ensure_not_multiindex(none_type_0)
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.encode_cf_variable(var_1)
    assert (
        f"{type(var_2).__module__}.{type(var_2).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_3 = module_0.encode_cf_variable(var_2)
    assert (
        f"{type(var_3).__module__}.{type(var_3).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_4 = module_0.maybe_default_fill_value(var_3)
    var_5 = module_0.maybe_default_fill_value(var_1)
    with pytest.raises(TypeError):
        module_0.decode_cf(var_2, drop_variables=var_2, decode_timedelta=var_0)


@pytest.mark.xfail(strict=True)
def test_case_19():
    none_type_0 = None
    var_0 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_0).__module__}.{type(var_0).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.ensure_dtype_not_object(var_0)
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = module_0.encode_cf_variable(var_0)
    assert (
        f"{type(var_2).__module__}.{type(var_2).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_3 = module_0.encode_cf_variable(var_1)
    var_4 = module_0.maybe_default_fill_value(var_0)
    module_0.BoolTypeArray(none_type_0)


def test_case_20():
    none_type_0 = None
    var_0 = module_0.ensure_not_multiindex(none_type_0)
    assert module_0.CF_RELATED_DATA == (
        "bounds",
        "grid_mapping",
        "climatology",
        "geometry",
        "node_coordinates",
        "node_count",
        "part_node_count",
        "interior_ring",
        "cell_measures",
        "formula_terms",
    )
    assert module_0.CF_RELATED_DATA_NEEDS_PARSING == ("cell_measures", "formula_terms")
    var_1 = module_0.decode_cf_variable(
        none_type_0, none_type_0, use_cftime=none_type_0, decode_timedelta=none_type_0
    )
    assert (
        f"{type(var_1).__module__}.{type(var_1).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_2 = var_1.notnull()
    var_3 = module_0.encode_cf_variable(var_1)
    assert (
        f"{type(var_3).__module__}.{type(var_3).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_4 = module_0.encode_cf_variable(var_2)
    assert (
        f"{type(var_4).__module__}.{type(var_4).__qualname__}"
        == "xarray.core.variable.Variable"
    )
    var_5 = module_0.maybe_default_fill_value(var_1)
    with pytest.raises(TypeError):
        module_0.decode_cf(var_0, decode_timedelta=var_5)

Coverage: 42.05298013245033
Mutation Score: 12.349999999999994

Baseline 2 (CodaMosa):
Predicted Test Suite: 
Coverage: -1
Mutation Score: -1

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import warnings
import numpy as np
import pandas as pd
import pytest
from xarray import Dataset, Variable, SerializationWarning, conventions
from xarray.conventions import decode_cf_variable, encode_cf_variable, decode_cf, cf_decoder, cf_encoder
from xarray.core.variable import as_variable

def test_NativeEndiannessArray():
    x = np.arange(5, dtype=">i2")
    array = conventions.NativeEndiannessArray(x)
    assert array.dtype == np.dtype('int16')
    indexer = conventions.indexing.BasicIndexer((slice(None),))
    assert array[indexer].dtype == np.dtype('int16')

def test_BoolTypeArray():
    x = np.array([1, 0, 1, 1, 0], dtype="i1")
    array = conventions.BoolTypeArray(x)
    assert array.dtype == np.dtype('bool')
    indexer = conventions.indexing.BasicIndexer((slice(None),))
    assert array[indexer].dtype == np.dtype('bool')

def test_maybe_encode_nonstring_dtype():
    var = Variable(('x',), np.array([1.0, 2.0, 3.0]), encoding={'dtype': 'int32'})
    encoded_var = conventions.maybe_encode_nonstring_dtype(var, name='test_var')
    assert encoded_var.dtype == np.int32

def test_maybe_default_fill_value():
    var = Variable(('x',), np.array([1.0, 2.0, np.nan]))
    var = conventions.maybe_default_fill_value(var)
    assert var.attrs['_FillValue'] == np.nan

def test_maybe_encode_bools():
    var = Variable(('x',), np.array([True, False, True]))
    encoded_var = conventions.maybe_encode_bools(var)
    assert encoded_var.dtype == np.int8
    assert encoded_var.attrs['dtype'] == 'bool'

def test_ensure_not_multiindex():
    index_var = Variable(('x',), pd.MultiIndex.from_arrays([[1, 2], [3, 4]], names=('a', 'b')))
    with pytest.raises(NotImplementedError):
        conventions.ensure_not_multiindex(index_var, name='multiindex_var')

def test_ensure_dtype_not_object():
    var = Variable(('x',), np.array(['a', 'b', 'c'], dtype=object))
    encoded_var = conventions.ensure_dtype_not_object(var, name='object_var')
    assert encoded_var.dtype != object

def test_encode_cf_variable():
    var = Variable(('x',), np.array([1.0, 2.0, 3.0]), attrs={'units': 'meters'})
    encoded_var = encode_cf_variable(var, name='test_var')
    assert '_FillValue' in encoded_var.attrs

def test_decode_cf_variable():
    var = Variable(('x',), np.array([1, 2, 3], dtype='i1'), attrs={'dtype': 'bool'})
    decoded_var = decode_cf_variable('test_var', var)
    assert decoded_var.dtype == np.bool_

def test_decode_cf():
    ds = Dataset({'temp': ('x', [1, 2, 3], {'units': 'K'})})
    decoded_ds = decode_cf(ds)
    assert 'temp' in decoded_ds

def test_cf_decoder():
    variables = {'temp': Variable(('x',), [1, 2, 3], {'units': 'K'})}
    attributes = {'title': 'Test Dataset'}
    decoded_vars, decoded_attrs = cf_decoder(variables, attributes)
    assert 'temp' in decoded_vars
    assert decoded_attrs['title'] == 'Test Dataset'

def test_cf_encoder():
    variables = {'temp': Variable(('x',), [1, 2, 3], {'units': 'K'})}
    attributes = {'title': 'Test Dataset'}
    encoded_vars, encoded_attrs = cf_encoder(variables, attributes)
    assert 'temp' in encoded_vars
    assert encoded_attrs['title'] == 'Test Dataset'

Coverage: 54.63576158940398
Mutation Score: 15.879999999999995

Approach:
Predicted Test Suite: import warnings
import numpy as np
import pandas as pd
import pytest
from xarray import Dataset, Variable, SerializationWarning, conventions
from xarray.conventions import decode_cf_variable, encode_cf_variable, decode_cf, cf_decoder, cf_encoder
from xarray.core.variable import as_variable

def test_NativeEndiannessArray():
    x = np.arange(5, dtype=">i2")
    array = conventions.NativeEndiannessArray(x)
    assert array.dtype == np.dtype('int16')
    indexer = conventions.indexing.BasicIndexer((slice(None),))
    assert array[indexer].dtype == np.dtype('int16')

def test_BoolTypeArray():
    x = np.array([1, 0, 1, 1, 0], dtype="i1")
    array = conventions.BoolTypeArray(x)
    assert array.dtype == np.dtype('bool')
    indexer = conventions.indexing.BasicIndexer((slice(None),))
    assert array[indexer].dtype == np.dtype('bool')

def test_maybe_encode_nonstring_dtype():
    var = Variable(('x',), np.array([1.0, 2.0, 3.0]), encoding={'dtype': 'int32'})
    encoded_var = conventions.maybe_encode_nonstring_dtype(var, name='test_var')
    assert encoded_var.dtype == np.int32

def test_maybe_default_fill_value():
    var = Variable(('x',), np.array([1.0, 2.0, np.nan]))
    var = conventions.maybe_default_fill_value(var)
    assert var.attrs['_FillValue'] == np.nan

def test_maybe_encode_bools():
    var = Variable(('x',), np.array([True, False, True]))
    encoded_var = conventions.maybe_encode_bools(var)
    assert encoded_var.dtype == np.int8
    assert encoded_var.attrs['dtype'] == 'bool'

def test_ensure_not_multiindex():
    index_var = Variable(('x',), pd.MultiIndex.from_arrays([[1, 2], [3, 4]], names=('a', 'b')))
    with pytest.raises(NotImplementedError):
        conventions.ensure_not_multiindex(index_var, name='multiindex_var')

def test_ensure_dtype_not_object():
    var = Variable(('x',), np.array(['a', 'b', 'c'], dtype=object))
    encoded_var = conventions.ensure_dtype_not_object(var, name='object_var')
    assert encoded_var.dtype != object

def test_encode_cf_variable():
    var = Variable(('x',), np.array([1.0, 2.0, 3.0]), attrs={'units': 'meters'})
    encoded_var = encode_cf_variable(var, name='test_var')
    assert '_FillValue' in encoded_var.attrs

def test_decode_cf_variable():
    var = Variable(('x',), np.array([1, 2, 3], dtype='i1'), attrs={'dtype': 'bool'})
    decoded_var = decode_cf_variable('test_var', var)
    assert decoded_var.dtype == np.bool_

def test_decode_cf():
    ds = Dataset({'temp': ('x', [1, 2, 3], {'units': 'K'})})
    decoded_ds = decode_cf(ds)
    assert 'temp' in decoded_ds

def test_cf_decoder():
    variables = {'temp': Variable(('x',), [1, 2, 3], {'units': 'K'})}
    attributes = {'title': 'Test Dataset'}
    decoded_vars, decoded_attrs = cf_decoder(variables, attributes)
    assert 'temp' in decoded_vars
    assert decoded_attrs['title'] == 'Test Dataset'

def test_cf_encoder():
    variables = {'temp': Variable(('x',), [1, 2, 3], {'units': 'K'})}
    attributes = {'title': 'Test Dataset'}
    encoded_vars, encoded_attrs = cf_encoder(variables, attributes)
    assert 'temp' in encoded_vars
    assert encoded_attrs['title'] == 'Test Dataset'
Coverage: 54.63576158940398
Mutation Score: 15.879999999999995
Output: On branch main
Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_conventions.py

nothing added to commit but untracked files present (use "git add" to track)
commit 14a35489544d26b583ead6cb9324d20eff45d2b4
Author: TestGenEval <>
Date:   Wed Dec 11 13:14:40 2024 +0000

    Testing fixes

diff --git a/xarray/conventions.py b/xarray/conventions.py
index 687da534..8bd316d1 100644
--- a/xarray/conventions.py
+++ b/xarray/conventions.py
@@ -519,16 +519,19 @@ def decode_cf_variables(
             and v.ndim > 0
             and stackable(v.dims[-1])
         )
-        new_vars[k] = decode_cf_variable(
-            k,
-            v,
-            concat_characters=concat_characters,
-            mask_and_scale=mask_and_scale,
-            decode_times=decode_times,
-            stack_char_dim=stack_char_dim,
-            use_cftime=use_cftime,
-            decode_timedelta=decode_timedelta,
-        )
+        try:
+            new_vars[k] = decode_cf_variable(
+                k,
+                v,
+                concat_characters=concat_characters,
+                mask_and_scale=mask_and_scale,
+                decode_times=decode_times,
+                stack_char_dim=stack_char_dim,
+                use_cftime=use_cftime,
+                decode_timedelta=decode_timedelta,
+            )
+        except Exception as e:
+            raise type(e)(f"Failed to decode variable {k!r}: {e}")
         if decode_coords in [True, "coordinates", "all"]:
             var_attrs = new_vars[k].attrs
             if "coordinates" in var_attrs:
diff --git a/xarray/tests/test_conventions.py b/xarray/tests/test_conventions.py
deleted file mode 100644
index 3ee6699f..00000000
--- a/xarray/tests/test_conventions.py
+++ /dev/null
@@ -1,477 +0,0 @@
-from __future__ import annotations
-
-import contextlib
-import warnings
-
-import numpy as np
-import pandas as pd
-import pytest
-
-from xarray import (
-    Dataset,
-    SerializationWarning,
-    Variable,
-    cftime_range,
-    coding,
-    conventions,
-    open_dataset,
-)
-from xarray.backends.common import WritableCFDataStore
-from xarray.backends.memory import InMemoryDataStore
-from xarray.conventions import decode_cf
-from xarray.testing import assert_identical
-
-from . import assert_array_equal, requires_cftime, requires_dask, requires_netCDF4
-from .test_backends import CFEncodedBase
-
-
-class TestBoolTypeArray:
-    def test_booltype_array(self) -> None:
-        x = np.array([1, 0, 1, 1, 0], dtype="i1")
-        bx = conventions.BoolTypeArray(x)
-        assert bx.dtype == bool
-        assert_array_equal(bx, np.array([True, False, True, True, False], dtype=bool))
-
-
-class TestNativeEndiannessArray:
-    def test(self) -> None:
-        x = np.arange(5, dtype=">i8")
-        expected = np.arange(5, dtype="int64")
-        a = conventions.NativeEndiannessArray(x)
-        assert a.dtype == expected.dtype
-        assert a.dtype == expected[:].dtype
-        assert_array_equal(a, expected)
-
-
-def test_decode_cf_with_conflicting_fill_missing_value() -> None:
-    expected = Variable(["t"], [np.nan, np.nan, 2], {"units": "foobar"})
-    var = Variable(
-        ["t"], np.arange(3), {"units": "foobar", "missing_value": 0, "_FillValue": 1}
-    )
-    with warnings.catch_warnings(record=True) as w:
-        actual = conventions.decode_cf_variable("t", var)
-        assert_identical(actual, expected)
-        assert "has multiple fill" in str(w[0].message)
-
-    expected = Variable(["t"], np.arange(10), {"units": "foobar"})
-
-    var = Variable(
-        ["t"],
-        np.arange(10),
-        {"units": "foobar", "missing_value": np.nan, "_FillValue": np.nan},
-    )
-    actual = conventions.decode_cf_variable("t", var)
-    assert_identical(actual, expected)
-
-    var = Variable(
-        ["t"],
-        np.arange(10),
-        {
-            "units": "foobar",
-            "missing_value": np.float32(np.nan),
-            "_FillValue": np.float32(np.nan),
-        },
-    )
-    actual = conventions.decode_cf_variable("t", var)
-    assert_identical(actual, expected)
-
-
-@requires_cftime
-class TestEncodeCFVariable:
-    def test_incompatible_attributes(self) -> None:
-        invalid_vars = [
-            Variable(
-                ["t"], pd.date_range("2000-01-01", periods=3), {"units": "foobar"}
-            ),
-            Variable(["t"], pd.to_timedelta(["1 day"]), {"units": "foobar"}),
-            Variable(["t"], [0, 1, 2], {"add_offset": 0}, {"add_offset": 2}),
-            Variable(["t"], [0, 1, 2], {"_FillValue": 0}, {"_FillValue": 2}),
-        ]
-        for var in invalid_vars:
-            with pytest.raises(ValueError):
-                conventions.encode_cf_variable(var)
-
-    def test_missing_fillvalue(self) -> None:
-        v = Variable(["x"], np.array([np.nan, 1, 2, 3]))
-        v.encoding = {"dtype": "int16"}
-        with pytest.warns(Warning, match="floating point data as an integer"):
-            conventions.encode_cf_variable(v)
-
-    def test_multidimensional_coordinates(self) -> None:
-        # regression test for GH1763
-        # Set up test case with coordinates that have overlapping (but not
-        # identical) dimensions.
-        zeros1 = np.zeros((1, 5, 3))
-        zeros2 = np.zeros((1, 6, 3))
-        zeros3 = np.zeros((1, 5, 4))
-        orig = Dataset(
-            {
-                "lon1": (["x1", "y1"], zeros1.squeeze(0), {}),
-                "lon2": (["x2", "y1"], zeros2.squeeze(0), {}),
-                "lon3": (["x1", "y2"], zeros3.squeeze(0), {}),
-                "lat1": (["x1", "y1"], zeros1.squeeze(0), {}),
-                "lat2": (["x2", "y1"], zeros2.squeeze(0), {}),
-                "lat3": (["x1", "y2"], zeros3.squeeze(0), {}),
-                "foo1": (["time", "x1", "y1"], zeros1, {"coordinates": "lon1 lat1"}),
-                "foo2": (["time", "x2", "y1"], zeros2, {"coordinates": "lon2 lat2"}),
-                "foo3": (["time", "x1", "y2"], zeros3, {"coordinates": "lon3 lat3"}),
-                "time": ("time", [0.0], {"units": "hours since 2017-01-01"}),
-            }
-        )
-        orig = conventions.decode_cf(orig)
-        # Encode the coordinates, as they would be in a netCDF output file.
-        enc, attrs = conventions.encode_dataset_coordinates(orig)
-        # Make sure we have the right coordinates for each variable.
-        foo1_coords = enc["foo1"].attrs.get("coordinates", "")
-        foo2_coords = enc["foo2"].attrs.get("coordinates", "")
-        foo3_coords = enc["foo3"].attrs.get("coordinates", "")
-        assert set(foo1_coords.split()) == {"lat1", "lon1"}
-        assert set(foo2_coords.split()) == {"lat2", "lon2"}
-        assert set(foo3_coords.split()) == {"lat3", "lon3"}
-        # Should not have any global coordinates.
-        assert "coordinates" not in attrs
-
-    def test_var_with_coord_attr(self) -> None:
-        # regression test for GH6310
-        # don't overwrite user-defined "coordinates" attributes
-        orig = Dataset(
-            {"values": ("time", np.zeros(2), {"coordinates": "time lon lat"})},
-            coords={
-                "time": ("time", np.zeros(2)),
-                "lat": ("time", np.zeros(2)),
-                "lon": ("time", np.zeros(2)),
-            },
-        )
-        # Encode the coordinates, as they would be in a netCDF output file.
-        enc, attrs = conventions.encode_dataset_coordinates(orig)
-        # Make sure we have the right coordinates for each variable.
-        values_coords = enc["values"].attrs.get("coordinates", "")
-        assert set(values_coords.split()) == {"time", "lat", "lon"}
-        # Should not have any global coordinates.
-        assert "coordinates" not in attrs
-
-    def test_do_not_overwrite_user_coordinates(self) -> None:
-        orig = Dataset(
-            coords={"x": [0, 1, 2], "y": ("x", [5, 6, 7]), "z": ("x", [8, 9, 10])},
-            data_vars={"a": ("x", [1, 2, 3]), "b": ("x", [3, 5, 6])},
-        )
-        orig["a"].encoding["coordinates"] = "y"
-        orig["b"].encoding["coordinates"] = "z"
-        enc, _ = conventions.encode_dataset_coordinates(orig)
-        assert enc["a"].attrs["coordinates"] == "y"
-        assert enc["b"].attrs["coordinates"] == "z"
-        orig["a"].attrs["coordinates"] = "foo"
-        with pytest.raises(ValueError, match=r"'coordinates' found in both attrs"):
-            conventions.encode_dataset_coordinates(orig)
-
-    def test_emit_coordinates_attribute_in_attrs(self) -> None:
-        orig = Dataset(
-            {"a": 1, "b": 1},
-            coords={"t": np.array("2004-11-01T00:00:00", dtype=np.datetime64)},
-        )
-
-        orig["a"].attrs["coordinates"] = None
-        enc, _ = conventions.encode_dataset_coordinates(orig)
-
-        # check coordinate attribute emitted for 'a'
-        assert "coordinates" not in enc["a"].attrs
-        assert "coordinates" not in enc["a"].encoding
-
-        # check coordinate attribute not emitted for 'b'
-        assert enc["b"].attrs.get("coordinates") == "t"
-        assert "coordinates" not in enc["b"].encoding
-
-    def test_emit_coordinates_attribute_in_encoding(self) -> None:
-        orig = Dataset(
-            {"a": 1, "b": 1},
-            coords={"t": np.array("2004-11-01T00:00:00", dtype=np.datetime64)},
-        )
-
-        orig["a"].encoding["coordinates"] = None
-        enc, _ = conventions.encode_dataset_coordinates(orig)
-
-        # check coordinate attribute emitted for 'a'
-        assert "coordinates" not in enc["a"].attrs
-        assert "coordinates" not in enc["a"].encoding
-
-        # check coordinate attribute not emitted for 'b'
-        assert enc["b"].attrs.get("coordinates") == "t"
-        assert "coordinates" not in enc["b"].encoding
-
-    @requires_dask
-    def test_string_object_warning(self) -> None:
-        original = Variable(("x",), np.array(["foo", "bar"], dtype=object)).chunk()
-        with pytest.warns(SerializationWarning, match="dask array with dtype=object"):
-            encoded = conventions.encode_cf_variable(original)
-        assert_identical(original, encoded)
-
-
-@requires_cftime
-class TestDecodeCF:
-    def test_dataset(self) -> None:
-        original = Dataset(
-            {
-                "t": ("t", [0, 1, 2], {"units": "days since 2000-01-01"}),
-                "foo": ("t", [0, 0, 0], {"coordinates": "y", "units": "bar"}),
-                "y": ("t", [5, 10, -999], {"_FillValue": -999}),
-            }
-        )
-        expected = Dataset(
-            {"foo": ("t", [0, 0, 0], {"units": "bar"})},
-            {
-                "t": pd.date_range("2000-01-01", periods=3),
-                "y": ("t", [5.0, 10.0, np.nan]),
-            },
-        )
-        actual = conventions.decode_cf(original)
-        assert_identical(expected, actual)
-
-    def test_invalid_coordinates(self) -> None:
-        # regression test for GH308
-        original = Dataset({"foo": ("t", [1, 2], {"coordinates": "invalid"})})
-        actual = conventions.decode_cf(original)
-        assert_identical(original, actual)
-
-    def test_decode_coordinates(self) -> None:
-        # regression test for GH610
-        original = Dataset(
-            {"foo": ("t", [1, 2], {"coordinates": "x"}), "x": ("t", [4, 5])}
-        )
-        actual = conventions.decode_cf(original)
-        assert actual.foo.encoding["coordinates"] == "x"
-
-    def test_0d_int32_encoding(self) -> None:
-        original = Variable((), np.int32(0), encoding={"dtype": "int64"})
-        expected = Variable((), np.int64(0))
-        actual = conventions.maybe_encode_nonstring_dtype(original)
-        assert_identical(expected, actual)
-
-    def test_decode_cf_with_multiple_missing_values(self) -> None:
-        original = Variable(["t"], [0, 1, 2], {"missing_value": np.array([0, 1])})
-        expected = Variable(["t"], [np.nan, np.nan, 2], {})
-        with warnings.catch_warnings(record=True) as w:
-            actual = conventions.decode_cf_variable("t", original)
-            assert_identical(expected, actual)
-            assert "has multiple fill" in str(w[0].message)
-
-    def test_decode_cf_with_drop_variables(self) -> None:
-        original = Dataset(
-            {
-                "t": ("t", [0, 1, 2], {"units": "days since 2000-01-01"}),
-                "x": ("x", [9, 8, 7], {"units": "km"}),
-                "foo": (
-                    ("t", "x"),
-                    [[0, 0, 0], [1, 1, 1], [2, 2, 2]],
-                    {"units": "bar"},
-                ),
-                "y": ("t", [5, 10, -999], {"_FillValue": -999}),
-            }
-        )
-        expected = Dataset(
-            {
-                "t": pd.date_range("2000-01-01", periods=3),
-                "foo": (
-                    ("t", "x"),
-                    [[0, 0, 0], [1, 1, 1], [2, 2, 2]],
-                    {"units": "bar"},
-                ),
-                "y": ("t", [5, 10, np.nan]),
-            }
-        )
-        actual = conventions.decode_cf(original, drop_variables=("x",))
-        actual2 = conventions.decode_cf(original, drop_variables="x")
-        assert_identical(expected, actual)
-        assert_identical(expected, actual2)
-
-    @pytest.mark.filterwarnings("ignore:Ambiguous reference date string")
-    def test_invalid_time_units_raises_eagerly(self) -> None:
-        ds = Dataset({"time": ("time", [0, 1], {"units": "foobar since 123"})})
-        with pytest.raises(ValueError, match=r"unable to decode time"):
-            decode_cf(ds)
-
-    @requires_cftime
-    def test_dataset_repr_with_netcdf4_datetimes(self) -> None:
-        # regression test for #347
-        attrs = {"units": "days since 0001-01-01", "calendar": "noleap"}
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "unable to decode time")
-            ds = decode_cf(Dataset({"time": ("time", [0, 1], attrs)}))
-            assert "(time) object" in repr(ds)
-
-        attrs = {"units": "days since 1900-01-01"}
-        ds = decode_cf(Dataset({"time": ("time", [0, 1], attrs)}))
-        assert "(time) datetime64[ns]" in repr(ds)
-
-    @requires_cftime
-    def test_decode_cf_datetime_transition_to_invalid(self) -> None:
-        # manually create dataset with not-decoded date
-        from datetime import datetime
-
-        ds = Dataset(coords={"time": [0, 266 * 365]})
-        units = "days since 2000-01-01 00:00:00"
-        ds.time.attrs = dict(units=units)
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "unable to decode time")
-            ds_decoded = conventions.decode_cf(ds)
-
-        expected = np.array([datetime(2000, 1, 1, 0, 0), datetime(2265, 10, 28, 0, 0)])
-
-        assert_array_equal(ds_decoded.time.values, expected)
-
-    @requires_dask
-    def test_decode_cf_with_dask(self) -> None:
-        import dask.array as da
-
-        original = Dataset(
-            {
-                "t": ("t", [0, 1, 2], {"units": "days since 2000-01-01"}),
-                "foo": ("t", [0, 0, 0], {"coordinates": "y", "units": "bar"}),
-                "bar": ("string2", [b"a", b"b"]),
-                "baz": (("x"), [b"abc"], {"_Encoding": "utf-8"}),
-                "y": ("t", [5, 10, -999], {"_FillValue": -999}),
-            }
-        ).chunk()
-        decoded = conventions.decode_cf(original)
-        print(decoded)
-        assert all(
-            isinstance(var.data, da.Array)
-            for name, var in decoded.variables.items()
-            if name not in decoded.xindexes
-        )
-        assert_identical(decoded, conventions.decode_cf(original).compute())
-
-    @requires_dask
-    def test_decode_dask_times(self) -> None:
-        original = Dataset.from_dict(
-            {
-                "coords": {},
-                "dims": {"time": 5},
-                "data_vars": {
-                    "average_T1": {
-                        "dims": ("time",),
-                        "attrs": {"units": "days since 1958-01-01 00:00:00"},
-                        "data": [87659.0, 88024.0, 88389.0, 88754.0, 89119.0],
-                    }
-                },
-            }
-        )
-        assert_identical(
-            conventions.decode_cf(original.chunk()),
-            conventions.decode_cf(original).chunk(),
-        )
-
-    def test_decode_cf_time_kwargs(self) -> None:
-        ds = Dataset.from_dict(
-            {
-                "coords": {
-                    "timedelta": {
-                        "data": np.array([1, 2, 3], dtype="int64"),
-                        "dims": "timedelta",
-                        "attrs": {"units": "days"},
-                    },
-                    "time": {
-                        "data": np.array([1, 2, 3], dtype="int64"),
-                        "dims": "time",
-                        "attrs": {"units": "days since 2000-01-01"},
-                    },
-                },
-                "dims": {"time": 3, "timedelta": 3},
-                "data_vars": {
-                    "a": {"dims": ("time", "timedelta"), "data": np.ones((3, 3))},
-                },
-            }
-        )
-
-        dsc = conventions.decode_cf(ds)
-        assert dsc.timedelta.dtype == np.dtype("m8[ns]")
-        assert dsc.time.dtype == np.dtype("M8[ns]")
-        dsc = conventions.decode_cf(ds, decode_times=False)
-        assert dsc.timedelta.dtype == np.dtype("int64")
-        assert dsc.time.dtype == np.dtype("int64")
-        dsc = conventions.decode_cf(ds, decode_times=True, decode_timedelta=False)
-        assert dsc.timedelta.dtype == np.dtype("int64")
-        assert dsc.time.dtype == np.dtype("M8[ns]")
-        dsc = conventions.decode_cf(ds, decode_times=False, decode_timedelta=True)
-        assert dsc.timedelta.dtype == np.dtype("m8[ns]")
-        assert dsc.time.dtype == np.dtype("int64")
-
-
-class CFEncodedInMemoryStore(WritableCFDataStore, InMemoryDataStore):
-    def encode_variable(self, var):
-        """encode one variable"""
-        coder = coding.strings.EncodedStringCoder(allows_unicode=True)
-        var = coder.encode(var)
-        return var
-
-
-@requires_netCDF4
-class TestCFEncodedDataStore(CFEncodedBase):
-    @contextlib.contextmanager
-    def create_store(self):
-        yield CFEncodedInMemoryStore()
-
-    @contextlib.contextmanager
-    def roundtrip(
-        self, data, save_kwargs=None, open_kwargs=None, allow_cleanup_failure=False
-    ):
-        if save_kwargs is None:
-            save_kwargs = {}
-        if open_kwargs is None:
-            open_kwargs = {}
-        store = CFEncodedInMemoryStore()
-        data.dump_to_store(store, **save_kwargs)
-        yield open_dataset(store, **open_kwargs)
-
-    @pytest.mark.skip("cannot roundtrip coordinates yet for CFEncodedInMemoryStore")
-    def test_roundtrip_coordinates(self) -> None:
-        pass
-
-    def test_invalid_dataarray_names_raise(self) -> None:
-        # only relevant for on-disk file formats
-        pass
-
-    def test_encoding_kwarg(self) -> None:
-        # we haven't bothered to raise errors yet for unexpected encodings in
-        # this test dummy
-        pass
-
-    def test_encoding_kwarg_fixed_width_string(self) -> None:
-        # CFEncodedInMemoryStore doesn't support explicit string encodings.
-        pass
-
-
-class TestDecodeCFVariableWithArrayUnits:
-    def test_decode_cf_variable_with_array_units(self) -> None:
-        v = Variable(["t"], [1, 2, 3], {"units": np.array(["foobar"], dtype=object)})
-        v_decoded = conventions.decode_cf_variable("test2", v)
-        assert_identical(v, v_decoded)
-
-
-def test_decode_cf_variable_timedelta64():
-    variable = Variable(["time"], pd.timedelta_range("1D", periods=2))
-    decoded = conventions.decode_cf_variable("time", variable)
-    assert decoded.encoding == {}
-    assert_identical(decoded, variable)
-
-
-def test_decode_cf_variable_datetime64():
-    variable = Variable(["time"], pd.date_range("2000", periods=2))
-    decoded = conventions.decode_cf_variable("time", variable)
-    assert decoded.encoding == {}
-    assert_identical(decoded, variable)
-
-
-@requires_cftime
-def test_decode_cf_variable_cftime():
-    variable = Variable(["time"], cftime_range("2000", periods=2))
-    decoded = conventions.decode_cf_variable("time", variable)
-    assert decoded.encoding == {}
-    assert_identical(decoded, variable)
-
-
-def test_scalar_units() -> None:
-    # test that scalar units does not raise an exception
-    var = Variable(["t"], [np.nan, np.nan, 2], {"units": np.nan})
-
-    actual = conventions.decode_cf_variable("t", var)
-    assert_identical(actual, var)
Obtaining file:///testbed
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.19 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev14+g14a35489) (1.23.0)
Requirement already satisfied: pandas>=1.2 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev14+g14a35489) (1.5.3)
Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==2022.9.1.dev14+g14a35489) (23.1)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.2->xarray==2022.9.1.dev14+g14a35489) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.2->xarray==2022.9.1.dev14+g14a35489) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2->xarray==2022.9.1.dev14+g14a35489) (1.16.0)
Building wheels for collected packages: xarray
  Building editable for xarray (pyproject.toml): started
  Building editable for xarray (pyproject.toml): finished with status 'done'
  Created wheel for xarray: filename=xarray-2022.9.1.dev14+g14a35489-0.editable-py3-none-any.whl size=8987 sha256=1aeb5962780a6ba11e718c5ef633c3a57bb674b27ffd87355089aa4bb9e6f5ea
  Stored in directory: /tmp/pip-ephem-wheel-cache-opznseca/wheels/0d/a6/cb/465a7b303d624cc531250fa27c75d038ddc29430bdb6ba7c9f
Successfully built xarray
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 2022.9.1.dev14+g14a35489
    Uninstalling xarray-2022.9.1.dev14+g14a35489:
      Successfully uninstalled xarray-2022.9.1.dev14+g14a35489
Successfully installed xarray-2022.9.1.dev14+g14a35489
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, timeout-2.3.1, xdist-3.6.1
collected 9 items

xarray/tests/test_conventions.py .........                               [100%]

=============================== warnings summary ===============================
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    from pkg_resources import get_distribution

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

xarray/tests/test_conventions.py::test_maybe_encode_nonstring_dtype
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pluggy/_manager.py:120: SerializationWarning: saving variable test_var with floating point data as an integer dtype without any _FillValue to use for NaNs
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_conventions.py::test_NativeEndiannessArray
PASSED xarray/tests/test_conventions.py::test_BoolTypeArray
PASSED xarray/tests/test_conventions.py::test_maybe_encode_nonstring_dtype
PASSED xarray/tests/test_conventions.py::test_maybe_encode_bools
PASSED xarray/tests/test_conventions.py::test_encode_cf_variable
PASSED xarray/tests/test_conventions.py::test_decode_cf_variable
PASSED xarray/tests/test_conventions.py::test_decode_cf
PASSED xarray/tests/test_conventions.py::test_cf_decoder
PASSED xarray/tests/test_conventions.py::test_cf_encoder
======================== 9 passed, 9 warnings in 0.18s =========================

