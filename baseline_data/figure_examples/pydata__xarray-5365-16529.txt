Instance ID: pydata__xarray-5365-16529

Baseline 1 (Pynguin):
Predicted Test Suite: # Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import xarray.core.computation as module_0
import pandas._testing as module_1
import unittest.loader as module_2
import scipy._lib._uarray._backend as module_3
import scipy.io.matlab.mio4 as module_4


def test_case_0():
    var_0 = module_0.unify_chunks()


@pytest.mark.xfail(strict=True)
def test_case_1():
    bool_0 = True
    none_type_0 = None
    list_0 = [bool_0, bool_0]
    var_0 = module_0.result_name(list_0)
    module_0.apply_dataarray_vfunc(bool_0, signature=none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_2():
    dict_0 = module_1.getSeriesData()
    module_0.where(dict_0, dict_0, dict_0)


def test_case_3():
    var_0 = module_0.unify_chunks()
    var_1 = module_0.result_name(var_0)


def test_case_4():
    none_type_0 = None
    with pytest.raises(AssertionError):
        module_0.apply_groupby_func(none_type_0)


def test_case_5():
    str_0 = "&{W=ah~J\x0co>Qcd"
    list_0 = []
    var_0 = module_0.result_name(list_0)
    none_type_0 = None
    list_1 = [none_type_0, none_type_0, none_type_0]
    with pytest.raises(AssertionError):
        module_0.apply_groupby_func(str_0, *list_1)


@pytest.mark.xfail(strict=True)
def test_case_6():
    none_type_0 = None
    module_0.apply_array_ufunc(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_7():
    dict_0 = module_1.getMixedTypeDict()
    u_func_signature_0 = module_0._UFuncSignature(dict_0)
    assert (
        f"{type(u_func_signature_0).__module__}.{type(u_func_signature_0).__qualname__}"
        == "xarray.core.computation._UFuncSignature"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_input_core_dims).__module__}.{type(module_0._UFuncSignature.all_input_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_output_core_dims).__module__}.{type(module_0._UFuncSignature.all_output_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_core_dims).__module__}.{type(module_0._UFuncSignature.all_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.dims_map).__module__}.{type(module_0._UFuncSignature.dims_map).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_inputs).__module__}.{type(module_0._UFuncSignature.num_inputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_outputs).__module__}.{type(module_0._UFuncSignature.num_outputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.input_core_dims).__module__}.{type(module_0._UFuncSignature.input_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    assert (
        f"{type(module_0._UFuncSignature.output_core_dims).__module__}.{type(module_0._UFuncSignature.output_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    module_0.where(dict_0, dict_0, dict_0)


def test_case_8():
    list_0 = []
    u_func_signature_0 = module_0._UFuncSignature(list_0)
    assert (
        f"{type(u_func_signature_0).__module__}.{type(u_func_signature_0).__qualname__}"
        == "xarray.core.computation._UFuncSignature"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_input_core_dims).__module__}.{type(module_0._UFuncSignature.all_input_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_output_core_dims).__module__}.{type(module_0._UFuncSignature.all_output_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_core_dims).__module__}.{type(module_0._UFuncSignature.all_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.dims_map).__module__}.{type(module_0._UFuncSignature.dims_map).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_inputs).__module__}.{type(module_0._UFuncSignature.num_inputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_outputs).__module__}.{type(module_0._UFuncSignature.num_outputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.input_core_dims).__module__}.{type(module_0._UFuncSignature.input_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    assert (
        f"{type(module_0._UFuncSignature.output_core_dims).__module__}.{type(module_0._UFuncSignature.output_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    with pytest.raises(TypeError):
        module_0.cov(u_func_signature_0, u_func_signature_0)


def test_case_9():
    none_type_0 = None
    with pytest.raises(TypeError):
        module_0.corr(none_type_0, none_type_0, none_type_0)


def test_case_10():
    with pytest.raises(TypeError):
        module_0.dot()


@pytest.mark.xfail(strict=True)
def test_case_11():
    none_type_0 = None
    module_0.polyval(none_type_0, none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_12():
    none_type_0 = None
    module_0.apply_dataset_vfunc(
        none_type_0,
        signature=none_type_0,
        dataset_join=none_type_0,
        fill_value=none_type_0,
        keep_attrs=none_type_0,
    )


@pytest.mark.xfail(strict=True)
def test_case_13():
    var_0 = module_0.unify_chunks()
    var_1 = var_0.__repr__()
    list_0 = module_0.collect_dict_values(var_0, var_1)
    list_1 = [var_1, var_1, var_1, var_1]
    u_func_signature_0 = module_0._UFuncSignature(list_1)
    assert (
        f"{type(u_func_signature_0).__module__}.{type(u_func_signature_0).__qualname__}"
        == "xarray.core.computation._UFuncSignature"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_input_core_dims).__module__}.{type(module_0._UFuncSignature.all_input_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_output_core_dims).__module__}.{type(module_0._UFuncSignature.all_output_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_core_dims).__module__}.{type(module_0._UFuncSignature.all_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.dims_map).__module__}.{type(module_0._UFuncSignature.dims_map).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_inputs).__module__}.{type(module_0._UFuncSignature.num_inputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_outputs).__module__}.{type(module_0._UFuncSignature.num_outputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.input_core_dims).__module__}.{type(module_0._UFuncSignature.input_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    assert (
        f"{type(module_0._UFuncSignature.output_core_dims).__module__}.{type(module_0._UFuncSignature.output_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    var_2 = u_func_signature_0.__repr__()
    assert (
        var_2
        == "_UFuncSignature([('(', ')'), ('(', ')'), ('(', ')'), ('(', ')')], [()])"
    )
    module_2.getTestCaseNames(list_1, list_1, list_1)


@pytest.mark.xfail(strict=True)
def test_case_14():
    none_type_0 = None
    module_0.ordered_set_union(none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_15():
    var_0 = module_0.unify_chunks()
    var_1 = var_0.__repr__()
    list_0 = module_0.collect_dict_values(var_0, var_1)
    u_func_signature_0 = module_0._UFuncSignature(var_0)
    assert (
        f"{type(u_func_signature_0).__module__}.{type(u_func_signature_0).__qualname__}"
        == "xarray.core.computation._UFuncSignature"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_input_core_dims).__module__}.{type(module_0._UFuncSignature.all_input_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_output_core_dims).__module__}.{type(module_0._UFuncSignature.all_output_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.all_core_dims).__module__}.{type(module_0._UFuncSignature.all_core_dims).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.dims_map).__module__}.{type(module_0._UFuncSignature.dims_map).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_inputs).__module__}.{type(module_0._UFuncSignature.num_inputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.num_outputs).__module__}.{type(module_0._UFuncSignature.num_outputs).__qualname__}"
        == "builtins.property"
    )
    assert (
        f"{type(module_0._UFuncSignature.input_core_dims).__module__}.{type(module_0._UFuncSignature.input_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    assert (
        f"{type(module_0._UFuncSignature.output_core_dims).__module__}.{type(module_0._UFuncSignature.output_core_dims).__qualname__}"
        == "builtins.member_descriptor"
    )
    module_0.unify_chunks(*list_0)


@pytest.mark.xfail(strict=True)
def test_case_16():
    none_type_0 = None
    list_0 = [none_type_0, none_type_0, none_type_0]
    module_0.unify_chunks(*list_0)


def test_case_17():
    none_type_0 = None
    with pytest.raises(TypeError):
        module_0.apply_dataset_vfunc(
            none_type_0,
            signature=none_type_0,
            join=none_type_0,
            dataset_join=none_type_0,
        )


@pytest.mark.xfail(strict=True)
def test_case_18():
    dict_0 = module_1.getSeriesData()
    none_type_0 = None
    module_0.where(dict_0, none_type_0, none_type_0)


@pytest.mark.xfail(strict=True)
def test_case_19():
    dict_0 = module_1.getSeriesData()
    var_0 = module_3.wrap_single_convertor_instance(dict_0)
    module_0.unified_dim_sizes(dict_0)


@pytest.mark.xfail(strict=True)
def test_case_20():
    dict_0 = module_4.__dir__()
    module_0.apply_dataarray_vfunc(
        dict_0, *dict_0, signature=dict_0, exclude_dims=dict_0
    )


def test_case_21():
    var_0 = module_0.unify_chunks()
    list_0 = module_0.collect_dict_values(var_0, var_0)
    var_1 = var_0.__eq__(var_0)
    var_2 = module_0.result_name(var_0)
    iterable_0 = module_0.ordered_set_union(var_0)
    with pytest.raises(TypeError):
        module_0.dot()

Coverage: 38.819320214669055
Mutation Score: 5.540000000000006

Baseline 2 (CodaMosa):
Predicted Test Suite: import builtins as module_1
import xarray.core.computation as module_0
import xarray.core.variable as module_1
import xarray.core.variable as module_2

def test_case_1():
    try:
        dict_0 = {}
        list_0 = [dict_0, dict_0, dict_0, dict_0]
        list_1 = [list_0]
        var_0 = module_0.apply_dataarray_vfunc(list_0, *list_1, signature=dict_0)
    except BaseException:
        pass


def test_case_2():
    try:
        bytes_0 = b'\x00i\xe5\xd5\x1b{#I\xb8\xb9\xf4D\x03\xf2<'
        dict_0 = {}
        var_0 = module_0.where(bytes_0, dict_0, dict_0)
    except BaseException:
        pass


def test_case_3():
    try:
        list_0 = []
        iterable_0 = module_0.ordered_set_intersection(list_0)
    except BaseException:
        pass


def test_case_4():
    try:
        object_0 = module_1.object()
        list_0 = [object_0]
        any_0 = module_0.result_name(list_0)
        assert any_0 is None
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        dict_0 = {}
        bool_0 = False
        object_1 = module_1.object()
        int_0 = 737
        hashable_0 = None
        dict_1 = {object_1: int_0, hashable_0: int_0}
        var_0 = module_0.where(bool_0, dict_0, dict_1)
    except BaseException:
        pass


def test_case_5():
    try:
        str_0 = ''
        var_0 = module_0.apply_groupby_func(str_0)
    except BaseException:
        pass


def test_case_6():
    try:
        str_0 = 'j'
        dict_0 = {str_0: str_0, str_0: str_0, str_0: str_0, str_0: str_0}
        var_0 = module_0.where(str_0, dict_0, dict_0)
    except BaseException:
        pass


def test_case_7():
    try:
        dict_0 = {}
        var_0 = module_0.apply_array_ufunc(dict_0)
    except BaseException:
        pass


def test_case_8():
    try:
        var_0 = module_0.dot()
    except BaseException:
        pass


def test_case_9():
    try:
        bytes_0 = b'\xa8\xb1\x8a\x02\xe0\x05\xa02\x86\xb1w\xbc\x94\xbe.\xb2\xbe|\xec\xaa'
        list_0 = [bytes_0]
        var_0 = module_0.apply_dataset_vfunc(list_0, signature=bytes_0)
    except BaseException:
        pass


def test_case_10():
    try:
        list_0 = None
        list_1 = []
        var_0 = module_0.corr(list_0, list_1)
    except BaseException:
        pass


def test_case_11():
    try:
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        callable_0 = None
        str_0 = 'operator.gt'
        none_type_0 = None
        any_0 = module_0.apply_ufunc(callable_0, output_core_dims=str_0, join=str_0, keep_attrs=str_0, output_dtypes=none_type_0)
    except BaseException:
        pass


def test_case_12():
    try:
        optional_0 = None
        str_0 = "VT9} 'Uq@}b~"
        var_0 = module_0.unify_chunks()
        assert var_0 == ()
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        float_0 = -42.93943185194997
        dict_0 = {float_0: float_0, float_0: optional_0, str_0: optional_0, float_0: float_0, str_0: optional_0}
        list_0 = [str_0, float_0]
        variable_0 = module_2.Variable(str_0, list_0, dict_0)
        assert len(variable_0) == 2
        assert module_2.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_2.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_2.annotations.compiler_flag == 16777216
        assert module_2.TYPE_CHECKING is False
        assert module_2.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        assert module_2.cupy_array_type == ()
        assert module_2.dask_array_type == ()
        assert len(module_2.integer_types) == 2
        assert module_2.sparse_array_type == ()
        assert len(module_2.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
        assert len(module_2.BASIC_INDEXING_TYPES) == 3
        assert module_2.Variable.concat is not None
        var_1 = variable_0.argmax()
        ndarray_0 = variable_0.to_numpy()
        dict_1 = {}
        u_func_signature_0 = module_0._UFuncSignature(ndarray_0, dict_1)
        var_2 = u_func_signature_0.__repr__()
        list_1 = module_0.build_output_coords(list_0, u_func_signature_0, str_0)
        var_3 = module_0.where(variable_0, var_1, list_0)
    except BaseException:
        pass


def test_case_13():
    try:
        list_0 = []
        any_0 = module_0.result_name(list_0)
        assert any_0 is None
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        u_func_signature_0 = module_0._UFuncSignature(list_0)
        var_0 = u_func_signature_0.__str__()
        assert var_0 == '->()'
        var_1 = module_0.unify_chunks()
        assert var_1 == ()
        list_1 = [list_0]
        list_2 = []
        str_0 = '4R_jgni9'
        object_0 = module_1.object(*list_2)
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        any_1 = module_0.apply_ufunc(list_1, *list_2, input_core_dims=list_2, output_core_dims=str_0, dataset_fill_value=object_0, output_dtypes=object_0)
    except BaseException:
        pass


def test_case_14():
    try:
        str_0 = 'jl\r'
        dict_0 = {str_0: str_0, str_0: str_0}
        str_1 = None
        var_0 = module_0.where(str_1, dict_0, dict_0)
    except BaseException:
        pass


def test_case_15():
    try:
        optional_0 = None
        str_0 = '8R9 0'
        float_0 = 1651.0
        dict_0 = {float_0: float_0, float_0: optional_0, str_0: optional_0}
        list_0 = [str_0, float_0]
        variable_0 = module_2.Variable(str_0, list_0, dict_0)
        u_func_signature_0 = None
        var_0 = module_0.cross(variable_0, u_func_signature_0, dim=list_0)
    except BaseException:
        pass


def test_case_16():
    try:
        str_0 = '-'
        list_0 = [str_0, str_0]
        var_0 = module_0.apply_groupby_func(list_0, *list_0)
    except BaseException:
        pass


def test_case_17():
    try:
        int_0 = 2569
        list_0 = [int_0, int_0]
        var_0 = module_0.cov(list_0, list_0)
    except BaseException:
        pass


def test_case_18():
    try:
        bool_0 = True
        dict_0 = {}
        list_0 = [dict_0, dict_0, dict_0]
        bytes_0 = b''
        dict_1 = None
        var_0 = module_0.apply_dataset_vfunc(bool_0, signature=list_0, dataset_join=bytes_0, fill_value=dict_1)
    except BaseException:
        pass


def test_case_19():
    try:
        optional_0 = None
        bytes_0 = b'/f\xe5\xdf\xc5\xdaHu-\xc2\x89@u'
        bytes_1 = b'\xf99j\xec\xfe\x92*\xcd\xa4m+\xc4\x84'
        tuple_0 = None
        list_0 = [optional_0, bytes_0, bytes_1]
        list_1 = [list_0, list_0, list_0, list_0]
        var_0 = module_0.polyval(tuple_0, list_1)
    except BaseException:
        pass


def test_case_20():
    try:
        dict_0 = None
        str_0 = 'qcgvh-35i!HT'
        list_0 = [str_0]
        list_1 = [dict_0, list_0, dict_0, str_0]
        bool_0 = True
        any_0 = module_0.apply_ufunc(list_1, *list_0, vectorize=bool_0, keep_attrs=bool_0, output_dtypes=str_0)
    except BaseException:
        pass


def test_case_21():
    try:
        str_0 = '"#Gb5-^C$oy$'
        bool_0 = False
        str_1 = 'p'
        object_0 = None
        bytes_0 = b'\xb1\x14v\x13N~b\xae\x8dk/\xbe/'
        any_0 = module_0.apply_ufunc(str_0, vectorize=bool_0, dataset_join=str_1, dataset_fill_value=object_0, kwargs=bytes_0)
    except BaseException:
        pass


def test_case_22():
    try:
        optional_0 = None
        dict_0 = None
        dict_1 = {dict_0: dict_0, optional_0: dict_0}
        dict_2 = {}
        u_func_signature_0 = module_0._UFuncSignature(dict_2)
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        var_0 = u_func_signature_0.to_gufunc_string(dict_1)
    except BaseException:
        pass


def test_case_23():
    try:
        str_0 = ''
        callable_0 = None
        set_0 = {str_0}
        dict_0 = {}
        any_0 = module_0.apply_ufunc(callable_0, exclude_dims=set_0, join=str_0, keep_attrs=str_0, dask_gufunc_kwargs=dict_0)
    except BaseException:
        pass


def test_case_24():
    try:
        str_0 = 'use_cftime'
        list_0 = []
        dict_0 = {}
        iterable_0 = module_0.ordered_set_union(list_0)
        assert module_0.TYPE_CHECKING is False
        list_1 = [iterable_0, iterable_0, iterable_0, iterable_0]
        iterable_1 = module_0.ordered_set_intersection(list_1)
        object_0 = None
        str_1 = "Z=U'O%X\x0c&S\nm"
        dict_1 = {str_0: iterable_1, str_1: object_0, str_0: dict_0}
        list_2 = []
        any_0 = module_0.apply_ufunc(object_0, exclude_dims=dict_1, dask_gufunc_kwargs=list_2)
    except BaseException:
        pass


def test_case_25():
    try:
        str_0 = 'j'
        dict_0 = {str_0: str_0, str_0: str_0}
        list_0 = [dict_0]
        var_0 = module_0.unify_chunks(*list_0)
    except BaseException:
        pass


def test_case_26():
    try:
        bool_0 = True
        list_0 = [bool_0, bool_0, bool_0]
        var_0 = module_0.unify_chunks(*list_0)
    except BaseException:
        pass


def test_case_27():
    try:
        dict_0 = None
        list_0 = []
        int_0 = -2233
        var_0 = module_0.apply_dataset_vfunc(dict_0, signature=list_0, join=dict_0, dataset_join=int_0, exclude_dims=list_0)
    except BaseException:
        pass


def test_case_28():
    try:
        str_0 = 'C8dMQfLaolE-|\x0c8v u'
        list_0 = []
        variable_0 = module_2.Variable(str_0, list_0)
        list_1 = [variable_0, variable_0]
        dict_0 = {str_0: variable_0}
        var_0 = module_0.where(list_1, dict_0, variable_0)
    except BaseException:
        pass


def test_case_29():
    try:
        optional_0 = None
        str_0 = '<'
        float_0 = 2586.1678680426626
        dict_0 = {str_0: str_0, str_0: str_0, optional_0: str_0}
        object_0 = module_1.object()
        bool_0 = True
        list_0 = [optional_0, float_0, dict_0]
        list_1 = [list_0]
        dict_1 = {str_0: list_0}
        list_2 = [list_1, list_1, list_1]
        variable_0 = None
        tuple_0 = (list_1, dict_1, list_2, variable_0)
        str_1 = '8'
        str_2 = "Qy:&UCZ]'TB VWJV "
        str_3 = 'This function creates an appropriate datastore for writing a dataset to\n    disk as a netCDF file\n\n    See `Dataset.to_netcdf` for full API docs.\n\n    The ``multifile`` argument is only for the private use of save_mfdataset.\n    '
        str_4 = '\\\\yVK+cF2(>[IU]@gN'
        dict_2 = {str_4: list_1}
        any_0 = module_0.apply_ufunc(bool_0, *list_0, input_core_dims=tuple_0, output_core_dims=str_1, dataset_join=str_2, keep_attrs=str_2, dask=str_3, meta=dict_0, dask_gufunc_kwargs=dict_2)
    except BaseException:
        pass


def test_case_30():
    try:
        optional_0 = None
        str_0 = 'HB0Z`7KC'
        dict_0 = {str_0: str_0, str_0: str_0, optional_0: str_0}
        bytes_0 = b'%T(\xd9w9\xdf\xffx\x01\x8f\xf21\xf4\x0bL\xe2'
        list_0 = [dict_0, dict_0, bytes_0]
        bool_0 = True
        str_1 = 'Encode coordinates on the given dataset object into variable specific\n    and global attributes.\n\n    When possible, this is done according to CF conventions.\n\n    Parameters\n    ----------\n    dataset : Dataset\n        Object to encode.\n\n    Returns\n    -------\n    variables : dict\n    attrs : dict\n    '
        tuple_0 = (bool_0, str_1)
        var_0 = module_0.dot(*list_0, dims=tuple_0)
    except BaseException:
        pass


def test_case_31():
    try:
        str_0 = 'C8dMQfLaolE-|\x0c8v u'
        list_0 = []
        variable_0 = module_2.Variable(str_0, list_0)
        dict_0 = {str_0: variable_0}
        var_0 = module_0.where(list_0, dict_0, variable_0)
    except BaseException:
        pass


def test_case_32():
    try:
        str_0 = '%sC* //Wpp=U9cv8*x!'
        str_1 = 'dbW\r'
        dict_0 = {str_0: str_0, str_1: str_1, str_1: str_0}
        dict_1 = {}
        object_0 = module_1.object(**dict_1)
        tuple_0 = (dict_0, object_0)
        iterable_0 = module_0.join_dict_keys(tuple_0)
        assert iterable_0 == ['%sC* //Wpp=U9cv8*x!', 'dbW\r']
        assert module_1.None is None
        assert module_1.False is False
        assert module_1.True is True
        assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
        assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
        assert module_0.annotations.compiler_flag == 16777216
        assert module_0.TYPE_CHECKING is False
        assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
        list_0 = [iterable_0, iterable_0, iterable_0, iterable_0]
        iterable_1 = module_0.ordered_set_union(list_0)
        assert len(iterable_1) == 2
        float_0 = -1233.0631120202595
        dict_2 = {}
        var_0 = module_0.where(float_0, str_0, dict_2)
    except BaseException:
        pass


def test_case_33():
    try:
        str_0 = 'ZC8dMQLaol6-|\x0c8v u'
        bool_0 = False
        list_0 = [bool_0, str_0, str_0]
        bytes_0 = b'\x8e\x9e\xa7n\xdc\n'
        var_0 = module_0.apply_dataarray_vfunc(bool_0, *list_0, signature=list_0, join=bytes_0, keep_attrs=bytes_0)
    except BaseException:
        pass


def test_case_34():
    try:
        optional_0 = None
        str_0 = "VT9} 'Uq@}b~"
        float_0 = -42.93943185194997
        dict_0 = {float_0: float_0, float_0: optional_0, str_0: optional_0, float_0: float_0, str_0: optional_0}
        list_0 = [str_0, float_0]
        variable_0 = module_2.Variable(str_0, list_0, dict_0)
        var_0 = variable_0.argmax()
        var_1 = module_0.where(variable_0, var_0, list_0)
    except BaseException:
        pass


def test_case_35():
    try:
        optional_0 = None
        str_0 = '?'
        float_0 = -42.93943185194997
        dict_0 = {float_0: float_0, float_0: optional_0, str_0: optional_0, float_0: float_0, str_0: optional_0}
        list_0 = [str_0, float_0]
        variable_0 = module_2.Variable(str_0, list_0, dict_0)
        var_0 = variable_0.argmax()
        hashable_0 = None
        int_0 = 3
        tuple_0 = (hashable_0, int_0)
        any_0 = module_0.broadcast_compat_data(variable_0, tuple_0, tuple_0)
    except BaseException:
        pass


def test_case_36():
    try:
        str_0 = 'Qanv'
        list_0 = [str_0]
        variable_0 = module_2.Variable(str_0, list_0)
        hashable_0 = None
        tuple_0 = (hashable_0, variable_0)
        any_0 = module_0.broadcast_compat_data(variable_0, tuple_0, tuple_0)
    except BaseException:
        pass


def test_case_37():
    try:
        optional_0 = None
        str_0 = 'Vs9} Uq}b~'
        float_0 = -43.62218821617937
        dict_0 = {float_0: str_0, float_0: optional_0, optional_0: float_0, float_0: float_0, float_0: optional_0, optional_0: float_0, float_0: float_0, str_0: optional_0, float_0: float_0, str_0: optional_0, optional_0: float_0}
        list_0 = [float_0]
        variable_0 = module_2.Variable(str_0, list_0, dict_0)
        dict_1 = {}
        list_1 = [dict_1, dict_1, dict_1]
        var_0 = module_0.where(dict_0, list_1, variable_0)
    except BaseException:
        pass# Automatically generated by Pynguin.


def test_case_38():
    pass


def test_case_39():
    str_0 = 'zU\tq^'
    float_0 = 2586.0
    var_0 = module_0.where(float_0, str_0, str_0)


def test_case_40():
    list_0 = []
    any_0 = module_0.result_name(list_0)
    assert any_0 is None
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_41():
    list_0 = []
    iterable_0 = module_0.ordered_set_union(list_0)
    assert module_0.TYPE_CHECKING is False
    list_1 = [iterable_0, iterable_0, iterable_0]
    iterable_1 = module_0.ordered_set_union(list_1)


def test_case_42():
    str_0 = 'ZC8dMQLaol6-|\x0c8v u'
    list_0 = []
    variable_0 = module_1.Variable(str_0, list_0)
    list_1 = None
    var_0 = module_0.where(variable_0, list_1, list_0)
    assert len(variable_0) == 0
    assert len(var_0) == 0
    assert module_1.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_1.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_1.annotations.compiler_flag == 16777216
    assert module_1.TYPE_CHECKING is False
    assert module_1.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.cupy_array_type == ()
    assert module_1.dask_array_type == ()
    assert len(module_1.integer_types) == 2
    assert module_1.sparse_array_type == ()
    assert len(module_1.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
    assert len(module_1.BASIC_INDEXING_TYPES) == 3
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.Variable.concat is not None


def test_case_43():
    var_0 = module_0.unify_chunks()
    assert var_0 == ()
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_44():
    bytes_0 = b''
    list_0 = [bytes_0, bytes_0]
    any_0 = module_0.result_name(list_0)
    assert any_0 is None
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_45():
    str_0 = 'zU\tq^'
    float_0 = 0.0
    str_1 = '\x0bRJ'
    dict_0 = {str_0: float_0, str_1: float_0}
    u_func_signature_0 = module_0._UFuncSignature(dict_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.to_gufunc_string()
    assert var_0 == '(dim7,dim4,dim0,dim6,dim5),(dim1,dim3,dim2)->()'


def test_case_46():
    list_0 = []
    iterable_0 = module_0.ordered_set_union(list_0)
    assert module_0.TYPE_CHECKING is False
    list_1 = [iterable_0, iterable_0]
    iterable_1 = module_0.ordered_set_intersection(list_1)


def test_case_47():
    str_0 = '*'
    list_0 = [str_0, str_0, str_0]
    u_func_signature_0 = module_0._UFuncSignature(list_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    list_1 = module_0.build_output_coords(list_0, u_func_signature_0)
    assert list_1 == [{}]


def test_case_48():
    str_0 = ''
    u_func_signature_0 = module_0._UFuncSignature(str_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    dict_0 = {}
    var_0 = u_func_signature_0.__eq__(dict_0)
    assert var_0 is False


def test_case_49():
    bool_0 = None
    list_0 = []
    u_func_signature_0 = module_0._UFuncSignature(list_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.__ne__(bool_0)
    assert var_0 is True


def test_case_50():
    int_0 = 24
    str_0 = 'lT:)Y'
    str_1 = None
    dict_0 = {str_0: str_0, str_1: str_1, str_1: str_1, str_0: str_1}
    list_0 = [str_1, str_1]
    list_1 = [list_0, list_0]
    list_2 = [int_0, dict_0, list_1]
    iterable_0 = module_0.join_dict_keys(list_2)
    assert iterable_0 == ['lT:)Y', None]
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}


def test_case_51():
    str_0 = '3D`w\\{ptXyew\'"X`\n7\rr'
    dict_0 = {str_0: str_0, str_0: str_0}
    u_func_signature_0 = module_0._UFuncSignature(dict_0, dict_0)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.to_gufunc_string()
    assert var_0 == '(dim4,dim6,dim9,dim14,dim8,dim16,dim11,dim13,dim7,dim15,dim10,dim14,dim3,dim2,dim7,dim9,dim0,dim5,dim1,dim12)->(dim4,dim6,dim9,dim14,dim8,dim16,dim11,dim13,dim7,dim15,dim10,dim14,dim3,dim2,dim7,dim9,dim0,dim5,dim1,dim12)'
    str_1 = 'zU^'
    float_0 = 2588.9228
    dict_1 = {}
    var_1 = u_func_signature_0.to_gufunc_string(dict_1)
    assert var_1 == '(dim4,dim6,dim9,dim14,dim8,dim16,dim11,dim13,dim7,dim15,dim10,dim14,dim3,dim2,dim7,dim9,dim0,dim5,dim1,dim12)->(dim4,dim6,dim9,dim14,dim8,dim16,dim11,dim13,dim7,dim15,dim10,dim14,dim3,dim2,dim7,dim9,dim0,dim5,dim1,dim12)'
    var_2 = module_0.where(float_0, str_1, str_1)


def test_case_52():
    str_0 = '#I0Sq3i9?$ 3;x'
    list_0 = []
    variable_0 = module_1.Variable(str_0, list_0)
    list_1 = [str_0]
    var_0 = module_0.where(variable_0, list_1, variable_0)
    assert len(variable_0) == 0
    assert len(var_0) == 0
    assert module_1.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_1.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_1.annotations.compiler_flag == 16777216
    assert module_1.TYPE_CHECKING is False
    assert module_1.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.cupy_array_type == ()
    assert module_1.dask_array_type == ()
    assert len(module_1.integer_types) == 2
    assert module_1.sparse_array_type == ()
    assert len(module_1.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
    assert len(module_1.BASIC_INDEXING_TYPES) == 3
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.Variable.concat is not None


def test_case_53():
    str_0 = 'x'
    str_1 = 'y'
    str_2 = (str_0, str_1)
    int_0 = 1
    int_1 = 2
    int_2 = [int_0, int_1]
    int_3 = 3
    int_4 = 4
    int_5 = [int_3, int_4]
    int_6 = [int_2, int_5]
    variable_0 = module_1.Variable(str_2, int_6)
    int_7 = 5
    int_8 = 6
    variable_1 = [variable_0, variable_0]
    dict_0 = module_0.unified_dim_sizes(variable_1)
    assert len(variable_0) == 2
    assert dict_0 == {'x': 2, 'y': 2}
    assert module_1.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_1.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_1.annotations.compiler_flag == 16777216
    assert module_1.TYPE_CHECKING is False
    assert module_1.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.cupy_array_type == ()
    assert module_1.dask_array_type == ()
    assert len(module_1.integer_types) == 2
    assert module_1.sparse_array_type == ()
    assert len(module_1.NON_NUMPY_SUPPORTED_ARRAY_TYPES) == 2
    assert len(module_1.BASIC_INDEXING_TYPES) == 3
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    assert module_1.Variable.concat is not None
    str_3 = 'z'
    str_4 = (str_0, str_3)
    int_9 = [int_0, int_1, int_3]
    int_10 = [int_4, int_7, int_8]
    int_11 = [int_9, int_10]
    variable_2 = module_1.Variable(str_4, int_11)
    assert len(variable_2) == 2
    variable_3 = [variable_0, variable_2]
    dict_1 = module_0.unified_dim_sizes(variable_3)
    assert dict_1 == {'x': 2, 'y': 2, 'z': 3}
    variable_4 = [variable_0, variable_2]
    str_5 = {str_3}
    dict_2 = module_0.unified_dim_sizes(variable_4, str_5)
    assert dict_2 == {'x': 2, 'y': 2}


def test_case_54():
    str_0 = 'x'
    str_1 = 'y'
    str_2 = (str_0, str_1)
    str_3 = 'z'
    str_4 = [str_2, str_1]
    str_5 = (str_0, str_3)
    str_6 = [str_5]
    u_func_signature_0 = module_0._UFuncSignature(str_4, str_6)
    assert module_0.annotations.optional == (3, 7, 0, 'beta', 1)
    assert module_0.annotations.mandatory == (3, 11, 0, 'alpha', 0)
    assert module_0.annotations.compiler_flag == 16777216
    assert module_0.TYPE_CHECKING is False
    assert module_0.OPTIONS == {'arithmetic_join': 'inner', 'cmap_divergent': 'RdBu_r', 'cmap_sequential': 'viridis', 'display_max_rows': 12, 'display_style': 'html', 'display_width': 80, 'display_expand_attrs': 'default', 'display_expand_coords': 'default', 'display_expand_data_vars': 'default', 'display_expand_data': 'default', 'enable_cftimeindex': True, 'file_cache_maxsize': 128, 'keep_attrs': 'default', 'use_bottleneck': True, 'warn_for_unclosed_files': False}
    var_0 = u_func_signature_0.to_gufunc_string()
    assert var_0 == '(dim0,dim1),(dim1,dim2)->(dim0,dim2)'
    assert var_0 == '(dim0,dim1),(dim1)->(dim0,dim2)'
    str_7 = {str_1}
    var_1 = u_func_signature_0.to_gufunc_string(str_7)
    assert var_1 == '(dim0,dim1_0),(dim1_1)->(dim0,dim2)'

Coverage: 53.66726296958855
Mutation Score: 9.64

Baseline 3 (GPT-4o):
Predicted Test Suite: 
import pytest
import numpy as np
import pandas as pd
import xarray as xr
from xarray.core.computation import (
    _UFuncSignature,
    apply_ufunc,
    broadcast_compat_data,
    collect_dict_values,
    join_dict_keys,
    ordered_set_intersection,
    ordered_set_union,
    result_name,
    unified_dim_sizes,
    cov,
    corr,
    cross,
    dot,
    where,
    polyval,
    _calc_idxminmax,
    unify_chunks,
)

def test_result_name_single_name():
    obj1 = xr.DataArray(name="test")
    assert result_name([obj1]) == "test"

def test_result_name_multiple_names():
    obj1 = xr.DataArray(name="test1")
    obj2 = xr.DataArray(name="test2")
    assert result_name([obj1, obj2]) is None

def test_result_name_no_name():
    obj1 = xr.DataArray()
    assert result_name([obj1]) is None

def test_ordered_set_union():
    assert list(ordered_set_union([[1, 2], [2, 3], [3, 4]])) == [1, 2, 3, 4]

def test_ordered_set_intersection():
    assert list(ordered_set_intersection([[1, 2, 3], [2, 3, 4], [3, 4, 5]])) == [3]

def test_join_dict_keys():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert list(join_dict_keys([dict1, dict2], how='inner')) == ['b']

def test_collect_dict_values():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert collect_dict_values([dict1, dict2], ['a', 'b', 'c'], fill_value=0) == [[1, 0], [2, 3], [0, 4]]

def test_unified_dim_sizes():
    var1 = xr.Variable(('x', 'y'), np.random.rand(3, 4))
    var2 = xr.Variable(('y', 'z'), np.random.rand(4, 5))
    assert unified_dim_sizes([var1, var2]) == {'x': 3, 'y': 4, 'z': 5}

def test_apply_ufunc():
    da = xr.DataArray([1, 2, 3], dims='x')
    result = apply_ufunc(np.sum, da)
    assert result == 6

def test_cov():
    da_a = xr.DataArray([1, 2, 3], dims='x')
    da_b = xr.DataArray([4, 5, 6], dims='x')
    result = cov(da_a, da_b, dim='x')
    assert np.isclose(result, 1.0)

def test_corr():
    da_a = xr.DataArray([1, 2, 3], dims='x')
    da_b = xr.DataArray([4, 5, 6], dims='x')
    result = corr(da_a, da_b, dim='x')
    assert np.isclose(result, 1.0)

def test_cross():
    a = xr.DataArray([1, 2, 3], dims='dim_0')
    b = xr.DataArray([4, 5, 6], dims='dim_0')
    result = cross(a, b, dim='dim_0')
    assert np.array_equal(result, [-3, 6, -3])

def test_dot():
    da_a = xr.DataArray(np.arange(6).reshape(3, 2), dims=["a", "b"])
    da_b = xr.DataArray(np.arange(6).reshape(2, 3), dims=["b", "c"])
    result = dot(da_a, da_b, dims="b")
    expected = np.array([[10, 13, 16], [28, 40, 52], [46, 67, 88]])
    assert np.array_equal(result, expected)

def test_where():
    cond = xr.DataArray([True, False, True], dims='x')
    x = xr.DataArray([1, 2, 3], dims='x')
    y = xr.DataArray([4, 5, 6], dims='x')
    result = where(cond, x, y)
    assert np.array_equal(result, [1, 5, 3])

def test_polyval():
    coord = xr.DataArray([0, 1, 2], dims='x')
    coeffs = xr.DataArray([1, 0, -1], dims='degree')
    result = polyval(coord, coeffs)
    expected = xr.DataArray([1, 0, -1], dims='x')
    assert np.array_equal(result, expected)

def test_unify_chunks():
    da1 = xr.DataArray(np.random.rand(4, 4), dims=['x', 'y']).chunk({'x': 2})
    da2 = xr.DataArray(np.random.rand(4, 4), dims=['x', 'y']).chunk({'y': 2})
    unified_da1, unified_da2 = unify_chunks(da1, da2)
    assert unified_da1.chunks == unified_da2.chunks

Coverage: 46.86940966010734
Mutation Score: 33.19

Approach:
Predicted Test Suite: import pytest
import numpy as np
import pandas as pd
import xarray as xr
from xarray.core.computation import (
    _UFuncSignature,
    apply_ufunc,
    broadcast_compat_data,
    collect_dict_values,
    join_dict_keys,
    ordered_set_intersection,
    ordered_set_union,
    result_name,
    unified_dim_sizes,
    cov,
    corr,
    cross,
    dot,
    where,
    polyval,
    _calc_idxminmax,
    unify_chunks,
)

def test_result_name_single_name():
    obj1 = xr.DataArray(name="test")
    assert result_name([obj1]) == "test"

def test_result_name_multiple_names():
    obj1 = xr.DataArray(name="test1")
    obj2 = xr.DataArray(name="test2")
    assert result_name([obj1, obj2]) is None

def test_result_name_no_name():
    obj1 = xr.DataArray()
    assert result_name([obj1]) is None

def test_ordered_set_union():
    assert list(ordered_set_union([[1, 2], [2, 3], [3, 4]])) == [1, 2, 3, 4]

def test_ordered_set_intersection():
    assert list(ordered_set_intersection([[1, 2, 3], [2, 3, 4], [3, 4, 5]])) == [3]

def test_join_dict_keys():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert list(join_dict_keys([dict1, dict2], how='inner')) == ['b']

def test_collect_dict_values():
    dict1 = {'a': 1, 'b': 2}
    dict2 = {'b': 3, 'c': 4}
    assert collect_dict_values([dict1, dict2], ['a', 'b', 'c'], fill_value=0) == [[1, 0], [2, 3], [0, 4]]

def test_unified_dim_sizes():
    var1 = xr.Variable(('x', 'y'), np.random.rand(3, 4))
    var2 = xr.Variable(('y', 'z'), np.random.rand(4, 5))
    assert unified_dim_sizes([var1, var2]) == {'x': 3, 'y': 4, 'z': 5}

def test_apply_ufunc():
    da = xr.DataArray([1, 2, 3], dims='x')
    result = apply_ufunc(np.sum, da, input_core_dims=[['x']], output_core_dims=[[]])
    assert result == 6

def test_cov():
    da_a = xr.DataArray([1, 2, 3], dims='x')
    da_b = xr.DataArray([4, 5, 6], dims='x')
    result = cov(da_a, da_b, dim='x')
    assert np.isclose(result, 1.0)

def test_corr():
    da_a = xr.DataArray([1, 2, 3], dims='x')
    da_b = xr.DataArray([4, 5, 6], dims='x')
    result = corr(da_a, da_b, dim='x')
    assert np.isclose(result, 1.0)

def test_cross():
    a = xr.DataArray([1, 2, 3], dims='dim_0')
    b = xr.DataArray([4, 5, 6], dims='dim_0')
    result = cross(a, b, dim='dim_0')
    assert np.array_equal(result, [-3, 6, -3])

def test_dot():
    da_a = xr.DataArray(np.arange(6).reshape(3, 2), dims=["a", "b"])
    da_b = xr.DataArray(np.arange(6).reshape(2, 3), dims=["b", "c"])
    result = dot(da_a, da_b, dims="b")
    expected = xr.DataArray(np.array([[ 3,  4,  5], [ 9, 14, 19], [15, 24, 33]]), dims=["a", "c"])
    assert result.equals(expected)

def test_where():
    cond = xr.DataArray([True, False, True], dims='x')
    x = xr.DataArray([1, 2, 3], dims='x')
    y = xr.DataArray([4, 5, 6], dims='x')
    result = where(cond, x, y)
    assert np.array_equal(result, [1, 5, 3])

def test_polyval():
    coord = xr.DataArray([0, 1, 2], dims='x', coords={'x': [0, 1, 2]})
    coeffs = xr.DataArray([1, 0, -1], dims='degree', coords={'degree': [2, 1, 0]})
    result = polyval(coord, coeffs, degree_dim='degree')
    expected = xr.DataArray([-1, 0, 1], dims='x', coords={'x': [0, 1, 2]})
    assert result.equals(expected)

def test_unify_chunks():
    da1 = xr.DataArray(np.random.rand(4, 4), dims=['x', 'y']).chunk({'x': 2})
    da2 = xr.DataArray(np.random.rand(4, 4), dims=['x', 'y']).chunk({'y': 2})
    unified_da1, unified_da2 = unify_chunks(da1, da2)
    assert unified_da1.chunks == unified_da2.chunks
Coverage: 51.8783542039356
Mutation Score: 39.03
Output: On branch main
Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        deleted:    .coveragerc

Untracked files:
  (use "git add <file>..." to include in what will be committed)
        xarray/tests/test_computation.py

no changes added to commit (use "git add" and/or "git commit -a")
commit 52e5e18bdbfbdcbeb1a982d5430d54989dab738d
Author: TestGenEval <>
Date:   Wed Dec 11 12:42:41 2024 +0000

    Testing fixes

diff --git a/xarray/__init__.py b/xarray/__init__.py
index 10f16e58..81ab9f38 100644
--- a/xarray/__init__.py
+++ b/xarray/__init__.py
@@ -16,7 +16,16 @@ from .conventions import SerializationWarning, decode_cf
 from .core.alignment import align, broadcast
 from .core.combine import combine_by_coords, combine_nested
 from .core.common import ALL_DIMS, full_like, ones_like, zeros_like
-from .core.computation import apply_ufunc, corr, cov, dot, polyval, unify_chunks, where
+from .core.computation import (
+    apply_ufunc,
+    corr,
+    cov,
+    cross,
+    dot,
+    polyval,
+    unify_chunks,
+    where,
+)
 from .core.concat import concat
 from .core.dataarray import DataArray
 from .core.dataset import Dataset
@@ -60,6 +69,7 @@ __all__ = (
     "dot",
     "cov",
     "corr",
+    "cross",
     "full_like",
     "get_options",
     "infer_freq",
diff --git a/xarray/core/computation.py b/xarray/core/computation.py
index 191b7771..9fe93c88 100644
--- a/xarray/core/computation.py
+++ b/xarray/core/computation.py
@@ -36,6 +36,7 @@ from .variable import Variable

 if TYPE_CHECKING:
     from .coordinates import Coordinates
+    from .dataarray import DataArray
     from .dataset import Dataset
     from .types import T_Xarray

@@ -1373,6 +1374,214 @@ def _cov_corr(da_a, da_b, dim=None, ddof=0, method=None):
         return corr


+def cross(
+    a: Union[DataArray, Variable], b: Union[DataArray, Variable], *, dim: Hashable
+) -> Union[DataArray, Variable]:
+    """
+    Compute the cross product of two (arrays of) vectors.
+
+    The cross product of `a` and `b` in :math:`R^3` is a vector
+    perpendicular to both `a` and `b`. The vectors in `a` and `b` are
+    defined by the values along the dimension `dim` and can have sizes
+    1, 2 or 3. Where the size of either `a` or `b` is
+    1 or 2, the remaining components of the input vector is assumed to
+    be zero and the cross product calculated accordingly. In cases where
+    both input vectors have dimension 2, the z-component of the cross
+    product is returned.
+
+    Parameters
+    ----------
+    a, b : DataArray or Variable
+        Components of the first and second vector(s).
+    dim : hashable
+        The dimension along which the cross product will be computed.
+        Must be available in both vectors.
+
+    Examples
+    --------
+    Vector cross-product with 3 dimensions:
+
+    >>> a = xr.DataArray([1, 2, 3])
+    >>> b = xr.DataArray([4, 5, 6])
+    >>> xr.cross(a, b, dim="dim_0")
+    <xarray.DataArray (dim_0: 3)>
+    array([-3,  6, -3])
+    Dimensions without coordinates: dim_0
+
+    Vector cross-product with 2 dimensions, returns in the perpendicular
+    direction:
+
+    >>> a = xr.DataArray([1, 2])
+    >>> b = xr.DataArray([4, 5])
+    >>> xr.cross(a, b, dim="dim_0")
+    <xarray.DataArray ()>
+    array(-3)
+
+    Vector cross-product with 3 dimensions but zeros at the last axis
+    yields the same results as with 2 dimensions:
+
+    >>> a = xr.DataArray([1, 2, 0])
+    >>> b = xr.DataArray([4, 5, 0])
+    >>> xr.cross(a, b, dim="dim_0")
+    <xarray.DataArray (dim_0: 3)>
+    array([ 0,  0, -3])
+    Dimensions without coordinates: dim_0
+
+    One vector with dimension 2:
+
+    >>> a = xr.DataArray(
+    ...     [1, 2],
+    ...     dims=["cartesian"],
+    ...     coords=dict(cartesian=(["cartesian"], ["x", "y"])),
+    ... )
+    >>> b = xr.DataArray(
+    ...     [4, 5, 6],
+    ...     dims=["cartesian"],
+    ...     coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
+    ... )
+    >>> xr.cross(a, b, dim="cartesian")
+    <xarray.DataArray (cartesian: 3)>
+    array([12, -6, -3])
+    Coordinates:
+      * cartesian  (cartesian) <U1 'x' 'y' 'z'
+
+    One vector with dimension 2 but coords in other positions:
+
+    >>> a = xr.DataArray(
+    ...     [1, 2],
+    ...     dims=["cartesian"],
+    ...     coords=dict(cartesian=(["cartesian"], ["x", "z"])),
+    ... )
+    >>> b = xr.DataArray(
+    ...     [4, 5, 6],
+    ...     dims=["cartesian"],
+    ...     coords=dict(cartesian=(["cartesian"], ["x", "y", "z"])),
+    ... )
+    >>> xr.cross(a, b, dim="cartesian")
+    <xarray.DataArray (cartesian: 3)>
+    array([-10,   2,   5])
+    Coordinates:
+      * cartesian  (cartesian) <U1 'x' 'y' 'z'
+
+    Multiple vector cross-products. Note that the direction of the
+    cross product vector is defined by the right-hand rule:
+
+    >>> a = xr.DataArray(
+    ...     [[1, 2, 3], [4, 5, 6]],
+    ...     dims=("time", "cartesian"),
+    ...     coords=dict(
+    ...         time=(["time"], [0, 1]),
+    ...         cartesian=(["cartesian"], ["x", "y", "z"]),
+    ...     ),
+    ... )
+    >>> b = xr.DataArray(
+    ...     [[4, 5, 6], [1, 2, 3]],
+    ...     dims=("time", "cartesian"),
+    ...     coords=dict(
+    ...         time=(["time"], [0, 1]),
+    ...         cartesian=(["cartesian"], ["x", "y", "z"]),
+    ...     ),
+    ... )
+    >>> xr.cross(a, b, dim="cartesian")
+    <xarray.DataArray (time: 2, cartesian: 3)>
+    array([[-3,  6, -3],
+           [ 3, -6,  3]])
+    Coordinates:
+      * time       (time) int64 0 1
+      * cartesian  (cartesian) <U1 'x' 'y' 'z'
+
+    Cross can be called on Datasets by converting to DataArrays and later
+    back to a Dataset:
+
+    >>> ds_a = xr.Dataset(dict(x=("dim_0", [1]), y=("dim_0", [2]), z=("dim_0", [3])))
+    >>> ds_b = xr.Dataset(dict(x=("dim_0", [4]), y=("dim_0", [5]), z=("dim_0", [6])))
+    >>> c = xr.cross(
+    ...     ds_a.to_array("cartesian"), ds_b.to_array("cartesian"), dim="cartesian"
+    ... )
+    >>> c.to_dataset(dim="cartesian")
+    <xarray.Dataset>
+    Dimensions:  (dim_0: 1)
+    Dimensions without coordinates: dim_0
+    Data variables:
+        x        (dim_0) int64 -3
+        y        (dim_0) int64 6
+        z        (dim_0) int64 -3
+
+    See Also
+    --------
+    numpy.cross : Corresponding numpy function
+    """
+
+    if dim not in a.dims:
+        raise ValueError(f"Dimension {dim!r} not on a")
+    elif dim not in b.dims:
+        raise ValueError(f"Dimension {dim!r} not on b")
+
+    if not 1 <= a.sizes[dim] <= 3:
+        raise ValueError(
+            f"The size of {dim!r} on a must be 1, 2, or 3 to be "
+            f"compatible with a cross product but is {a.sizes[dim]}"
+        )
+    elif not 1 <= b.sizes[dim] <= 3:
+        raise ValueError(
+            f"The size of {dim!r} on b must be 1, 2, or 3 to be "
+            f"compatible with a cross product but is {b.sizes[dim]}"
+        )
+
+    all_dims = list(dict.fromkeys(a.dims + b.dims))
+
+    if a.sizes[dim] != b.sizes[dim]:
+        # Arrays have different sizes. Append zeros where the smaller
+        # array is missing a value, zeros will not affect np.cross:
+
+        if (
+            not isinstance(a, Variable)  # Only used to make mypy happy.
+            and dim in getattr(a, "coords", {})
+            and not isinstance(b, Variable)  # Only used to make mypy happy.
+            and dim in getattr(b, "coords", {})
+        ):
+            # If the arrays have coords we know which indexes to fill
+            # with zeros:
+            a, b = align(
+                a,
+                b,
+                fill_value=0,
+                join="outer",
+                exclude=set(all_dims) - {dim},
+            )
+        elif min(a.sizes[dim], b.sizes[dim]) == 2:
+            # If the array doesn't have coords we can only infer
+            # that it has composite values if the size is at least 2.
+            # Once padded, rechunk the padded array because apply_ufunc
+            # requires core dimensions not to be chunked:
+            if a.sizes[dim] < b.sizes[dim]:
+                a = a.pad({dim: (0, 1)}, constant_values=0)
+                # TODO: Should pad or apply_ufunc handle correct chunking?
+                a = a.chunk({dim: -1}) if is_duck_dask_array(a.data) else a
+            else:
+                b = b.pad({dim: (0, 1)}, constant_values=0)
+                # TODO: Should pad or apply_ufunc handle correct chunking?
+                b = b.chunk({dim: -1}) if is_duck_dask_array(b.data) else b
+        else:
+            raise ValueError(
+                f"{dim!r} on {'a' if a.sizes[dim] == 1 else 'b'} is incompatible:"
+                " dimensions without coordinates must have have a length of 2 or 3"
+            )
+
+    c = apply_ufunc(
+        np.cross,
+        a,
+        b,
+        input_core_dims=[[dim], [dim]],
+        output_core_dims=[[dim] if a.sizes[dim] == 3 else []],
+        dask="parallelized",
+        output_dtypes=[np.result_type(a, b)],
+    )
+    c = c.transpose(*all_dims, missing_dims="ignore")
+
+    return c
+
+
 def dot(*arrays, dims=None, **kwargs):
     """Generalized dot product for xarray objects. Like np.einsum, but
     provides a simpler interface based on array dimensions.
diff --git a/xarray/tests/test_computation.py b/xarray/tests/test_computation.py
deleted file mode 100644
index 77d31101..00000000
--- a/xarray/tests/test_computation.py
+++ /dev/null
@@ -1,1954 +0,0 @@
-import functools
-import operator
-import pickle
-
-import numpy as np
-import pandas as pd
-import pytest
-from numpy.testing import assert_allclose, assert_array_equal
-from packaging.version import Version
-
-import xarray as xr
-from xarray.core.alignment import broadcast
-from xarray.core.computation import (
-    _UFuncSignature,
-    apply_ufunc,
-    broadcast_compat_data,
-    collect_dict_values,
-    join_dict_keys,
-    ordered_set_intersection,
-    ordered_set_union,
-    result_name,
-    unified_dim_sizes,
-)
-from xarray.core.pycompat import dask_version
-
-from . import has_dask, raise_if_dask_computes, requires_dask
-
-
-def assert_identical(a, b):
-    """A version of this function which accepts numpy arrays"""
-    __tracebackhide__ = True
-    from xarray.testing import assert_identical as assert_identical_
-
-    if hasattr(a, "identical"):
-        assert_identical_(a, b)
-    else:
-        assert_array_equal(a, b)
-
-
-def test_signature_properties() -> None:
-    sig = _UFuncSignature([["x"], ["x", "y"]], [["z"]])
-    assert sig.input_core_dims == (("x",), ("x", "y"))
-    assert sig.output_core_dims == (("z",),)
-    assert sig.all_input_core_dims == frozenset(["x", "y"])
-    assert sig.all_output_core_dims == frozenset(["z"])
-    assert sig.num_inputs == 2
-    assert sig.num_outputs == 1
-    assert str(sig) == "(x),(x,y)->(z)"
-    assert sig.to_gufunc_string() == "(dim0),(dim0,dim1)->(dim2)"
-    assert (
-        sig.to_gufunc_string(exclude_dims=set("x")) == "(dim0_0),(dim0_1,dim1)->(dim2)"
-    )
-    # dimension names matter
-    assert _UFuncSignature([["x"]]) != _UFuncSignature([["y"]])
-
-
-def test_result_name() -> None:
-    class Named:
-        def __init__(self, name=None):
-            self.name = name
-
-    assert result_name([1, 2]) is None
-    assert result_name([Named()]) is None
-    assert result_name([Named("foo"), 2]) == "foo"
-    assert result_name([Named("foo"), Named("bar")]) is None
-    assert result_name([Named("foo"), Named()]) is None
-
-
-def test_ordered_set_union() -> None:
-    assert list(ordered_set_union([[1, 2]])) == [1, 2]
-    assert list(ordered_set_union([[1, 2], [2, 1]])) == [1, 2]
-    assert list(ordered_set_union([[0], [1, 2], [1, 3]])) == [0, 1, 2, 3]
-
-
-def test_ordered_set_intersection() -> None:
-    assert list(ordered_set_intersection([[1, 2]])) == [1, 2]
-    assert list(ordered_set_intersection([[1, 2], [2, 1]])) == [1, 2]
-    assert list(ordered_set_intersection([[1, 2], [1, 3]])) == [1]
-    assert list(ordered_set_intersection([[1, 2], [2]])) == [2]
-
-
-def test_join_dict_keys() -> None:
-    dicts = [dict.fromkeys(keys) for keys in [["x", "y"], ["y", "z"]]]
-    assert list(join_dict_keys(dicts, "left")) == ["x", "y"]
-    assert list(join_dict_keys(dicts, "right")) == ["y", "z"]
-    assert list(join_dict_keys(dicts, "inner")) == ["y"]
-    assert list(join_dict_keys(dicts, "outer")) == ["x", "y", "z"]
-    with pytest.raises(ValueError):
-        join_dict_keys(dicts, "exact")
-    with pytest.raises(KeyError):
-        join_dict_keys(dicts, "foobar")
-
-
-def test_collect_dict_values() -> None:
-    dicts = [{"x": 1, "y": 2, "z": 3}, {"z": 4}, 5]
-    expected = [[1, 0, 5], [2, 0, 5], [3, 4, 5]]
-    collected = collect_dict_values(dicts, ["x", "y", "z"], fill_value=0)
-    assert collected == expected
-
-
-def identity(x):
-    return x
-
-
-def test_apply_identity() -> None:
-    array = np.arange(10)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    apply_identity = functools.partial(apply_ufunc, identity)
-
-    assert_identical(array, apply_identity(array))
-    assert_identical(variable, apply_identity(variable))
-    assert_identical(data_array, apply_identity(data_array))
-    assert_identical(data_array, apply_identity(data_array.groupby("x")))
-    assert_identical(dataset, apply_identity(dataset))
-    assert_identical(dataset, apply_identity(dataset.groupby("x")))
-
-
-def add(a, b):
-    return apply_ufunc(operator.add, a, b)
-
-
-def test_apply_two_inputs() -> None:
-    array = np.array([1, 2, 3])
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    zero_array = np.zeros_like(array)
-    zero_variable = xr.Variable("x", zero_array)
-    zero_data_array = xr.DataArray(zero_variable, [("x", -array)])
-    zero_dataset = xr.Dataset({"y": zero_variable}, {"x": -array})
-
-    assert_identical(array, add(array, zero_array))
-    assert_identical(array, add(zero_array, array))
-
-    assert_identical(variable, add(variable, zero_array))
-    assert_identical(variable, add(variable, zero_variable))
-    assert_identical(variable, add(zero_array, variable))
-    assert_identical(variable, add(zero_variable, variable))
-
-    assert_identical(data_array, add(data_array, zero_array))
-    assert_identical(data_array, add(data_array, zero_variable))
-    assert_identical(data_array, add(data_array, zero_data_array))
-    assert_identical(data_array, add(zero_array, data_array))
-    assert_identical(data_array, add(zero_variable, data_array))
-    assert_identical(data_array, add(zero_data_array, data_array))
-
-    assert_identical(dataset, add(dataset, zero_array))
-    assert_identical(dataset, add(dataset, zero_variable))
-    assert_identical(dataset, add(dataset, zero_data_array))
-    assert_identical(dataset, add(dataset, zero_dataset))
-    assert_identical(dataset, add(zero_array, dataset))
-    assert_identical(dataset, add(zero_variable, dataset))
-    assert_identical(dataset, add(zero_data_array, dataset))
-    assert_identical(dataset, add(zero_dataset, dataset))
-
-    assert_identical(data_array, add(data_array.groupby("x"), zero_data_array))
-    assert_identical(data_array, add(zero_data_array, data_array.groupby("x")))
-
-    assert_identical(dataset, add(data_array.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_dataset, data_array.groupby("x")))
-
-    assert_identical(dataset, add(dataset.groupby("x"), zero_data_array))
-    assert_identical(dataset, add(dataset.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_data_array, dataset.groupby("x")))
-    assert_identical(dataset, add(zero_dataset, dataset.groupby("x")))
-
-
-def test_apply_1d_and_0d() -> None:
-    array = np.array([1, 2, 3])
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    zero_array = 0
-    zero_variable = xr.Variable((), zero_array)
-    zero_data_array = xr.DataArray(zero_variable)
-    zero_dataset = xr.Dataset({"y": zero_variable})
-
-    assert_identical(array, add(array, zero_array))
-    assert_identical(array, add(zero_array, array))
-
-    assert_identical(variable, add(variable, zero_array))
-    assert_identical(variable, add(variable, zero_variable))
-    assert_identical(variable, add(zero_array, variable))
-    assert_identical(variable, add(zero_variable, variable))
-
-    assert_identical(data_array, add(data_array, zero_array))
-    assert_identical(data_array, add(data_array, zero_variable))
-    assert_identical(data_array, add(data_array, zero_data_array))
-    assert_identical(data_array, add(zero_array, data_array))
-    assert_identical(data_array, add(zero_variable, data_array))
-    assert_identical(data_array, add(zero_data_array, data_array))
-
-    assert_identical(dataset, add(dataset, zero_array))
-    assert_identical(dataset, add(dataset, zero_variable))
-    assert_identical(dataset, add(dataset, zero_data_array))
-    assert_identical(dataset, add(dataset, zero_dataset))
-    assert_identical(dataset, add(zero_array, dataset))
-    assert_identical(dataset, add(zero_variable, dataset))
-    assert_identical(dataset, add(zero_data_array, dataset))
-    assert_identical(dataset, add(zero_dataset, dataset))
-
-    assert_identical(data_array, add(data_array.groupby("x"), zero_data_array))
-    assert_identical(data_array, add(zero_data_array, data_array.groupby("x")))
-
-    assert_identical(dataset, add(data_array.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_dataset, data_array.groupby("x")))
-
-    assert_identical(dataset, add(dataset.groupby("x"), zero_data_array))
-    assert_identical(dataset, add(dataset.groupby("x"), zero_dataset))
-    assert_identical(dataset, add(zero_data_array, dataset.groupby("x")))
-    assert_identical(dataset, add(zero_dataset, dataset.groupby("x")))
-
-
-def test_apply_two_outputs() -> None:
-    array = np.arange(5)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    def twice(obj):
-        def func(x):
-            return (x, x)
-
-        return apply_ufunc(func, obj, output_core_dims=[[], []])
-
-    out0, out1 = twice(array)
-    assert_identical(out0, array)
-    assert_identical(out1, array)
-
-    out0, out1 = twice(variable)
-    assert_identical(out0, variable)
-    assert_identical(out1, variable)
-
-    out0, out1 = twice(data_array)
-    assert_identical(out0, data_array)
-    assert_identical(out1, data_array)
-
-    out0, out1 = twice(dataset)
-    assert_identical(out0, dataset)
-    assert_identical(out1, dataset)
-
-    out0, out1 = twice(data_array.groupby("x"))
-    assert_identical(out0, data_array)
-    assert_identical(out1, data_array)
-
-    out0, out1 = twice(dataset.groupby("x"))
-    assert_identical(out0, dataset)
-    assert_identical(out1, dataset)
-
-
-@requires_dask
-def test_apply_dask_parallelized_two_outputs() -> None:
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-
-    def twice(obj):
-        def func(x):
-            return (x, x)
-
-        return apply_ufunc(func, obj, output_core_dims=[[], []], dask="parallelized")
-
-    out0, out1 = twice(data_array.chunk({"x": 1}))
-    assert_identical(data_array, out0)
-    assert_identical(data_array, out1)
-
-
-def test_apply_input_core_dimension() -> None:
-    def first_element(obj, dim):
-        def func(x):
-            return x[..., 0]
-
-        return apply_ufunc(func, obj, input_core_dims=[[dim]])
-
-    array = np.array([[1, 2], [3, 4]])
-    variable = xr.Variable(["x", "y"], array)
-    data_array = xr.DataArray(variable, {"x": ["a", "b"], "y": [-1, -2]})
-    dataset = xr.Dataset({"data": data_array})
-
-    expected_variable_x = xr.Variable(["y"], [1, 2])
-    expected_data_array_x = xr.DataArray(expected_variable_x, {"y": [-1, -2]})
-    expected_dataset_x = xr.Dataset({"data": expected_data_array_x})
-
-    expected_variable_y = xr.Variable(["x"], [1, 3])
-    expected_data_array_y = xr.DataArray(expected_variable_y, {"x": ["a", "b"]})
-    expected_dataset_y = xr.Dataset({"data": expected_data_array_y})
-
-    assert_identical(expected_variable_x, first_element(variable, "x"))
-    assert_identical(expected_variable_y, first_element(variable, "y"))
-
-    assert_identical(expected_data_array_x, first_element(data_array, "x"))
-    assert_identical(expected_data_array_y, first_element(data_array, "y"))
-
-    assert_identical(expected_dataset_x, first_element(dataset, "x"))
-    assert_identical(expected_dataset_y, first_element(dataset, "y"))
-
-    assert_identical(expected_data_array_x, first_element(data_array.groupby("y"), "x"))
-    assert_identical(expected_dataset_x, first_element(dataset.groupby("y"), "x"))
-
-    def multiply(*args):
-        val = args[0]
-        for arg in args[1:]:
-            val = val * arg
-        return val
-
-    # regression test for GH:2341
-    with pytest.raises(ValueError):
-        apply_ufunc(
-            multiply,
-            data_array,
-            data_array["y"].values,
-            input_core_dims=[["y"]],
-            output_core_dims=[["y"]],
-        )
-    expected = xr.DataArray(
-        multiply(data_array, data_array["y"]), dims=["x", "y"], coords=data_array.coords
-    )
-    actual = apply_ufunc(
-        multiply,
-        data_array,
-        data_array["y"].values,
-        input_core_dims=[["y"], []],
-        output_core_dims=[["y"]],
-    )
-    assert_identical(expected, actual)
-
-
-def test_apply_output_core_dimension() -> None:
-    def stack_negative(obj):
-        def func(x):
-            return np.stack([x, -x], axis=-1)
-
-        result = apply_ufunc(func, obj, output_core_dims=[["sign"]])
-        if isinstance(result, (xr.Dataset, xr.DataArray)):
-            result.coords["sign"] = [1, -1]
-        return result
-
-    array = np.array([[1, 2], [3, 4]])
-    variable = xr.Variable(["x", "y"], array)
-    data_array = xr.DataArray(variable, {"x": ["a", "b"], "y": [-1, -2]})
-    dataset = xr.Dataset({"data": data_array})
-
-    stacked_array = np.array([[[1, -1], [2, -2]], [[3, -3], [4, -4]]])
-    stacked_variable = xr.Variable(["x", "y", "sign"], stacked_array)
-    stacked_coords = {"x": ["a", "b"], "y": [-1, -2], "sign": [1, -1]}
-    stacked_data_array = xr.DataArray(stacked_variable, stacked_coords)
-    stacked_dataset = xr.Dataset({"data": stacked_data_array})
-
-    assert_identical(stacked_array, stack_negative(array))
-    assert_identical(stacked_variable, stack_negative(variable))
-    assert_identical(stacked_data_array, stack_negative(data_array))
-    assert_identical(stacked_dataset, stack_negative(dataset))
-    assert_identical(stacked_data_array, stack_negative(data_array.groupby("x")))
-    assert_identical(stacked_dataset, stack_negative(dataset.groupby("x")))
-
-    def original_and_stack_negative(obj):
-        def func(x):
-            return (x, np.stack([x, -x], axis=-1))
-
-        result = apply_ufunc(func, obj, output_core_dims=[[], ["sign"]])
-        if isinstance(result[1], (xr.Dataset, xr.DataArray)):
-            result[1].coords["sign"] = [1, -1]
-        return result
-
-    out0, out1 = original_and_stack_negative(array)
-    assert_identical(array, out0)
-    assert_identical(stacked_array, out1)
-
-    out0, out1 = original_and_stack_negative(variable)
-    assert_identical(variable, out0)
-    assert_identical(stacked_variable, out1)
-
-    out0, out1 = original_and_stack_negative(data_array)
-    assert_identical(data_array, out0)
-    assert_identical(stacked_data_array, out1)
-
-    out0, out1 = original_and_stack_negative(dataset)
-    assert_identical(dataset, out0)
-    assert_identical(stacked_dataset, out1)
-
-    out0, out1 = original_and_stack_negative(data_array.groupby("x"))
-    assert_identical(data_array, out0)
-    assert_identical(stacked_data_array, out1)
-
-    out0, out1 = original_and_stack_negative(dataset.groupby("x"))
-    assert_identical(dataset, out0)
-    assert_identical(stacked_dataset, out1)
-
-
-def test_apply_exclude() -> None:
-    def concatenate(objects, dim="x"):
-        def func(*x):
-            return np.concatenate(x, axis=-1)
-
-        result = apply_ufunc(
-            func,
-            *objects,
-            input_core_dims=[[dim]] * len(objects),
-            output_core_dims=[[dim]],
-            exclude_dims={dim},
-        )
-        if isinstance(result, (xr.Dataset, xr.DataArray)):
-            # note: this will fail if dim is not a coordinate on any input
-            new_coord = np.concatenate([obj.coords[dim] for obj in objects])
-            result.coords[dim] = new_coord
-        return result
-
-    arrays = [np.array([1]), np.array([2, 3])]
-    variables = [xr.Variable("x", a) for a in arrays]
-    data_arrays = [
-        xr.DataArray(v, {"x": c, "y": ("x", range(len(c)))})
-        for v, c in zip(variables, [["a"], ["b", "c"]])
-    ]
-    datasets = [xr.Dataset({"data": data_array}) for data_array in data_arrays]
-
-    expected_array = np.array([1, 2, 3])
-    expected_variable = xr.Variable("x", expected_array)
-    expected_data_array = xr.DataArray(expected_variable, [("x", list("abc"))])
-    expected_dataset = xr.Dataset({"data": expected_data_array})
-
-    assert_identical(expected_array, concatenate(arrays))
-    assert_identical(expected_variable, concatenate(variables))
-    assert_identical(expected_data_array, concatenate(data_arrays))
-    assert_identical(expected_dataset, concatenate(datasets))
-
-    # must also be a core dimension
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, variables[0], exclude_dims={"x"})
-
-
-def test_apply_groupby_add() -> None:
-    array = np.arange(5)
-    variable = xr.Variable("x", array)
-    coords = {"x": -array, "y": ("x", [0, 0, 1, 1, 2])}
-    data_array = xr.DataArray(variable, coords, dims="x")
-    dataset = xr.Dataset({"z": variable}, coords)
-
-    other_variable = xr.Variable("y", [0, 10])
-    other_data_array = xr.DataArray(other_variable, dims="y")
-    other_dataset = xr.Dataset({"z": other_variable})
-
-    expected_variable = xr.Variable("x", [0, 1, 12, 13, np.nan])
-    expected_data_array = xr.DataArray(expected_variable, coords, dims="x")
-    expected_dataset = xr.Dataset({"z": expected_variable}, coords)
-
-    assert_identical(
-        expected_data_array, add(data_array.groupby("y"), other_data_array)
-    )
-    assert_identical(expected_dataset, add(data_array.groupby("y"), other_dataset))
-    assert_identical(expected_dataset, add(dataset.groupby("y"), other_data_array))
-    assert_identical(expected_dataset, add(dataset.groupby("y"), other_dataset))
-
-    # cannot be performed with xarray.Variable objects that share a dimension
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), other_variable)
-
-    # if they are all grouped the same way
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array[:4].groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array[1:].groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), other_data_array.groupby("y"))
-    with pytest.raises(ValueError):
-        add(data_array.groupby("y"), data_array.groupby("x"))
-
-
-def test_unified_dim_sizes() -> None:
-    assert unified_dim_sizes([xr.Variable((), 0)]) == {}
-    assert unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("x", [1])]) == {"x": 1}
-    assert unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("y", [1, 2])]) == {
-        "x": 1,
-        "y": 2,
-    }
-    assert (
-        unified_dim_sizes(
-            [xr.Variable(("x", "z"), [[1]]), xr.Variable(("y", "z"), [[1, 2], [3, 4]])],
-            exclude_dims={"z"},
-        )
-        == {"x": 1, "y": 2}
-    )
-
-    # duplicate dimensions
-    with pytest.raises(ValueError):
-        unified_dim_sizes([xr.Variable(("x", "x"), [[1]])])
-
-    # mismatched lengths
-    with pytest.raises(ValueError):
-        unified_dim_sizes([xr.Variable("x", [1]), xr.Variable("x", [1, 2])])
-
-
-def test_broadcast_compat_data_1d() -> None:
-    data = np.arange(5)
-    var = xr.Variable("x", data)
-
-    assert_identical(data, broadcast_compat_data(var, ("x",), ()))
-    assert_identical(data, broadcast_compat_data(var, (), ("x",)))
-    assert_identical(data[:], broadcast_compat_data(var, ("w",), ("x",)))
-    assert_identical(data[:, None], broadcast_compat_data(var, ("w", "x", "y"), ()))
-
-    with pytest.raises(ValueError):
-        broadcast_compat_data(var, ("x",), ("w",))
-
-    with pytest.raises(ValueError):
-        broadcast_compat_data(var, (), ())
-
-
-def test_broadcast_compat_data_2d() -> None:
-    data = np.arange(12).reshape(3, 4)
-    var = xr.Variable(["x", "y"], data)
-
-    assert_identical(data, broadcast_compat_data(var, ("x", "y"), ()))
-    assert_identical(data, broadcast_compat_data(var, ("x",), ("y",)))
-    assert_identical(data, broadcast_compat_data(var, (), ("x", "y")))
-    assert_identical(data.T, broadcast_compat_data(var, ("y", "x"), ()))
-    assert_identical(data.T, broadcast_compat_data(var, ("y",), ("x",)))
-    assert_identical(data, broadcast_compat_data(var, ("w", "x"), ("y",)))
-    assert_identical(data, broadcast_compat_data(var, ("w",), ("x", "y")))
-    assert_identical(data.T, broadcast_compat_data(var, ("w",), ("y", "x")))
-    assert_identical(
-        data[:, :, None], broadcast_compat_data(var, ("w", "x", "y", "z"), ())
-    )
-    assert_identical(
-        data[None, :, :].T, broadcast_compat_data(var, ("w", "y", "x", "z"), ())
-    )
-
-
-def test_keep_attrs() -> None:
-    def add(a, b, keep_attrs):
-        if keep_attrs:
-            return apply_ufunc(operator.add, a, b, keep_attrs=keep_attrs)
-        else:
-            return apply_ufunc(operator.add, a, b)
-
-    a = xr.DataArray([0, 1], [("x", [0, 1])])
-    a.attrs["attr"] = "da"
-    a["x"].attrs["attr"] = "da_coord"
-    b = xr.DataArray([1, 2], [("x", [0, 1])])
-
-    actual = add(a, b, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(a, b, keep_attrs=True)
-    assert_identical(actual.attrs, a.attrs)
-    assert_identical(actual["x"].attrs, a["x"].attrs)
-
-    actual = add(a.variable, b.variable, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(a.variable, b.variable, keep_attrs=True)
-    assert_identical(actual.attrs, a.attrs)
-
-    ds_a = xr.Dataset({"x": [0, 1]})
-    ds_a.attrs["attr"] = "ds"
-    ds_a.x.attrs["attr"] = "da"
-    ds_b = xr.Dataset({"x": [0, 1]})
-
-    actual = add(ds_a, ds_b, keep_attrs=False)
-    assert not actual.attrs
-    actual = add(ds_a, ds_b, keep_attrs=True)
-    assert_identical(actual.attrs, ds_a.attrs)
-    assert_identical(actual.x.attrs, ds_a.x.attrs)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_variable(strategy, attrs, expected, error) -> None:
-    a = xr.Variable("x", [0, 1], attrs=attrs[0])
-    b = xr.Variable("x", [0, 1], attrs=attrs[1])
-    c = xr.Variable("x", [0, 1], attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.Variable("x", [0, 3], attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataarray(strategy, attrs, expected, error) -> None:
-    a = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[0])
-    b = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[1])
-    c = xr.DataArray(dims="x", data=[0, 1], attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.DataArray(dims="x", data=[0, 3], attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize("variant", ("dim", "coord"))
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataarray_variables(
-    variant, strategy, attrs, expected, error
-):
-    compute_attrs = {
-        "dim": lambda attrs, default: (attrs, default),
-        "coord": lambda attrs, default: (default, attrs),
-    }.get(variant)
-
-    dim_attrs, coord_attrs = compute_attrs(attrs, [{}, {}, {}])
-
-    a = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[0]), "u": ("x", [0, 1], coord_attrs[0])},
-    )
-    b = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[1]), "u": ("x", [0, 1], coord_attrs[1])},
-    )
-    c = xr.DataArray(
-        dims="x",
-        data=[0, 1],
-        coords={"x": ("x", [0, 1], dim_attrs[2]), "u": ("x", [0, 1], coord_attrs[2])},
-    )
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        dim_attrs, coord_attrs = compute_attrs(expected, {})
-        expected = xr.DataArray(
-            dims="x",
-            data=[0, 3],
-            coords={"x": ("x", [0, 1], dim_attrs), "u": ("x", [0, 1], coord_attrs)},
-        )
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataset(strategy, attrs, expected, error) -> None:
-    a = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[0])
-    b = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[1])
-    c = xr.Dataset({"a": ("x", [0, 1])}, attrs=attrs[2])
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        expected = xr.Dataset({"a": ("x", [0, 3])}, attrs=expected)
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-@pytest.mark.parametrize("variant", ("data", "dim", "coord"))
-@pytest.mark.parametrize(
-    ["strategy", "attrs", "expected", "error"],
-    (
-        pytest.param(
-            None,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="default",
-        ),
-        pytest.param(
-            False,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="False",
-        ),
-        pytest.param(
-            True,
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="True",
-        ),
-        pytest.param(
-            "override",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {"a": 1},
-            False,
-            id="override",
-        ),
-        pytest.param(
-            "drop",
-            [{"a": 1}, {"a": 2}, {"a": 3}],
-            {},
-            False,
-            id="drop",
-        ),
-        pytest.param(
-            "drop_conflicts",
-            [{"a": 1, "b": 2}, {"b": 1, "c": 3}, {"c": 3, "d": 4}],
-            {"a": 1, "c": 3, "d": 4},
-            False,
-            id="drop_conflicts",
-        ),
-        pytest.param(
-            "no_conflicts",
-            [{"a": 1}, {"b": 2}, {"b": 3}],
-            None,
-            True,
-            id="no_conflicts",
-        ),
-    ),
-)
-def test_keep_attrs_strategies_dataset_variables(
-    variant, strategy, attrs, expected, error
-):
-    compute_attrs = {
-        "data": lambda attrs, default: (attrs, default, default),
-        "dim": lambda attrs, default: (default, attrs, default),
-        "coord": lambda attrs, default: (default, default, attrs),
-    }.get(variant)
-    data_attrs, dim_attrs, coord_attrs = compute_attrs(attrs, [{}, {}, {}])
-
-    a = xr.Dataset(
-        {"a": ("x", [], data_attrs[0])},
-        coords={"x": ("x", [], dim_attrs[0]), "u": ("x", [], coord_attrs[0])},
-    )
-    b = xr.Dataset(
-        {"a": ("x", [], data_attrs[1])},
-        coords={"x": ("x", [], dim_attrs[1]), "u": ("x", [], coord_attrs[1])},
-    )
-    c = xr.Dataset(
-        {"a": ("x", [], data_attrs[2])},
-        coords={"x": ("x", [], dim_attrs[2]), "u": ("x", [], coord_attrs[2])},
-    )
-
-    if error:
-        with pytest.raises(xr.MergeError):
-            apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-    else:
-        data_attrs, dim_attrs, coord_attrs = compute_attrs(expected, {})
-        expected = xr.Dataset(
-            {"a": ("x", [], data_attrs)},
-            coords={"x": ("x", [], dim_attrs), "u": ("x", [], coord_attrs)},
-        )
-        actual = apply_ufunc(lambda *args: sum(args), a, b, c, keep_attrs=strategy)
-
-        assert_identical(actual, expected)
-
-
-def test_dataset_join() -> None:
-    ds0 = xr.Dataset({"a": ("x", [1, 2]), "x": [0, 1]})
-    ds1 = xr.Dataset({"a": ("x", [99, 3]), "x": [1, 2]})
-
-    # by default, cannot have different labels
-    with pytest.raises(ValueError, match=r"indexes .* are not equal"):
-        apply_ufunc(operator.add, ds0, ds1)
-    with pytest.raises(TypeError, match=r"must supply"):
-        apply_ufunc(operator.add, ds0, ds1, dataset_join="outer")
-
-    def add(a, b, join, dataset_join):
-        return apply_ufunc(
-            operator.add,
-            a,
-            b,
-            join=join,
-            dataset_join=dataset_join,
-            dataset_fill_value=np.nan,
-        )
-
-    actual = add(ds0, ds1, "outer", "inner")
-    expected = xr.Dataset({"a": ("x", [np.nan, 101, np.nan]), "x": [0, 1, 2]})
-    assert_identical(actual, expected)
-
-    actual = add(ds0, ds1, "outer", "outer")
-    assert_identical(actual, expected)
-
-    with pytest.raises(ValueError, match=r"data variable names"):
-        apply_ufunc(operator.add, ds0, xr.Dataset({"b": 1}))
-
-    ds2 = xr.Dataset({"b": ("x", [99, 3]), "x": [1, 2]})
-    actual = add(ds0, ds2, "outer", "inner")
-    expected = xr.Dataset({"x": [0, 1, 2]})
-    assert_identical(actual, expected)
-
-    # we used np.nan as the fill_value in add() above
-    actual = add(ds0, ds2, "outer", "outer")
-    expected = xr.Dataset(
-        {
-            "a": ("x", [np.nan, np.nan, np.nan]),
-            "b": ("x", [np.nan, np.nan, np.nan]),
-            "x": [0, 1, 2],
-        }
-    )
-    assert_identical(actual, expected)
-
-
-@requires_dask
-def test_apply_dask() -> None:
-    import dask.array as da
-
-    array = da.ones((2,), chunks=2)
-    variable = xr.Variable("x", array)
-    coords = xr.DataArray(variable).coords.variables
-    data_array = xr.DataArray(variable, dims=["x"], coords=coords)
-    dataset = xr.Dataset({"y": variable})
-
-    # encountered dask array, but did not set dask='allowed'
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, array)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, variable)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, data_array)
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, dataset)
-
-    # unknown setting for dask array handling
-    with pytest.raises(ValueError):
-        apply_ufunc(identity, array, dask="unknown")
-
-    def dask_safe_identity(x):
-        return apply_ufunc(identity, x, dask="allowed")
-
-    assert array is dask_safe_identity(array)
-
-    actual = dask_safe_identity(variable)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(variable, actual)
-
-    actual = dask_safe_identity(data_array)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(data_array, actual)
-
-    actual = dask_safe_identity(dataset)
-    assert isinstance(actual["y"].data, da.Array)
-    assert_identical(dataset, actual)
-
-
-@requires_dask
-def test_apply_dask_parallelized_one_arg() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    def parallel_identity(x):
-        return apply_ufunc(identity, x, dask="parallelized", output_dtypes=[x.dtype])
-
-    actual = parallel_identity(data_array)
-    assert isinstance(actual.data, da.Array)
-    assert actual.data.chunks == array.chunks
-    assert_identical(data_array, actual)
-
-    computed = data_array.compute()
-    actual = parallel_identity(computed)
-    assert_identical(computed, actual)
-
-
-@requires_dask
-def test_apply_dask_parallelized_two_args() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1), dtype=np.int64)
-    data_array = xr.DataArray(array, dims=("x", "y"))
-    data_array.name = None
-
-    def parallel_add(x, y):
-        return apply_ufunc(
-            operator.add, x, y, dask="parallelized", output_dtypes=[np.int64]
-        )
-
-    def check(x, y):
-        actual = parallel_add(x, y)
-        assert isinstance(actual.data, da.Array)
-        assert actual.data.chunks == array.chunks
-        assert_identical(data_array, actual)
-
-    check(data_array, 0),
-    check(0, data_array)
-    check(data_array, xr.DataArray(0))
-    check(data_array, 0 * data_array)
-    check(data_array, 0 * data_array[0])
-    check(data_array[:, 0], 0 * data_array[0])
-    check(data_array, 0 * data_array.compute())
-
-
-@requires_dask
-def test_apply_dask_parallelized_errors() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    # from apply_array_ufunc
-    with pytest.raises(ValueError, match=r"at least one input is an xarray object"):
-        apply_ufunc(identity, array, dask="parallelized")
-
-    # formerly from _apply_blockwise, now from apply_variable_ufunc
-    with pytest.raises(ValueError, match=r"consists of multiple chunks"):
-        apply_ufunc(
-            identity,
-            data_array,
-            dask="parallelized",
-            output_dtypes=[float],
-            input_core_dims=[("y",)],
-            output_core_dims=[("y",)],
-        )
-
-
-# it's currently impossible to silence these warnings from inside dask.array:
-# https://github.com/dask/dask/issues/3245
-@requires_dask
-@pytest.mark.filterwarnings("ignore:Mean of empty slice")
-def test_apply_dask_multiple_inputs() -> None:
-    import dask.array as da
-
-    def covariance(x, y):
-        return (
-            (x - x.mean(axis=-1, keepdims=True)) * (y - y.mean(axis=-1, keepdims=True))
-        ).mean(axis=-1)
-
-    rs = np.random.RandomState(42)
-    array1 = da.from_array(rs.randn(4, 4), chunks=(2, 4))
-    array2 = da.from_array(rs.randn(4, 4), chunks=(2, 4))
-    data_array_1 = xr.DataArray(array1, dims=("x", "z"))
-    data_array_2 = xr.DataArray(array2, dims=("y", "z"))
-
-    expected = apply_ufunc(
-        covariance,
-        data_array_1.compute(),
-        data_array_2.compute(),
-        input_core_dims=[["z"], ["z"]],
-    )
-    allowed = apply_ufunc(
-        covariance,
-        data_array_1,
-        data_array_2,
-        input_core_dims=[["z"], ["z"]],
-        dask="allowed",
-    )
-    assert isinstance(allowed.data, da.Array)
-    xr.testing.assert_allclose(expected, allowed.compute())
-
-    parallelized = apply_ufunc(
-        covariance,
-        data_array_1,
-        data_array_2,
-        input_core_dims=[["z"], ["z"]],
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert isinstance(parallelized.data, da.Array)
-    xr.testing.assert_allclose(expected, parallelized.compute())
-
-
-@requires_dask
-def test_apply_dask_new_output_dimension() -> None:
-    import dask.array as da
-
-    array = da.ones((2, 2), chunks=(1, 1))
-    data_array = xr.DataArray(array, dims=("x", "y"))
-
-    def stack_negative(obj):
-        def func(x):
-            return np.stack([x, -x], axis=-1)
-
-        return apply_ufunc(
-            func,
-            obj,
-            output_core_dims=[["sign"]],
-            dask="parallelized",
-            output_dtypes=[obj.dtype],
-            dask_gufunc_kwargs=dict(output_sizes={"sign": 2}),
-        )
-
-    expected = stack_negative(data_array.compute())
-
-    actual = stack_negative(data_array)
-    assert actual.dims == ("x", "y", "sign")
-    assert actual.shape == (2, 2, 2)
-    assert isinstance(actual.data, da.Array)
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_apply_dask_new_output_sizes() -> None:
-    ds = xr.Dataset({"foo": (["lon", "lat"], np.arange(10 * 10).reshape((10, 10)))})
-    ds["bar"] = ds["foo"]
-    newdims = {"lon_new": 3, "lat_new": 6}
-
-    def extract(obj):
-        def func(da):
-            return da[1:4, 1:7]
-
-        return apply_ufunc(
-            func,
-            obj,
-            dask="parallelized",
-            input_core_dims=[["lon", "lat"]],
-            output_core_dims=[["lon_new", "lat_new"]],
-            dask_gufunc_kwargs=dict(output_sizes=newdims),
-        )
-
-    expected = extract(ds)
-
-    actual = extract(ds.chunk())
-    assert actual.dims == {"lon_new": 3, "lat_new": 6}
-    assert_identical(expected.chunk(), actual)
-
-
-def pandas_median(x):
-    return pd.Series(x).median()
-
-
-def test_vectorize() -> None:
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median, data_array, input_core_dims=[["y"]], vectorize=True
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_dask() -> None:
-    # run vectorization in dask.array.gufunc by using `dask='parallelized'`
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_dask_dtype() -> None:
-    # ensure output_dtypes is preserved with vectorize=True
-    # GH4015
-
-    # integer
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[int],
-    )
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-    # complex
-    data_array = xr.DataArray([[0 + 0j, 1 + 2j, 2 + 1j]], dims=("x", "y"))
-    expected = data_array.copy()
-    actual = apply_ufunc(
-        identity,
-        data_array.chunk({"x": 1}),
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[complex],
-    )
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-
-@requires_dask
-@pytest.mark.parametrize(
-    "data_array",
-    [
-        xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y")),
-        xr.DataArray([[0 + 0j, 1 + 2j, 2 + 1j]], dims=("x", "y")),
-    ],
-)
-def test_vectorize_dask_dtype_without_output_dtypes(data_array) -> None:
-    # ensure output_dtypes is preserved with vectorize=True
-    # GH4015
-
-    expected = data_array.copy()
-    actual = apply_ufunc(
-        identity,
-        data_array.chunk({"x": 1}),
-        vectorize=True,
-        dask="parallelized",
-    )
-
-    assert_identical(expected, actual)
-    assert expected.dtype == actual.dtype
-
-
-@pytest.mark.skipif(
-    dask_version > Version("2021.06"),
-    reason="dask/dask#7669: can no longer pass output_dtypes and meta",
-)
-@requires_dask
-def test_vectorize_dask_dtype_meta() -> None:
-    # meta dtype takes precedence
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    expected = xr.DataArray([1, 2], dims=["x"])
-
-    actual = apply_ufunc(
-        pandas_median,
-        data_array.chunk({"x": 1}),
-        input_core_dims=[["y"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[int],
-        dask_gufunc_kwargs=dict(meta=np.ndarray((0, 0), dtype=float)),
-    )
-
-    assert_identical(expected, actual)
-    assert float == actual.dtype
-
-
-def pandas_median_add(x, y):
-    # function which can consume input of unequal length
-    return pd.Series(x).median() + pd.Series(y).median()
-
-
-def test_vectorize_exclude_dims() -> None:
-    # GH 3890
-    data_array_a = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    data_array_b = xr.DataArray([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dims=("x", "y"))
-
-    expected = xr.DataArray([3, 5], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median_add,
-        data_array_a,
-        data_array_b,
-        input_core_dims=[["y"], ["y"]],
-        vectorize=True,
-        exclude_dims=set("y"),
-    )
-    assert_identical(expected, actual)
-
-
-@requires_dask
-def test_vectorize_exclude_dims_dask() -> None:
-    # GH 3890
-    data_array_a = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    data_array_b = xr.DataArray([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dims=("x", "y"))
-
-    expected = xr.DataArray([3, 5], dims=["x"])
-    actual = apply_ufunc(
-        pandas_median_add,
-        data_array_a.chunk({"x": 1}),
-        data_array_b.chunk({"x": 1}),
-        input_core_dims=[["y"], ["y"]],
-        exclude_dims=set("y"),
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-    )
-    assert_identical(expected, actual)
-
-
-def test_corr_only_dataarray() -> None:
-    with pytest.raises(TypeError, match="Only xr.DataArray is supported"):
-        xr.corr(xr.Dataset(), xr.Dataset())
-
-
-def arrays_w_tuples():
-    da = xr.DataArray(
-        np.random.random((3, 21, 4)),
-        coords={"time": pd.date_range("2000-01-01", freq="1D", periods=21)},
-        dims=("a", "time", "x"),
-    )
-
-    arrays = [
-        da.isel(time=range(0, 18)),
-        da.isel(time=range(2, 20)).rolling(time=3, center=True).mean(),
-        xr.DataArray([[1, 2], [1, np.nan]], dims=["x", "time"]),
-        xr.DataArray([[1, 2], [np.nan, np.nan]], dims=["x", "time"]),
-        xr.DataArray([[1, 2], [2, 1]], dims=["x", "time"]),
-    ]
-
-    array_tuples = [
-        (arrays[0], arrays[0]),
-        (arrays[0], arrays[1]),
-        (arrays[1], arrays[1]),
-        (arrays[2], arrays[2]),
-        (arrays[2], arrays[3]),
-        (arrays[2], arrays[4]),
-        (arrays[4], arrays[2]),
-        (arrays[3], arrays[3]),
-        (arrays[4], arrays[4]),
-    ]
-
-    return arrays, array_tuples
-
-
-@pytest.mark.parametrize("ddof", [0, 1])
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [
-        arrays_w_tuples()[1][3],
-        arrays_w_tuples()[1][4],
-        arrays_w_tuples()[1][5],
-        arrays_w_tuples()[1][6],
-        arrays_w_tuples()[1][7],
-        arrays_w_tuples()[1][8],
-    ],
-)
-@pytest.mark.parametrize("dim", [None, "x", "time"])
-@requires_dask
-def test_lazy_corrcov(da_a, da_b, dim, ddof) -> None:
-    # GH 5284
-    from dask import is_dask_collection
-
-    with raise_if_dask_computes():
-        cov = xr.cov(da_a.chunk(), da_b.chunk(), dim=dim, ddof=ddof)
-        assert is_dask_collection(cov)
-
-        corr = xr.corr(da_a.chunk(), da_b.chunk(), dim=dim)
-        assert is_dask_collection(corr)
-
-
-@pytest.mark.parametrize("ddof", [0, 1])
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [arrays_w_tuples()[1][0], arrays_w_tuples()[1][1], arrays_w_tuples()[1][2]],
-)
-@pytest.mark.parametrize("dim", [None, "time"])
-def test_cov(da_a, da_b, dim, ddof) -> None:
-    if dim is not None:
-
-        def np_cov_ind(ts1, ts2, a, x):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            # While dropping isn't ideal here, numpy will return nan
-            # if any segment contains a NaN.
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.cov(
-                np.ma.masked_invalid(ts1.sel(a=a, x=x).data.flatten()),
-                np.ma.masked_invalid(ts2.sel(a=a, x=x).data.flatten()),
-                ddof=ddof,
-            )[0, 1]
-
-        expected = np.zeros((3, 4))
-        for a in [0, 1, 2]:
-            for x in [0, 1, 2, 3]:
-                expected[a, x] = np_cov_ind(da_a, da_b, a=a, x=x)
-        actual = xr.cov(da_a, da_b, dim=dim, ddof=ddof)
-        assert_allclose(actual, expected)
-
-    else:
-
-        def np_cov(ts1, ts2):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.cov(
-                np.ma.masked_invalid(ts1.data.flatten()),
-                np.ma.masked_invalid(ts2.data.flatten()),
-                ddof=ddof,
-            )[0, 1]
-
-        expected = np_cov(da_a, da_b)
-        actual = xr.cov(da_a, da_b, dim=dim, ddof=ddof)
-        assert_allclose(actual, expected)
-
-
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    [arrays_w_tuples()[1][0], arrays_w_tuples()[1][1], arrays_w_tuples()[1][2]],
-)
-@pytest.mark.parametrize("dim", [None, "time"])
-def test_corr(da_a, da_b, dim) -> None:
-    if dim is not None:
-
-        def np_corr_ind(ts1, ts2, a, x):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.corrcoef(
-                np.ma.masked_invalid(ts1.sel(a=a, x=x).data.flatten()),
-                np.ma.masked_invalid(ts2.sel(a=a, x=x).data.flatten()),
-            )[0, 1]
-
-        expected = np.zeros((3, 4))
-        for a in [0, 1, 2]:
-            for x in [0, 1, 2, 3]:
-                expected[a, x] = np_corr_ind(da_a, da_b, a=a, x=x)
-        actual = xr.corr(da_a, da_b, dim)
-        assert_allclose(actual, expected)
-
-    else:
-
-        def np_corr(ts1, ts2):
-            # Ensure the ts are aligned and missing values ignored
-            ts1, ts2 = broadcast(ts1, ts2)
-            valid_values = ts1.notnull() & ts2.notnull()
-
-            ts1 = ts1.where(valid_values)
-            ts2 = ts2.where(valid_values)
-
-            return np.ma.corrcoef(
-                np.ma.masked_invalid(ts1.data.flatten()),
-                np.ma.masked_invalid(ts2.data.flatten()),
-            )[0, 1]
-
-        expected = np_corr(da_a, da_b)
-        actual = xr.corr(da_a, da_b, dim)
-        assert_allclose(actual, expected)
-
-
-@pytest.mark.parametrize(
-    "da_a, da_b",
-    arrays_w_tuples()[1],
-)
-@pytest.mark.parametrize("dim", [None, "time", "x"])
-def test_covcorr_consistency(da_a, da_b, dim) -> None:
-    # Testing that xr.corr and xr.cov are consistent with each other
-    # 1. Broadcast the two arrays
-    da_a, da_b = broadcast(da_a, da_b)
-    # 2. Ignore the nans
-    valid_values = da_a.notnull() & da_b.notnull()
-    da_a = da_a.where(valid_values)
-    da_b = da_b.where(valid_values)
-
-    expected = xr.cov(da_a, da_b, dim=dim, ddof=0) / (
-        da_a.std(dim=dim) * da_b.std(dim=dim)
-    )
-    actual = xr.corr(da_a, da_b, dim=dim)
-    assert_allclose(actual, expected)
-
-
-@requires_dask
-@pytest.mark.parametrize("da_a, da_b", arrays_w_tuples()[1])
-@pytest.mark.parametrize("dim", [None, "time", "x"])
-def test_corr_lazycorr_consistency(da_a, da_b, dim) -> None:
-    da_al = da_a.chunk()
-    da_bl = da_b.chunk()
-    c_abl = xr.corr(da_al, da_bl, dim=dim)
-    c_ab = xr.corr(da_a, da_b, dim=dim)
-    c_ab_mixed = xr.corr(da_a, da_bl, dim=dim)
-    assert_allclose(c_ab, c_abl)
-    assert_allclose(c_ab, c_ab_mixed)
-
-
-@requires_dask
-def test_corr_dtype_error():
-    da_a = xr.DataArray([[1, 2], [2, 1]], dims=["x", "time"])
-    da_b = xr.DataArray([[1, 2], [1, np.nan]], dims=["x", "time"])
-
-    xr.testing.assert_equal(xr.corr(da_a, da_b), xr.corr(da_a.chunk(), da_b.chunk()))
-    xr.testing.assert_equal(xr.corr(da_a, da_b), xr.corr(da_a, da_b.chunk()))
-
-
-@pytest.mark.parametrize(
-    "da_a",
-    arrays_w_tuples()[0],
-)
-@pytest.mark.parametrize("dim", [None, "time", "x", ["time", "x"]])
-def test_autocov(da_a, dim) -> None:
-    # Testing that the autocovariance*(N-1) is ~=~ to the variance matrix
-    # 1. Ignore the nans
-    valid_values = da_a.notnull()
-    # Because we're using ddof=1, this requires > 1 value in each sample
-    da_a = da_a.where(valid_values.sum(dim=dim) > 1)
-    expected = ((da_a - da_a.mean(dim=dim)) ** 2).sum(dim=dim, skipna=True, min_count=1)
-    actual = xr.cov(da_a, da_a, dim=dim) * (valid_values.sum(dim) - 1)
-    assert_allclose(actual, expected)
-
-
-@requires_dask
-def test_vectorize_dask_new_output_dims() -> None:
-    # regression test for GH3574
-    # run vectorization in dask.array.gufunc by using `dask='parallelized'`
-    data_array = xr.DataArray([[0, 1, 2], [1, 2, 3]], dims=("x", "y"))
-    func = lambda x: x[np.newaxis, ...]
-    expected = data_array.expand_dims("z")
-    actual = apply_ufunc(
-        func,
-        data_array.chunk({"x": 1}),
-        output_core_dims=[["z"]],
-        vectorize=True,
-        dask="parallelized",
-        output_dtypes=[float],
-        dask_gufunc_kwargs=dict(output_sizes={"z": 1}),
-    ).transpose(*expected.dims)
-    assert_identical(expected, actual)
-
-    with pytest.raises(
-        ValueError, match=r"dimension 'z1' in 'output_sizes' must correspond"
-    ):
-        apply_ufunc(
-            func,
-            data_array.chunk({"x": 1}),
-            output_core_dims=[["z"]],
-            vectorize=True,
-            dask="parallelized",
-            output_dtypes=[float],
-            dask_gufunc_kwargs=dict(output_sizes={"z1": 1}),
-        )
-
-    with pytest.raises(
-        ValueError, match=r"dimension 'z' in 'output_core_dims' needs corresponding"
-    ):
-        apply_ufunc(
-            func,
-            data_array.chunk({"x": 1}),
-            output_core_dims=[["z"]],
-            vectorize=True,
-            dask="parallelized",
-            output_dtypes=[float],
-        )
-
-
-def test_output_wrong_number() -> None:
-    variable = xr.Variable("x", np.arange(10))
-
-    def identity(x):
-        return x
-
-    def tuple3x(x):
-        return (x, x, x)
-
-    with pytest.raises(ValueError, match=r"number of outputs"):
-        apply_ufunc(identity, variable, output_core_dims=[(), ()])
-
-    with pytest.raises(ValueError, match=r"number of outputs"):
-        apply_ufunc(tuple3x, variable, output_core_dims=[(), ()])
-
-
-def test_output_wrong_dims() -> None:
-    variable = xr.Variable("x", np.arange(10))
-
-    def add_dim(x):
-        return x[..., np.newaxis]
-
-    def remove_dim(x):
-        return x[..., 0]
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(add_dim, variable, output_core_dims=[("y", "z")])
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(add_dim, variable)
-
-    with pytest.raises(ValueError, match=r"unexpected number of dimensions"):
-        apply_ufunc(remove_dim, variable)
-
-
-def test_output_wrong_dim_size() -> None:
-    array = np.arange(10)
-    variable = xr.Variable("x", array)
-    data_array = xr.DataArray(variable, [("x", -array)])
-    dataset = xr.Dataset({"y": variable}, {"x": -array})
-
-    def truncate(array):
-        return array[:5]
-
-    def apply_truncate_broadcast_invalid(obj):
-        return apply_ufunc(truncate, obj)
-
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(variable)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(data_array)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_broadcast_invalid(dataset)
-
-    def apply_truncate_x_x_invalid(obj):
-        return apply_ufunc(
-            truncate, obj, input_core_dims=[["x"]], output_core_dims=[["x"]]
-        )
-
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(variable)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(data_array)
-    with pytest.raises(ValueError, match=r"size of dimension"):
-        apply_truncate_x_x_invalid(dataset)
-
-    def apply_truncate_x_z(obj):
-        return apply_ufunc(
-            truncate, obj, input_core_dims=[["x"]], output_core_dims=[["z"]]
-        )
-
-    assert_identical(xr.Variable("z", array[:5]), apply_truncate_x_z(variable))
-    assert_identical(
-        xr.DataArray(array[:5], dims=["z"]), apply_truncate_x_z(data_array)
-    )
-    assert_identical(xr.Dataset({"y": ("z", array[:5])}), apply_truncate_x_z(dataset))
-
-    def apply_truncate_x_x_valid(obj):
-        return apply_ufunc(
-            truncate,
-            obj,
-            input_core_dims=[["x"]],
-            output_core_dims=[["x"]],
-            exclude_dims={"x"},
-        )
-
-    assert_identical(xr.Variable("x", array[:5]), apply_truncate_x_x_valid(variable))
-    assert_identical(
-        xr.DataArray(array[:5], dims=["x"]), apply_truncate_x_x_valid(data_array)
-    )
-    assert_identical(
-        xr.Dataset({"y": ("x", array[:5])}), apply_truncate_x_x_valid(dataset)
-    )
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-def test_dot(use_dask) -> None:
-    if use_dask:
-        if not has_dask:
-            pytest.skip("test for dask.")
-
-    a = np.arange(30 * 4).reshape(30, 4)
-    b = np.arange(30 * 4 * 5).reshape(30, 4, 5)
-    c = np.arange(5 * 60).reshape(5, 60)
-    da_a = xr.DataArray(a, dims=["a", "b"], coords={"a": np.linspace(0, 1, 30)})
-    da_b = xr.DataArray(b, dims=["a", "b", "c"], coords={"a": np.linspace(0, 1, 30)})
-    da_c = xr.DataArray(c, dims=["c", "e"])
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-        da_c = da_c.chunk({"c": 3})
-    actual = xr.dot(da_a, da_b, dims=["a", "b"])
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    actual = xr.dot(da_a, da_b)
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    # for only a single array is passed without dims argument, just return
-    # as is
-    actual = xr.dot(da_a)
-    assert_identical(da_a, actual)
-
-    # test for variable
-    actual = xr.dot(da_a.variable, da_b.variable)
-    assert actual.dims == ("c",)
-    assert (actual.data == np.einsum("ij,ijk->k", a, b)).all()
-    assert isinstance(actual.data, type(da_a.variable.data))
-
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-        actual = xr.dot(da_a, da_b, dims=["b"])
-        assert actual.dims == ("a", "c")
-        assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-        assert isinstance(actual.variable.data, type(da_a.variable.data))
-
-    actual = xr.dot(da_a, da_b, dims=["b"])
-    assert actual.dims == ("a", "c")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="b")
-    assert actual.dims == ("a", "c")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="a")
-    assert actual.dims == ("b", "c")
-    assert (actual.data == np.einsum("ij,ijk->jk", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, dims="c")
-    assert actual.dims == ("a", "b")
-    assert (actual.data == np.einsum("ij,ijk->ij", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, da_c, dims=["a", "b"])
-    assert actual.dims == ("c", "e")
-    assert (actual.data == np.einsum("ij,ijk,kl->kl ", a, b, c)).all()
-
-    # should work with tuple
-    actual = xr.dot(da_a, da_b, dims=("c",))
-    assert actual.dims == ("a", "b")
-    assert (actual.data == np.einsum("ij,ijk->ij", a, b)).all()
-
-    # default dims
-    actual = xr.dot(da_a, da_b, da_c)
-    assert actual.dims == ("e",)
-    assert (actual.data == np.einsum("ij,ijk,kl->l ", a, b, c)).all()
-
-    # 1 array summation
-    actual = xr.dot(da_a, dims="a")
-    assert actual.dims == ("b",)
-    assert (actual.data == np.einsum("ij->j ", a)).all()
-
-    # empty dim
-    actual = xr.dot(da_a.sel(a=[]), da_a.sel(a=[]), dims="a")
-    assert actual.dims == ("b",)
-    assert (actual.data == np.zeros(actual.shape)).all()
-
-    # Ellipsis (...) sums over all dimensions
-    actual = xr.dot(da_a, da_b, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij,ijk->", a, b)).all()
-
-    actual = xr.dot(da_a, da_b, da_c, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij,ijk,kl-> ", a, b, c)).all()
-
-    actual = xr.dot(da_a, dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.einsum("ij-> ", a)).all()
-
-    actual = xr.dot(da_a.sel(a=[]), da_a.sel(a=[]), dims=...)
-    assert actual.dims == ()
-    assert (actual.data == np.zeros(actual.shape)).all()
-
-    # Invalid cases
-    if not use_dask:
-        with pytest.raises(TypeError):
-            xr.dot(da_a, dims="a", invalid=None)
-    with pytest.raises(TypeError):
-        xr.dot(da_a.to_dataset(name="da"), dims="a")
-    with pytest.raises(TypeError):
-        xr.dot(dims="a")
-
-    # einsum parameters
-    actual = xr.dot(da_a, da_b, dims=["b"], order="C")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-    assert actual.values.flags["C_CONTIGUOUS"]
-    assert not actual.values.flags["F_CONTIGUOUS"]
-    actual = xr.dot(da_a, da_b, dims=["b"], order="F")
-    assert (actual.data == np.einsum("ij,ijk->ik", a, b)).all()
-    # dask converts Fortran arrays to C order when merging the final array
-    if not use_dask:
-        assert not actual.values.flags["C_CONTIGUOUS"]
-        assert actual.values.flags["F_CONTIGUOUS"]
-
-    # einsum has a constant string as of the first parameter, which makes
-    # it hard to pass to xarray.apply_ufunc.
-    # make sure dot() uses functools.partial(einsum, subscripts), which
-    # can be pickled, and not a lambda, which can't.
-    pickle.loads(pickle.dumps(xr.dot(da_a)))
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-def test_dot_align_coords(use_dask) -> None:
-    # GH 3694
-
-    if use_dask:
-        if not has_dask:
-            pytest.skip("test for dask.")
-
-    a = np.arange(30 * 4).reshape(30, 4)
-    b = np.arange(30 * 4 * 5).reshape(30, 4, 5)
-
-    # use partially overlapping coords
-    coords_a = {"a": np.arange(30), "b": np.arange(4)}
-    coords_b = {"a": np.arange(5, 35), "b": np.arange(1, 5)}
-
-    da_a = xr.DataArray(a, dims=["a", "b"], coords=coords_a)
-    da_b = xr.DataArray(b, dims=["a", "b", "c"], coords=coords_b)
-
-    if use_dask:
-        da_a = da_a.chunk({"a": 3})
-        da_b = da_b.chunk({"a": 3})
-
-    # join="inner" is the default
-    actual = xr.dot(da_a, da_b)
-    # `dot` sums over the common dimensions of the arguments
-    expected = (da_a * da_b).sum(["a", "b"])
-    xr.testing.assert_allclose(expected, actual)
-
-    actual = xr.dot(da_a, da_b, dims=...)
-    expected = (da_a * da_b).sum()
-    xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="exact"):
-        with pytest.raises(ValueError, match=r"indexes along dimension"):
-            xr.dot(da_a, da_b)
-
-    # NOTE: dot always uses `join="inner"` because `(a * b).sum()` yields the same for all
-    # join method (except "exact")
-    with xr.set_options(arithmetic_join="left"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="right"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-    with xr.set_options(arithmetic_join="outer"):
-        actual = xr.dot(da_a, da_b)
-        expected = (da_a * da_b).sum(["a", "b"])
-        xr.testing.assert_allclose(expected, actual)
-
-
-def test_where() -> None:
-    cond = xr.DataArray([True, False], dims="x")
-    actual = xr.where(cond, 1, 0)
-    expected = xr.DataArray([1, 0], dims="x")
-    assert_identical(expected, actual)
-
-
-@pytest.mark.parametrize("use_dask", [True, False])
-@pytest.mark.parametrize("use_datetime", [True, False])
-def test_polyval(use_dask, use_datetime) -> None:
-    if use_dask and not has_dask:
-        pytest.skip("requires dask")
-
-    if use_datetime:
-        xcoord = xr.DataArray(
-            pd.date_range("2000-01-01", freq="D", periods=10), dims=("x",), name="x"
-        )
-        x = xr.core.missing.get_clean_interp_index(xcoord, "x")
-    else:
-        xcoord = x = np.arange(10)
-
-    da = xr.DataArray(
-        np.stack((1.0 + x + 2.0 * x ** 2, 1.0 + 2.0 * x + 3.0 * x ** 2)),
-        dims=("d", "x"),
-        coords={"x": xcoord, "d": [0, 1]},
-    )
-    coeffs = xr.DataArray(
-        [[2, 1, 1], [3, 2, 1]],
-        dims=("d", "degree"),
-        coords={"d": [0, 1], "degree": [2, 1, 0]},
-    )
-    if use_dask:
-        coeffs = coeffs.chunk({"d": 2})
-
-    da_pv = xr.polyval(da.x, coeffs)
-
-    xr.testing.assert_allclose(da, da_pv.T)
Obtaining file:///testbed
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.18 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.20.3.dev15+g52e5e18b.d20250207) (1.23.0)
Requirement already satisfied: pandas>=1.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from xarray==0.20.3.dev15+g52e5e18b.d20250207) (1.5.3)
Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.1->xarray==0.20.3.dev15+g52e5e18b.d20250207) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from pandas>=1.1->xarray==0.20.3.dev15+g52e5e18b.d20250207) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/testbed/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1->xarray==0.20.3.dev15+g52e5e18b.d20250207) (1.16.0)
Building wheels for collected packages: xarray
  Building editable for xarray (pyproject.toml): started
  Building editable for xarray (pyproject.toml): finished with status 'done'
  Created wheel for xarray: filename=xarray-0.20.3.dev15+g52e5e18b.d20250207-0.editable-py3-none-any.whl size=9122 sha256=2b2e6469d673aa4d706e75ed15a4d013f6c7a5972054bd5c4bde1a63b192eecd
  Stored in directory: /tmp/pip-ephem-wheel-cache-3_a8xwqj/wheels/0d/a6/cb/465a7b303d624cc531250fa27c75d038ddc29430bdb6ba7c9f
Successfully built xarray
Installing collected packages: xarray
  Attempting uninstall: xarray
    Found existing installation: xarray 0.20.3.dev15+g52e5e18b
    Uninstalling xarray-0.20.3.dev15+g52e5e18b:
      Successfully uninstalled xarray-0.20.3.dev15+g52e5e18b
Successfully installed xarray-0.20.3.dev15+g52e5e18b.d20250207
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
============================= test session starts ==============================
platform linux -- Python 3.10.14, pytest-7.4.0, pluggy-1.5.0
rootdir: /testbed
configfile: setup.cfg
plugins: env-1.1.3, cov-5.0.0, hypothesis-6.108.5, xdist-3.6.1
collected 15 items

xarray/tests/test_computation.py ...............                         [100%]

=============================== warnings summary ===============================
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pydap/lib.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    from pkg_resources import get_distribution

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.responses')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(parent)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.handlers')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871
  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pydap.tests')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
=========================== short test summary info ============================
PASSED xarray/tests/test_computation.py::test_result_name_single_name
PASSED xarray/tests/test_computation.py::test_result_name_multiple_names
PASSED xarray/tests/test_computation.py::test_result_name_no_name
PASSED xarray/tests/test_computation.py::test_ordered_set_union
PASSED xarray/tests/test_computation.py::test_ordered_set_intersection
PASSED xarray/tests/test_computation.py::test_join_dict_keys
PASSED xarray/tests/test_computation.py::test_collect_dict_values
PASSED xarray/tests/test_computation.py::test_unified_dim_sizes
PASSED xarray/tests/test_computation.py::test_apply_ufunc
PASSED xarray/tests/test_computation.py::test_cov
PASSED xarray/tests/test_computation.py::test_corr
PASSED xarray/tests/test_computation.py::test_cross
PASSED xarray/tests/test_computation.py::test_dot
PASSED xarray/tests/test_computation.py::test_where
PASSED xarray/tests/test_computation.py::test_unify_chunks
======================== 15 passed, 8 warnings in 0.24s ========================

